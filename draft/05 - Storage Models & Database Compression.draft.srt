1
00:00:33,520 --> 00:00:40,170
0,400 540,940 940,4950 4950,5350 5790,6190 6390,6650
{You,get,a,live,show} {coming,up},| {we'll,talking,that,in,a,second}.| {So,quickly\,,for,you,guys,in,the,class},| {homework,#1,is} due
你有一场表演要来了，|我们稍后再讨论这个。|对于来到这节课的人，|作业一截止这周五，15 号，

2
00:00:40,170 --> 00:00:41,390
0,165 165,450 450,675 675,765 765,1220
this Friday on the 15th,|
|

3
00:00:41,650 --> 00:00:43,665
0,350 350,700 1260,1550 1550,1805 1805,2015
project #1 is out and
项目一已经发布，截止 10 月 1 日，

4
00:00:43,665 --> 00:00:45,050
0,105 105,285 285,605 775,1080 1080,1385
be due on October 1st,|
|

5
00:00:46,270 --> 00:00:47,175
0,290 290,425 425,515 515,740 740,905
even though we haven't discussed|
尽管我们还没有讨论|

6
00:00:47,175 --> 00:00:47,940
0,105 105,180 180,405 405,555 555,765
what a Buffer Pool is
什么是缓冲池，什么是缓冲池管理器，

7
00:00:47,940 --> 00:00:50,025
0,320 520,900 900,1140 1140,1520 1810,2085
yet, {Buffer,Pool} Manager is,| you
|如果你想要开始，你可以开始，

8
00:00:50,025 --> 00:00:50,775
0,165 165,330 330,495 495,645 645,750
can get started if you

9
00:00:50,775 --> 00:00:52,890
0,245 1105,1505 1705,1950 1950,2070 2070,2115
want,| again where you're going
|在哪里分配内存，以便将其写出磁盘，

10
00:00:52,890 --> 00:00:53,670
0,45 45,285 285,480 480,660 660,780
to allocate memory that gets

11
00:00:53,670 --> 00:00:54,620
0,120 120,255 255,390 390,495 495,950
it written out of disk.|
|

12
00:00:56,020 --> 00:00:58,485
0,400 960,1280 1280,1600 1860,2180 2180,2465
The upcoming events,| so next,
即将到来的活动，|下周一， Dana Van Aken 将给我们一个演讲，

13
00:00:58,485 --> 00:01:00,360
0,315 315,665 1315,1715
next Monday, Dana

14
00:01:00,360 --> 00:01:01,425
0,165 165,345 345,450 450,710 730,1065
{Van,Aken} will be giving a

15
00:01:01,425 --> 00:01:03,180
0,240 240,405 405,665 745,1335 1335,1755
talk with us {[] -}

16
00:01:03,180 --> 00:01:04,980
0,350 400,645 645,1100 1360,1650 1650,1800
{[] - -},| giving a
|在我们的系列讲座上进行演讲，

17
00:01:04,980 --> 00:01:06,350
0,260 280,570 570,750 750,1080 1080,1370
talk at our seminar series

18
00:01:06,730 --> 00:01:15,075
0,400 420,820 7680,7970 7970,8090 8090,8345
on the,| talking the seminary
|演讲系列讲座在 Zoom 上 在星期一，

19
00:01:15,075 --> 00:01:16,280
0,255 255,540 540,780 780,945 945,1205
series on Zoom on Monday,|
|

20
00:01:16,510 --> 00:01:18,750
0,275 275,550 1170,1520 1520,1865 1865,2240
and then before that {DJ2PL
在那之前， DJ2PL 在本周六晚上 9 有一场演唱会，

21
00:01:18,750 --> 00:01:20,150
0,225 225,465 465,735 735,1065 1065,1400
-} is having a concert

22
00:01:20,320 --> 00:01:23,025
0,400 750,1070 1070,1390 2250,2525 2525,2705
this, this Saturday at {9pm

23
00:01:23,025 --> 00:01:25,110
0,240 240,435 435,755 1435,1710 1710,2085
-}| on campus, in Rangos
|在校园里，在 CUC 的 Rangos 。

24
00:01:25,110 --> 00:01:26,740
0,195 195,500 550,825 825,1100
in the, in the,

25
00:01:27,320 --> 00:01:29,200
0,230 230,335 335,515 515,820 1620,1880
{CUC - -}, right.| They
|他们是不是还让你签名？

26
00:01:29,200 --> 00:01:30,160
0,135 135,300 300,465 465,855 855,960
let you sign autographs or

27
00:01:30,160 --> 00:01:35,890
0,260 3970,4370 5200,5505 5505,5640 5640,5730
no?| Yeah, {CMU -} is
|是的， CMU 有点奇怪，

28
00:01:35,890 --> 00:01:36,730
0,120 120,240 240,420 420,600 600,840
kind of weird,| they won't
|他们不会让他，

29
00:01:36,730 --> 00:01:37,645
0,120 120,270 270,525 525,750 750,915
let him,| like like it's
|这是一场盛大的演出，

30
00:01:37,645 --> 00:01:38,380
0,90 90,285 285,510 510,645 645,735
a big show| and they
|之后也不会让他签名，

31
00:01:38,380 --> 00:01:39,325
0,150 150,225 225,345 345,510 510,945
won't let him sign autographs

32
00:01:39,325 --> 00:01:46,735
0,245 1375,1775 1825,2225 3805,7305 7305,7410
afterwards,| {some,stupid} yeah.| {So,last,class,is}, jump
|有点愚蠢，是的。|所以上一节课，跳转到那里。

33
00:01:46,735 --> 00:01:47,900
0,120 120,240 240,515
right into it.|
|

34
00:01:48,160 --> 00:01:49,515
0,350 350,635 635,965 965,1220 1220,1355
So last class we were
上一节课，我们讨论了其他方法，

35
00:01:49,515 --> 00:01:51,950
0,240 240,605 1045,1445 1735,2085 2085,2435
talking about {} alternative approaches|
|

36
00:01:51,970 --> 00:01:54,075
0,400 960,1295 1295,1505 1505,1685 1685,2105
to to the {tuple-oriented -}
对于我们上周提出的面向 tuple 的插槽页面存储方案，

37
00:01:54,075 --> 00:01:55,785
0,405 405,615 615,885 885,1205 1435,1710
{slotted-page -} storage scheme, that

38
00:01:55,785 --> 00:01:58,230
0,135 135,395 1195,1515 1515,1835 2185,2445
we presented last week| and
|特别是我们花了很多时间讨论日志结构存储方法，

39
00:01:58,230 --> 00:01:59,210
0,150 150,330 330,540 540,720 720,980
in particular we spent a

40
00:01:59,350 --> 00:02:00,285
0,260 260,380 380,530 530,740 740,935
lot of time talking about

41
00:02:00,285 --> 00:02:02,600
0,135 135,345 345,780 780,1085 1915,2315
the {log-structured -} storage method,|
|

42
00:02:03,040 --> 00:02:04,290
0,400 540,785 785,890 890,1070 1070,1250
where instead of storing the
不是存储实际的 tuple ，

43
00:02:04,290 --> 00:02:05,300
0,165 165,315 315,600 600,735 735,1010
actual {tuples -},| you store
|而是存储对 tuple 所做更改的日志条目，

44
00:02:06,070 --> 00:02:07,940
0,275 275,470 470,970 1050,1450 1470,1870
the log entries of of

45
00:02:08,410 --> 00:02:09,600
0,320 320,620 620,905 905,1040 1040,1190
the changes you've made to

46
00:02:09,600 --> 00:02:11,430
0,410 1210,1455 1455,1560 1560,1680 1680,1830
tuple| and I said that
|我说过这在写入密集型的现代系统中很流行。

47
00:02:11,430 --> 00:02:13,020
0,290 340,735 735,1130 1270,1500 1500,1590
was popular in sort of

48
00:02:13,020 --> 00:02:13,965
0,210 210,525 525,735 735,825 825,945
modern systems that are more

49
00:02:13,965 --> 00:02:17,235
0,135 135,515 1465,1865 2755,3060 3060,3270
write intensive.| So the three
|所以，我们谈到的三种方法，

50
00:02:17,235 --> 00:02:18,255
0,225 225,405 405,570 570,810 810,1020
approaches we talked about,| so
|面向 tuple 的插槽页面，日志结构存储，索引组织存储，

51
00:02:18,255 --> 00:02:19,290
0,150 150,285 285,405 405,915 915,1035
the the {tuple-oriented -} {slotted-pages

52
00:02:19,290 --> 00:02:21,135
0,260 610,975 975,1245 1245,1500 1500,1845
-}, the {log-structure -} storage,

53
00:02:21,135 --> 00:02:23,180
0,285 285,570 570,840 840,1115 1645,2045
the {index-organized -} storage,| these
|这些存储方法非常适合写入工作负载很重的情况，

54
00:02:23,290 --> 00:02:26,960
0,380 380,760 990,1390 2520,2920 3270,3670
storage approaches are are ideal

55
00:02:26,980 --> 00:02:28,395
0,380 380,965 965,1070 1070,1220 1220,1415
for workloads that are write

56
00:02:28,395 --> 00:02:29,360
0,305
heavy,|
|

57
00:02:29,460 --> 00:02:30,380
0,245 245,350 350,605 605,815 815,920
meaning if you're doing a
这意味着如果你执行大量的插入、更新或删除，

58
00:02:30,380 --> 00:02:31,490
0,75 75,165 165,705 705,960 960,1110
lot of inserts, updates or

59
00:02:31,490 --> 00:02:33,215
0,560 910,1215 1215,1365 1365,1515 1515,1725
deletes, right,| the {log-structure -}
|日志结构显然更适合这个，

60
00:02:33,215 --> 00:02:34,490
0,165 165,330 330,635 805,1110 1110,1275
one is obviously better for

61
00:02:34,490 --> 00:02:36,095
0,210 210,560 730,1020 1020,1290 1290,1605
this,| because you're appending to
|因为你在追加日志，

62
00:02:36,095 --> 00:02:38,675
0,225 225,485 2035,2325 2325,2475 2475,2580
the log| and for a
|对于许多应用程序或大多数应用程序，

63
00:02:38,675 --> 00:02:40,040
0,105 105,330 330,695 865,1125 1125,1365
lot of applications or most

64
00:02:40,040 --> 00:02:40,990
0,300 300,465 465,570 570,690 690,950
applications,| when you start off,
|当你开始时，你可能是更多写入工作负载，

65
00:02:42,540 --> 00:02:44,045
0,290 290,365 365,440 440,670 1230,1505
you're going to be a

66
00:02:44,045 --> 00:02:45,700
0,275 355,690 690,915 915,1125 1125,1655
more potentially write heavy workload,|
|

67
00:02:46,500 --> 00:02:47,225
0,260 260,455 455,530 530,590 590,725
but there's going to be
但将会有一些应用程序、某些环境或一些工作负载，

68
00:02:47,225 --> 00:02:49,100
0,305 475,875 895,1185 1185,1455 1455,1875
some applications or some environments

69
00:02:49,100 --> 00:02:51,005
0,120 120,285 285,855 855,1130 1600,1905
or some workloads,| where maybe
|你可能并不关心获得最好的写入性能，

70
00:02:51,005 --> 00:02:52,010
0,135 135,390 390,615 615,810 810,1005
you don't care about getting

71
00:02:52,010 --> 00:02:53,290
0,165 165,345 345,750 750,990 990,1280
the best performance for writes,|
|

72
00:02:54,160 --> 00:02:54,970
0,165 165,315 315,525 525,705 705,810
what you really want to
你真正想要做的是获得最好的读取性能，

73
00:02:54,970 --> 00:02:55,735
0,120 120,240 240,390 390,540 540,765
do is get the best

74
00:02:55,735 --> 00:02:57,960
0,365 505,795 795,1265
performance for reads,|
|

75
00:02:57,960 --> 00:02:59,505
0,270 270,555 555,855 855,1250 1270,1545
and therefore, these approaches may
所以，这些方法可能不是接近它的最好方式。

76
00:02:59,505 --> 00:03:01,875
0,180 180,485 1645,1935 1935,2130 2130,2370
not be the best way

77
00:03:01,875 --> 00:03:04,100
0,335 985,1275 1275,1565
to approach it.|
|

78
00:03:04,280 --> 00:03:04,795
0,215 215,335 335,365 365,425 425,515
So I'm going to spend
所以，我将花一点时间讨论一下大类别或数据库应用程序是什么样子的，

79
00:03:04,795 --> 00:03:05,635
0,105 105,285 285,510 510,690 690,840
a little time talking about

80
00:03:05,635 --> 00:03:07,075
0,165 165,285 285,515 715,1080 1080,1440
what sort of broad categories

81
00:03:07,075 --> 00:03:08,580
0,240 240,485 565,945 945,1215 1215,1505
or database applications look like,|
|

82
00:03:08,990 --> 00:03:10,225
0,245 245,380 380,680 680,785 785,1235
and then that'll be motivation
然后这将是我们为什么要考虑替代存储方案的动机，

83
00:03:10,225 --> 00:03:11,305
0,255 255,495 495,705 705,825 825,1080
for why we want to

84
00:03:11,305 --> 00:03:12,370
0,255 255,330 330,480 480,765 765,1065
look at an alternative storage

85
00:03:12,370 --> 00:03:14,860
0,350 730,1130 1660,2060 2110,2355 2355,2490
scheme,| where maybe we don't
|我们可能不想存储所有东西在行中，

86
00:03:14,860 --> 00:03:15,685
0,60 60,150 150,345 345,600 600,825
want to store everything just

87
00:03:15,685 --> 00:03:18,750
0,515 515,2035 2035,2310 2310,2475 2475,2745 2745,3065
rows,| {like,the,tuples,with} all the attributes together.|
|tuple 将所有属性放在一起。|

88
00:03:20,660 --> 00:03:21,625
0,350 350,575 575,680 680,785 785,965
So this is a rough
这是一个粗略的分类，

89
00:03:21,625 --> 00:03:24,720
0,635 2005,2405 2425,2700 2700,2835 2835,3095
categorization,| but industry this is,|
|但行业是，|

90
00:03:25,040 --> 00:03:25,870
0,245 245,380 380,590 590,755 755,830
if you say sort of
如果你说这三个方法，

91
00:03:25,870 --> 00:03:27,820
0,135 135,440 550,840 840,1130 1690,1950
these three, these three, you

92
00:03:27,820 --> 00:03:28,375
0,105 105,270 270,345 345,420 420,555
say you're one of these

93
00:03:28,375 --> 00:03:30,600
0,210 210,515 1285,1590 1590,1860 1860,2225
three approaches,| people roughly know
|人们大致知道你的意思。

94
00:03:30,740 --> 00:03:32,785
0,260 260,380 380,640 1620,1895 1895,2045
what you mean.| So the
|第一类应用程序将称为 OLTP 或在线事务处理，

95
00:03:32,785 --> 00:03:34,465
0,275 295,690 690,1035 1035,1385 1405,1680
first category of applications are

96
00:03:34,465 --> 00:03:35,530
0,90 90,150 150,270 270,870 870,1065
going to call OLTP or

97
00:03:35,530 --> 00:03:37,810
0,315 315,705 705,1100 1810,2100 2100,2280
On-Line Transaction Processing| and these
|这些应用程序中，你可以从外部世界获取新数据，

98
00:03:37,810 --> 00:03:40,675
0,290 310,710 760,1160 1750,2190 2190,2865
are applications where you're ingesting

99
00:03:40,675 --> 00:03:41,890
0,225 225,495 495,705 705,930 930,1215
new data from the outside

100
00:03:41,890 --> 00:03:44,065
0,320 610,975 975,1305 1305,1580 1930,2175
world| and you're serving, you
|你同时为许多用户提供服务，

101
00:03:44,065 --> 00:03:45,370
0,245 415,720 720,915 915,1065 1065,1305
know, a lot of users

102
00:03:45,370 --> 00:03:46,990
0,240 240,375 375,555 555,860 1360,1620
at the same time,| so
|我一直喜欢使用的示例应用程序是 Amazon ，

103
00:03:46,990 --> 00:03:48,385
0,135 135,315 315,540 540,860 1000,1395
again the, the, the example

104
00:03:48,385 --> 00:03:49,120
0,285 285,435 435,540 540,645 645,735
application I always like to

105
00:03:49,120 --> 00:03:51,100
0,120 120,410 430,830 1570,1845 1845,1980
use is Amazon,| when you
|当你去亚马逊网站，

106
00:03:51,100 --> 00:03:52,020
0,120 120,210 210,375 375,615 615,920
go to the Amazon website,|
|

107
00:03:52,280 --> 00:03:53,245
0,260 260,500 500,725 725,830 830,965
you look, you look at
你看产品，然后你点击东西，

108
00:03:53,245 --> 00:03:55,165
0,275 955,1215 1215,1425 1425,1680 1680,1920
products, then you click things,|
|

109
00:03:55,165 --> 00:03:55,795
0,195 195,300 300,405 405,510 510,630
you add them to your
你把它们添加到你的购物车，然后你购买它们，

110
00:03:55,795 --> 00:03:56,875
0,275 355,615 615,735 735,870 870,1080
cart and then you purchase

111
00:03:56,875 --> 00:03:58,015
0,335 505,780 780,885 885,990 990,1140
them,| maybe you go to
|也许你打开你的账户信息，

112
00:03:58,015 --> 00:03:59,275
0,150 150,345 345,665 685,1035 1035,1260
on your account information| and
|然后更新你的邮寄地址或付款信息，

113
00:03:59,275 --> 00:04:00,510
0,135 135,395 415,780 780,990 990,1235
you go update, you know,

114
00:04:00,890 --> 00:04:02,335
0,275 275,590 590,815 815,1100 1100,1445
your mailing address or payment

115
00:04:02,335 --> 00:04:04,435
0,395 1015,1305 1305,1455 1455,1715 1765,2100
information,| those are all considered
|这些都被认为是 OLTP 类型工作负载，

116
00:04:04,435 --> 00:04:08,230
0,695 1465,1770 1770,2385 2385,2705 3475,3795
OLTP style workloads,| because you're
|因为你对数据库的一小部分进行更改，

117
00:04:08,230 --> 00:04:10,375
0,230 490,890 1030,1365 1365,1700 1750,2145
making changes to a small

118
00:04:10,375 --> 00:04:11,590
0,465 465,585 585,690 690,935 955,1215
subset of the database,| like
|比如，你要更新你的购物车，更新你的支付信息。

119
00:04:11,590 --> 00:04:12,900
0,150 150,360 360,735 735,975 975,1310
you're going updating your cart,

120
00:04:13,040 --> 00:04:14,640
0,335 335,680 680,875 875,1180 1200,1600
going updating your payment information,

121
00:04:15,580 --> 00:04:17,490
0,400 1230,1490 1490,1640 1640,1805 1805,1910
right.| So think about, you
|想想在 Reddit 或 Hacker News 上发布一些东西，

122
00:04:17,490 --> 00:04:18,150
0,195 195,405 405,495 495,585 585,660
know, you know, think of

123
00:04:18,150 --> 00:04:19,110
0,120 120,420 420,540 540,675 675,960
like posting things on Reddit

124
00:04:19,110 --> 00:04:20,475
0,105 105,345 345,590 880,1185 1185,1365
or Hacker News,| those are
|它们进行小的更改，

125
00:04:20,475 --> 00:04:21,930
0,240 240,510 510,815 835,1170 1170,1455
making small changes,| which potentially
|这可能是一个大的数据库，

126
00:04:21,930 --> 00:04:22,740
0,225 225,315 315,375 375,525 525,810
could be a large database,|
|

127
00:04:22,740 --> 00:04:23,970
0,240 240,500 520,810 810,975 975,1230
but the amount of change
但是每个操作进行的查询的更改量是小的，

128
00:04:23,970 --> 00:04:25,680
0,315 315,680 910,1245 1245,1500 1500,1710
each query where operation is

129
00:04:25,680 --> 00:04:26,790
0,240 240,510 510,780 780,975 975,1110
making is small,| amount of
|它们读取的很多数据是小的，

130
00:04:26,790 --> 00:04:28,200
0,255 255,480 480,645 645,890 1090,1410
data that they're reading is

131
00:04:28,200 --> 00:04:30,270
0,320 820,1220 1600,1830 1830,1920 1920,2070
small,| reading for a single
|读取单个实体。

132
00:04:30,270 --> 00:04:31,280
0,530
entity.|
|

133
00:04:31,980 --> 00:04:33,425
0,260 260,520 660,995 995,1205 1205,1445
So contrast this with On-Line
将这与在线分析处理 OLAP 工作负载进行对比，

134
00:04:33,425 --> 00:04:35,770
0,585 585,845 985,1485 1485,2055 2055,2345
Analytical Processing, OLAP workloads,| where
|这就是我想要使用，

135
00:04:36,690 --> 00:04:37,520
0,275 275,410 410,545 545,695 695,830
this is where I want

136
00:04:37,520 --> 00:04:39,230
0,150 150,440 1300,1590 1590,1635 1635,1710
to use,| I'm going to
|我将运行将在整个数据集中提取或推断新信息的查询，

137
00:04:39,230 --> 00:04:40,670
0,260 280,795 795,1100 1120,1365 1365,1440
run queries that are going

138
00:04:40,670 --> 00:04:42,340
0,180 180,465 465,630 630,1275 1275,1670
to extract or extrapolate new

139
00:04:42,450 --> 00:04:44,765
0,400 1200,1505 1505,1730 1730,2015 2015,2315
information across the entire data

140
00:04:44,765 --> 00:04:45,740
0,335
set,|
|

141
00:04:45,740 --> 00:04:46,510
0,150 150,240 240,360 360,495 495,770
so this would be like
所以，这就像是亚马逊运行一个查询，

142
00:04:46,590 --> 00:04:47,735
0,320 320,530 530,695 695,935 935,1145
Amazon running a query,| that
|说为我找到销售排名第一的产品，

143
00:04:47,735 --> 00:04:48,680
0,240 240,510 510,675 675,795 795,945
says find me the number

144
00:04:48,680 --> 00:04:50,525
0,290 310,630 630,950 1330,1650 1650,1845
one sold product| in the
|在宾夕法尼亚州，在星期六，

145
00:04:50,525 --> 00:04:52,115
0,150 150,285 285,545 1075,1395 1395,1590
state of Pennsylvania on, on

146
00:04:52,115 --> 00:04:53,285
0,165 165,455 535,795 795,915 915,1170
a Saturday,| when the temperature
|而且当时气温超过 80 度，

147
00:04:53,285 --> 00:04:55,580
0,330 330,665 805,1170 1170,1535
is above 80 degrees,

148
00:04:56,030 --> 00:04:57,190
0,320 320,545 545,710 710,965 965,1160
right,| It's not looking at
|它不是着眼于单个人或单个实体，

149
00:04:57,190 --> 00:04:58,510
0,135 135,345 345,660 660,1020 1020,1320
a single person or looking

150
00:04:58,510 --> 00:05:00,235
0,285 285,525 525,800 1210,1665 1665,1725
at a single entity,| but
|而是着眼于整个表，

151
00:05:00,235 --> 00:05:01,240
0,135 135,300 300,540 540,750 750,1005
it's looking across the entire

152
00:05:01,240 --> 00:05:02,400
0,350
table,|
|

153
00:05:02,530 --> 00:05:03,345
0,305 305,485 485,605 605,695 695,815
potentially doing a lot of
可以与额外的信息做了很多 JOIN ，

154
00:05:03,345 --> 00:05:04,965
0,515 655,1055 1105,1350 1350,1440 1440,1620
JOINs also, you know, with

155
00:05:04,965 --> 00:05:08,505
0,335 775,1175 2335,2735 3055,3375 3375,3540
with additional information,| similar to
|类似于你们在家庭作业一中做过的事情。

156
00:05:08,505 --> 00:05:09,150
0,90 90,225 225,360 360,495 495,645
the things you guys have

157
00:05:09,150 --> 00:05:11,360
0,210 210,560 1000,1400 1510,1860 1860,2210
done in in homework #1.|
|

158
00:05:13,080 --> 00:05:14,015
0,395 395,620 620,680 680,785 785,935
And so in these {OLAP
所以，在这些 OLAP 工作负载中，

159
00:05:14,015 --> 00:05:14,885
0,150 150,555 555,765 765,825 825,870
-} workloads,| they're going to
|它们将主要是重读或只读，

160
00:05:14,885 --> 00:05:16,775
0,135 135,455 745,1020 1020,1295 1615,1890
be primarily read heavy or

161
00:05:16,775 --> 00:05:18,365
0,150 150,425 985,1290 1290,1485 1485,1590
read only, right,| I'm not
|我不做单个更新，

162
00:05:18,365 --> 00:05:19,595
0,180 180,435 435,720 720,990 990,1230
doing single updates,| I'm going
|我要在大表上做大的扫描和 JOIN 。

163
00:05:19,595 --> 00:05:21,140
0,330 330,615 615,990 990,1320 1320,1545
doing large scans of and

164
00:05:21,140 --> 00:05:23,360
0,390 390,680 880,1170 1170,1460
JOINs over big tables.|
|

165
00:05:23,890 --> 00:05:24,975
0,260 260,410 410,665 665,920 920,1085
And this last one is
最后一个是行业分析师或 Gartner 的流行语，叫做 HTAP ，

166
00:05:24,975 --> 00:05:26,535
0,120 120,365 475,720 720,965 1285,1560
sort of, sort of a

167
00:05:26,535 --> 00:05:28,440
0,545 595,960 960,1325 1345,1590 1590,1905
buzzword from the industry [analyst]

168
00:05:28,440 --> 00:05:30,960
0,150 150,590 1150,1410 1410,1940 2260,2520
or Gartner, called HTAP,| and
|这基本上就是，在某些应用程序中，

169
00:05:30,960 --> 00:05:31,890
0,105 105,225 225,500 610,840 840,930
this is basically there are

170
00:05:31,890 --> 00:05:32,865
0,225 225,540 540,750 750,870 870,975
some applications,| where you want
|你可能希望同时执行 OLTP 工作负载和 OLAP 工作负载，

171
00:05:32,865 --> 00:05:34,485
0,135 135,425 1015,1335 1335,1500 1500,1620
to do both the {OLTP

172
00:05:34,485 --> 00:05:35,430
0,105 105,210 210,360 360,795 795,945
- -} style workloads and

173
00:05:35,430 --> 00:05:37,695
0,120 120,375 375,1010 1780,2100 2100,2265
the OLAP workloads,| potentially in
|可能在同一个系统中，

174
00:05:37,695 --> 00:05:39,780
0,120 120,315 315,635 1405,1805 1825,2085
the same system,| so instead
|所以，不是让我把我所有的交易数据放进一个单独的数据仓库，

175
00:05:39,780 --> 00:05:40,650
0,120 120,300 300,480 480,660 660,870
of having to me take

176
00:05:40,650 --> 00:05:42,075
0,195 195,465 465,1005 1005,1230 1230,1425
all my transactional data, put

177
00:05:42,075 --> 00:05:43,280
0,135 135,285 285,465 465,705 705,1205
into a separate data warehouse|
|

178
00:05:44,050 --> 00:05:44,970
0,245 245,350 350,455 455,545 545,920
and then do my analytics
然后在那里做我的分析，

179
00:05:44,970 --> 00:05:46,755
0,120 120,380 1270,1560 1560,1695 1695,1785
on there,| maybe I can
|也许我可以在数据进来的时候直接做一些分析，

180
00:05:46,755 --> 00:05:48,195
0,150 150,330 330,855 855,1200 1200,1440
do some analytics directly as

181
00:05:48,195 --> 00:05:50,835
0,135 135,300 300,495 495,785 2305,2640
the data comes in,| we'll,
|我们会在整个学期讨论这个问题，

182
00:05:50,835 --> 00:05:52,680
0,335 505,780 780,1055 1405,1695 1695,1845
we'll discuss this throughout the

183
00:05:52,680 --> 00:05:54,435
0,285 285,650 910,1290 1290,1530 1530,1755
semester,| but the the main
|但你们要关注的主要两个是 OLTP 和 OLAP 。

184
00:05:54,435 --> 00:05:55,050
0,225 225,360 360,480 480,540 540,615
two ones you want to

185
00:05:55,050 --> 00:05:56,010
0,165 165,345 345,495 495,855 855,960
focus on are OLTP and

186
00:05:56,010 --> 00:05:57,080
0,380
OLAP.|
|

187
00:05:57,940 --> 00:05:58,755
0,290 290,425 425,515 515,650 650,815
Another way to think about
另一种考虑它们之间区别的方法是，

188
00:05:58,755 --> 00:06:01,635
0,450 450,705 705,965 1135,1535 2635,2880
distinction between them is,| sort
|这样一个简单的网格，

189
00:06:01,635 --> 00:06:02,745
0,90 90,195 195,455 655,945 945,1110
of a simple grid like

190
00:06:02,745 --> 00:06:05,100
0,270 270,635 1105,1485 1485,1865 2095,2355
this,| where along the the
|在 x 轴上表示工作负载是重写入的还是重读取，

191
00:06:05,100 --> 00:06:06,570
0,150 150,710 760,1110 1110,1260 1260,1470
x axis, I'm saying whether

192
00:06:06,570 --> 00:06:07,410
0,165 165,405 405,510 510,660 660,840
the workload is {} {Write-Heavy

193
00:06:07,410 --> 00:06:09,225
0,290 490,825 825,1050 1050,1340 1570,1815
-} versus {Read-Heavy -},| and
|然后 y 轴表示查询的复杂程度，

194
00:06:09,225 --> 00:06:10,305
0,105 105,225 225,375 375,795 795,1080
then the y axis says

195
00:06:10,305 --> 00:06:11,660
0,335 355,660 660,810 810,1080 1080,1355
how complex the queries are,

196
00:06:12,100 --> 00:06:12,990
0,400 450,680 680,740 740,815 815,890
right,| so you can sort
|所以你可以像这样划分它，

197
00:06:12,990 --> 00:06:13,545
0,120 120,270 270,360 360,435 435,555
of divide it up like

198
00:06:13,545 --> 00:06:14,775
0,270 270,870 870,1005 1005,1110 1110,1230
this,| OLTP would be down
|OLTP 会在这个角落，

199
00:06:14,775 --> 00:06:16,140
0,120 120,270 270,575 895,1185 1185,1365
in this corner,| because we're
|因为我们可能会进行大量的更新，

200
00:06:16,140 --> 00:06:17,295
0,230 370,675 675,825 825,945 945,1155
doing potentially a lot of

201
00:06:17,295 --> 00:06:19,245
0,335 1165,1425 1425,1545 1545,1815 1815,1950
updates,| but the queries we're
|但我们要执行的查询将非常简单，

202
00:06:19,245 --> 00:06:19,815
0,45 45,195 195,375 375,495 495,570
going to execute are going

203
00:06:19,815 --> 00:06:21,140
0,45 45,135 135,345 345,695
to be really simple,|
|

204
00:06:21,140 --> 00:06:22,930
0,300 300,600 600,930 930,1280 1390,1790
like go SELECT single,| go
比如 SELECT 单个，|SELECT * FROM account WHERE id = 'Andy',

205
00:06:22,950 --> 00:06:24,395
0,290 290,470 470,760 990,1265 1265,1445
SELECT * FROM the account

206
00:06:24,395 --> 00:06:25,955
0,240 240,575 655,960 960,1265 1285,1560
table, where your id equals

207
00:06:25,955 --> 00:06:28,685
0,275 895,1200 1200,1350 1350,1655 2395,2730
Andy,| it's going, getting, going,
|它会获取单个东西。

208
00:06:28,685 --> 00:06:30,340
0,285 285,555 555,875
getting single things.|
|

209
00:06:30,680 --> 00:06:31,630
0,305 305,485 485,620 620,785 785,950
{OLAP -} would be on
OLAP 会在范围的另一端，

210
00:06:31,630 --> 00:06:32,305
0,225 225,435 435,525 525,585 585,675
the opposite end of the

211
00:06:32,305 --> 00:06:34,900
0,210 210,545 1405,1805 2065,2400 2400,2595
spectrum here,| where we're doing
|在这里，我们主要进行读取，

212
00:06:34,900 --> 00:06:37,210
0,300 300,650 1060,1335 1335,1610 1960,2310
mostly writes and the mostly

213
00:06:37,210 --> 00:06:39,445
0,590 1000,1260 1260,1395 1395,1905 1905,2235
reads| and the reads, the
|读取， SELECT 查询将执行的，

214
00:06:39,445 --> 00:06:40,045
0,210 210,450 450,525 525,570 570,600
select queries are going to

215
00:06:40,045 --> 00:06:41,155
0,180 180,645 645,900 900,1020 1020,1110
be executing are going to

216
00:06:41,155 --> 00:06:42,680
0,245
be,|
|

217
00:06:42,680 --> 00:06:44,345
0,380 670,975 975,1260 1260,1530 1530,1665
{} much more complex than
比我们在 OLTP 的世界做的 要复杂得多，

218
00:06:44,345 --> 00:06:44,990
0,105 105,195 195,270 270,345 345,645
we do in the OLTP

219
00:06:44,990 --> 00:06:46,910
0,260 970,1260 1260,1455 1455,1650 1650,1920
world,| think it {Q9 -}
|想想作业一中的 Q9 Q10 。

220
00:06:46,910 --> 00:06:48,520
0,300 300,615 615,975 975,1275 1275,1610
{Q10 -} in homework #1.|
|

221
00:06:49,880 --> 00:06:52,140
0,260 260,760 1110,1475 1475,1970 1970,2260
So OLAP, the OLDP term
所以， OLTP 术语可以追溯到 80 年代，

222
00:06:52,760 --> 00:06:53,790
0,275 275,425 425,530 530,605 605,1030
goes back to the 80s,|
|

223
00:06:54,020 --> 00:06:55,855
0,400 690,1205 1205,1475 1475,1700 1700,1835
{} OLAP comes from the
OLAP 诞生于 90 年代，

224
00:06:55,855 --> 00:06:57,370
0,450 450,840 840,1110 1110,1290 1290,1515
90s,| {} this guy that
|这个叫 Jim Gray 的人是著名的数据库研究员，

225
00:06:57,370 --> 00:06:58,390
0,225 225,435 435,660 660,840 840,1020
named Jim Gray was famous

226
00:06:58,390 --> 00:07:00,085
0,255 255,735 735,1010 1240,1545 1545,1695
database researcher,| who invented a
|他发明了很多东西。当我们谈到这个学期时，

227
00:07:00,085 --> 00:07:00,715
0,120 120,270 270,420 420,540 540,630
lot of stuff, when we

228
00:07:00,715 --> 00:07:02,520
0,105 105,240 240,375 375,695 1405,1805
talk about this semester,| he
|他写了一篇文章说，

229
00:07:03,140 --> 00:07:04,510
0,305 305,485 485,760 840,1160 1160,1370
wrote an article saying,| hey,
|90 年代初出现了一种新的工作负载类别，称为 OLAP ，

230
00:07:04,510 --> 00:07:05,395
0,195 195,285 285,450 450,690 690,885
there's this new category of

231
00:07:05,395 --> 00:07:06,790
0,600 600,825 825,915 915,1050 1050,1395
workloads in the early 90s

232
00:07:06,790 --> 00:07:07,600
0,150 150,450 450,585 585,690 690,810
called OLAP| and we should
|我们应该注意它，

233
00:07:07,600 --> 00:07:10,090
0,150 150,375 375,555 555,800 2200,2490
pay attention to it,| turns
|事实证明，他从一家公司获得报酬，

234
00:07:10,090 --> 00:07:10,855
0,180 180,300 300,420 420,555 555,765
out he was actually getting

235
00:07:10,855 --> 00:07:12,010
0,365 385,675 675,810 810,990 990,1155
paid by a company| who
|这家公司在 90 年代初试图销售一种 OLAP 数据库系统产品，

236
00:07:12,010 --> 00:07:12,835
0,105 105,225 225,345 345,585 585,825
was trying to sell a

237
00:07:12,835 --> 00:07:13,930
0,150 150,330 330,570 570,840 840,1095
{OLAP -} database system product

238
00:07:13,930 --> 00:07:14,680
0,150 150,195 195,315 315,645 645,750
in the early 90s| and
|论文被撤回，但这个名字仍然存在，

239
00:07:14,680 --> 00:07:16,315
0,90 90,240 240,390 390,980 1390,1635
the paper got retracted, but

240
00:07:16,315 --> 00:07:17,370
0,105 105,300 300,540 540,750 750,1055
the name still stuck around,|
|

241
00:07:17,980 --> 00:07:19,000
0,195 195,420 420,705 705,885 885,1020
and then Jim Gray won
然后 Jim Gray 在 96 年获得了关于数据库的图灵奖，

242
00:07:19,000 --> 00:07:20,125
0,120 120,330 330,450 450,555 555,1125
the Turing Award in databases

243
00:07:20,125 --> 00:07:22,495
0,395 445,690 690,795 795,1355 2125,2370
in, I {think,96 -},| a
|他是一位非常著名的数据研究员，

244
00:07:22,495 --> 00:07:24,700
0,135 135,345 345,570 570,1145
very famous data researcher,|
|

245
00:07:25,240 --> 00:07:26,070
0,275 275,410 410,530 530,665 665,830
has anyone heard the story,
有人听说过这个故事吗，

246
00:07:26,070 --> 00:07:27,495
0,290 640,990 990,1185 1185,1290 1290,1425
{you,know},| {has,anyone} heard of Jim
|之前有人听说过 Jim Gray 吗，

247
00:07:27,495 --> 00:07:28,820
0,150 150,425
Gray before,|
|

248
00:07:30,490 --> 00:07:31,920
0,350 350,560 560,680 680,940 1050,1430
one, sort of guy,| so
一个，一个人，|他于 2006 年在旧金山湾的海上失踪是出了名的，

249
00:07:31,920 --> 00:07:33,390
0,270 270,825 825,1005 1005,1230 1230,1470
he famously got lost at

250
00:07:33,390 --> 00:07:34,485
0,300 300,525 525,630 630,810 810,1095
sea in the San Francisco

251
00:07:34,485 --> 00:07:36,465
0,240 240,375 375,1725 1725,1800 1800,1980
Bay in 2006,| {he,was} out
|他独自一人出海航行，

252
00:07:36,465 --> 00:07:37,605
0,360 360,555 555,870 870,1065 1065,1140
sailing by himself,| it was
|这不是一个玩笑，

253
00:07:37,605 --> 00:07:38,655
0,90 90,180 180,425 745,975 975,1050
not a joke,| he was
|他独自出海航行，他的船不见了，

254
00:07:38,655 --> 00:07:39,870
0,135 135,390 390,540 540,845 955,1215
out sailing by himself and

255
00:07:39,870 --> 00:07:42,540
0,260 340,735 735,1130 2230,2475 2475,2670
his boat disappeared,| and it's
|这是早期的[]搜寻的例子之一，

256
00:07:42,540 --> 00:07:43,160
0,135 135,210 210,270 270,360 360,620
actually one of the early

257
00:07:43,690 --> 00:07:45,105
0,335 335,560 560,770 770,1190 1190,1415
examples of [] searching,| because
|因为他们移动了卫星来拍摄旧金山湾的照片，

258
00:07:45,105 --> 00:07:47,130
0,240 240,435 435,630 630,1235 1765,2025
they actually moved satellites to

259
00:07:47,130 --> 00:07:48,225
0,180 180,500 550,810 810,930 930,1095
take pictures of the San

260
00:07:48,225 --> 00:07:49,190
0,240 240,450 450,600 600,720 720,965
Francisco Bay| and try to,
|人们查看图像，试图找到那艘船，

261
00:07:49,240 --> 00:07:49,965
0,230 230,305 305,470 470,635 635,725
you know, people look at

262
00:07:49,965 --> 00:07:50,640
0,75 75,255 255,450 450,540 540,675
the images, try to find

263
00:07:50,640 --> 00:07:51,740
0,225 225,405 405,650
the, the boat,|
|

264
00:07:51,740 --> 00:07:52,600
0,225 225,315 315,435 435,585 585,860
and they never found him,|
但他们一直没找到他，|

265
00:07:55,290 --> 00:07:56,890
0,260 260,520 930,1250 1250,1340 1340,1600
{all,right}, so that's a weird
好的，这太奇怪了，

266
00:07:57,150 --> 00:08:00,080
0,440 440,700 2370,2630 2630,2780 2780,2930
{}, but,| I never met
|我从来没见过他，但是很多，

267
00:08:00,080 --> 00:08:01,090
0,105 105,345 345,600 600,735 735,1010
him, but a lot of,|
|

268
00:08:01,650 --> 00:08:02,510
0,260 260,395 395,545 545,725 725,860
we talked about like, you
我们谈到的去冥王星，在你面前读书，

269
00:08:02,510 --> 00:08:03,395
0,135 135,315 315,450 450,720 720,885
know, going to Pluto versus

270
00:08:03,395 --> 00:08:04,340
0,285 285,510 510,615 615,795 795,945
reading, you know, reading the

271
00:08:04,340 --> 00:08:04,895
0,90 90,195 195,285 285,345 345,555
book in front of you,|
|

272
00:08:04,895 --> 00:08:05,555
0,225 225,315 315,435 435,540 540,660
you know, that was a
这是 Jim Gray 的比喻，

273
00:08:05,555 --> 00:08:06,635
0,240 240,480 480,615 615,975 975,1080
{Jim -} Gray metaphor,| he
|他有很多这样的有趣的事情。

274
00:08:06,635 --> 00:08:07,400
0,60 60,150 150,255 255,510 510,765
had a lot of interesting

275
00:08:07,400 --> 00:08:08,440
0,150 150,315 315,590
things like that.|
|

276
00:08:08,990 --> 00:08:09,730
0,245 245,380 380,545 545,650 650,740
So {HTAP -} would be
所以 HTAP 应该在中间，

277
00:08:09,730 --> 00:08:11,130
0,120 120,225 225,300 300,530 1000,1400
sort of the middle,| so,
|所以，今天我想花点时间谈谈，

278
00:08:11,270 --> 00:08:12,730
0,400 420,820 1020,1265 1265,1340 1340,1460
so today I want to

279
00:08:12,730 --> 00:08:15,720
0,195 195,435 435,735 735,1100
spend time talking about,|
|

280
00:08:16,070 --> 00:08:17,035
0,320 320,485 485,605 605,755 755,965
why the things we talked
为什么到目前为止，我们在前两节课中谈到的东西，

281
00:08:17,035 --> 00:08:18,310
0,330 330,630 630,900 900,1125 1125,1275
about so far in the

282
00:08:18,310 --> 00:08:19,930
0,290 310,615 615,765 765,1160 1300,1620
the previous two lectures,| they're
|它们将有利于 OLTP 而不是 OLAP ，

283
00:08:19,930 --> 00:08:20,785
0,90 90,180 180,285 285,560 610,855
gonna be good for for

284
00:08:20,785 --> 00:08:22,360
0,420 420,585 585,720 720,1205 1315,1575
OLTP and not OLAP| and
|然后我们将设计一个更适合 OLAP 的存储方案。

285
00:08:22,360 --> 00:08:24,420
0,135 135,390 390,705 705,1100 1660,2060
then we'll design a, a

286
00:08:24,770 --> 00:08:25,660
0,320 320,500 500,605 605,725 725,890
storage scheme, that is better

287
00:08:25,660 --> 00:08:26,820
0,135 135,500
for OLAP.|
|

288
00:08:27,980 --> 00:08:28,735
0,245 245,335 335,455 455,605 605,755
So to do this,| we're
为了做到这一点，|我们将使用一个真实的数据库来做一个非常简单的示例，

289
00:08:28,735 --> 00:08:29,245
0,45 45,135 135,240 240,345 345,510
going to do a real

290
00:08:29,245 --> 00:08:31,315
0,300 300,695 715,1050 1050,1385 1795,2070
simple {} example, using a

291
00:08:31,315 --> 00:08:33,270
0,275 505,905 1285,1545 1545,1680 1680,1955
real database.| so this is,
|所以这大概就是维基百科数据库的样子，

292
00:08:33,290 --> 00:08:35,260
0,400 810,1055 1055,1265 1265,1610 1610,1970
{} this is roughly what

293
00:08:35,260 --> 00:08:38,040
0,255 255,980 1720,2055 2055,2280 2280,2780
the Wikipedia database looks like,|
|

294
00:08:38,180 --> 00:08:39,040
0,260 260,395 395,530 530,695 695,860
it runs a software called
它运行着一个名为 MediaWiki 的软件，

295
00:08:39,040 --> 00:08:40,480
0,180 180,650 670,945 945,1185 1185,1440
{MediaWiki -},| it runs off
|它运行在 MySQL 和 PHP 上，

296
00:08:40,480 --> 00:08:42,480
0,120 120,240 240,710 1210,1500 1500,2000
of {MySQL -} and PHP,|
|

297
00:08:42,560 --> 00:08:43,450
0,380 380,530 530,695 695,830 830,890
it's open source, you can
它是开源的，你可以去看看它，

298
00:08:43,450 --> 00:08:44,515
0,105 105,255 255,390 390,650 760,1065
go look at it| and
|[模式]大概是这样的，

299
00:08:44,515 --> 00:08:46,320
0,305
the,

300
00:08:46,320 --> 00:08:47,745
0,195 195,405 405,855 855,1200 1200,1425
the, the schema roughly looks

301
00:08:47,745 --> 00:08:49,035
0,150 150,425 715,1005 1005,1185 1185,1290
like this, right,| there'll be
|有 useracct ，那些进行修改的人，

302
00:08:49,035 --> 00:08:50,505
0,255 255,635 985,1260 1260,1350 1350,1470
{useracct -}, people that are

303
00:08:50,505 --> 00:08:52,095
0,150 150,315 315,635 1165,1455 1455,1590
actually making changes,| there'll be
|有 pages ，就像维基百科上的文章，

304
00:08:52,095 --> 00:08:53,250
0,305 325,600 600,720 720,930 930,1155
pages, like the articles in

305
00:08:53,250 --> 00:08:54,945
0,680 910,1200 1200,1395 1395,1590 1590,1695
Wikipedia,| and then there'll be
|然后有 revisions ，对于那些文章，

306
00:08:54,945 --> 00:08:57,090
0,405 405,645 645,905 1045,1445 1885,2145
revisions for those articles,| and
|这里 revision 有一个外键引用，

307
00:08:57,090 --> 00:08:57,705
0,105 105,240 240,330 330,465 465,615
so there's a foreign {}

308
00:08:57,705 --> 00:08:58,760
0,165 165,420 420,615 615,705 705,1055
key reference for a revision,|
|

309
00:08:59,020 --> 00:08:59,880
0,245 245,350 350,470 470,650 650,860
you have the user that
你有创建更改的用户，

310
00:08:59,880 --> 00:09:01,040
0,180 180,330 330,590 640,900 900,1160
created the change| and then
|然后是页面本身的 ID ，

311
00:09:01,990 --> 00:09:03,590
0,245 245,490 570,965 965,1280 1280,1600
an ID to the actual

312
00:09:05,320 --> 00:09:06,660
0,380 380,760
page itself,|
|

313
00:09:06,730 --> 00:09:07,800
0,230 230,380 380,575 575,815 815,1070
but all the text itself
但所有的文本本身都将在 revision 部分，

314
00:09:07,800 --> 00:09:08,490
0,150 150,255 255,330 330,495 495,690
is going to go in

315
00:09:08,490 --> 00:09:09,720
0,90 90,375 375,710
the revision part,|
|

316
00:09:11,430 --> 00:09:12,950
0,260 260,485 485,710 710,940 1230,1520
and there's, there's a, there's
这里有一个外键从 page 回到 revision ，

317
00:09:12,950 --> 00:09:13,760
0,90 90,255 255,420 420,585 585,810
a foreign key going back

318
00:09:13,760 --> 00:09:15,200
0,210 210,480 480,810 810,1200 1200,1440
from page to revision,| so,
|所以，你可以找到最新的版本。

319
00:09:15,200 --> 00:09:15,910
0,135 135,195 195,285 285,420 420,710
so you can find the

320
00:09:16,110 --> 00:09:17,520
0,305 305,730
latest revision.|
|

321
00:09:18,970 --> 00:09:19,950
0,230 230,350 350,485 485,695 695,980
So I said this before,
我在之前已经说过了，

322
00:09:19,950 --> 00:09:21,420
0,240 240,405 405,525 525,800 1210,1470
I say it again,| the
|关系模型并没有定义或指定，

323
00:09:21,420 --> 00:09:23,690
0,330 330,710 1000,1305 1305,1610 1870,2270
relational model does not define

324
00:09:23,710 --> 00:09:26,240
0,305 305,880 1170,1570
or specify that,|
|

325
00:09:26,580 --> 00:09:27,605
0,260 260,470 470,710 710,860 860,1025
anything about how we should
关于我们应该如何将数据存储在表中，

326
00:09:27,605 --> 00:09:28,805
0,180 180,315 315,575 685,1005 1005,1200
store the data in a

327
00:09:28,805 --> 00:09:30,425
0,275 925,1260 1260,1425 1425,1485 1485,1620
table, right,| so in all
|所以在我目前为止展示的所有例子中，

328
00:09:30,425 --> 00:09:31,385
0,195 195,390 390,630 630,780 780,960
the examples I've shown so

329
00:09:31,385 --> 00:09:32,555
0,275 385,675 675,780 780,975 975,1170
far,| we're just showing the
|我们只是展示 tuple ，

330
00:09:32,555 --> 00:09:34,070
0,275 445,750 750,1035 1035,1305 1305,1515
tuple,| every tuple, all the
|每个 tuple ，所有一个接一个的属性，

331
00:09:34,070 --> 00:09:35,420
0,270 270,420 420,600 600,920 1060,1350
attributes one after another,| yes,
|是的，我们说过大型属性有溢出页面，

332
00:09:35,420 --> 00:09:36,290
0,150 150,270 270,375 375,480 480,870
we said there was overflow

333
00:09:36,290 --> 00:09:38,200
0,270 270,525 525,780 780,1250 1510,1910
pages for large attributes,| but
|但是，通常所有较小的属性都存储在一起，

334
00:09:38,970 --> 00:09:41,420
0,245 245,350 350,610 1860,2180 2180,2450
you know that in general

335
00:09:41,420 --> 00:09:43,430
0,285 285,620 700,1005 1005,1310 1570,2010
all all the smaller attributes

336
00:09:43,430 --> 00:09:44,930
0,270 270,560 880,1125 1125,1275 1275,1500
store together,| but there's nothing
|但是，关系模型并没有说你必须这样做，

337
00:09:44,930 --> 00:09:46,010
0,330 330,525 525,600 600,810 810,1080
about, again, the relational model

338
00:09:46,010 --> 00:09:46,865
0,225 225,375 375,540 540,705 705,855
says you have to do

339
00:09:46,865 --> 00:09:48,065
0,195 195,515 745,990 990,1065 1065,1200
that,| just sort of what
|只是我们作为人类最先想到的东西，

340
00:09:48,065 --> 00:09:48,905
0,180 180,330 330,540 540,720 720,840
we as humans came up

341
00:09:48,905 --> 00:09:49,820
0,165 165,375 375,600 600,750 750,915
with first,| it's easy for
|我们很容易从概念上思考。

342
00:09:49,820 --> 00:09:50,950
0,105 105,255 255,645 645,825 825,1130
us to conceptually think about.|
|

343
00:09:51,870 --> 00:09:53,450
0,305 305,560 560,770 770,1115 1115,1580
But again, for OLAP workloads,|
但是，对于 OLAP 工作负载而言，|

344
00:09:53,450 --> 00:09:54,485
0,150 150,330 330,525 525,810 810,1035
this may not be the
这可能不是最好的选择。

345
00:09:54,485 --> 00:09:55,700
0,165 165,485
best thing.|
|

346
00:09:55,870 --> 00:09:56,685
0,245 245,425 425,560 560,710 710,815
So let's see how it
那么让我们来看看它是如何为 OLTP 工作的，

347
00:09:56,685 --> 00:09:59,235
0,150 150,455 805,1475 1705,2105 2275,2550
works for OLTP, right,| again
|对于 OLTP ，它将是一堆小查询，

348
00:09:59,235 --> 00:10:00,120
0,120 120,600 600,795 795,840 840,885
for OLTP, it's going to

349
00:10:00,120 --> 00:10:01,020
0,90 90,195 195,285 285,530 610,900
be a bunch of small

350
00:10:01,020 --> 00:10:02,200
0,440
queries,|
|

351
00:10:02,410 --> 00:10:03,705
0,305 305,485 485,760 930,1250 1250,1295
that are going, it's going
这将是非常简单的大量查询，

352
00:10:03,705 --> 00:10:04,155
0,30 30,75 75,165 165,315 315,450
to be a lot of

353
00:10:04,155 --> 00:10:04,725
0,300 300,405 405,465 465,525 525,570
queries that are going to

354
00:10:04,725 --> 00:10:06,135
0,75 75,255 255,575 895,1200 1200,1410
be really simple| and they're
|它们将读取或写入少量数据，

355
00:10:06,135 --> 00:10:07,230
0,60 60,305 325,645 645,855 855,1095
going to read or write

356
00:10:07,230 --> 00:10:08,450
0,350 370,675 675,825 825,945 945,1220
a small amount of data|
|

357
00:10:08,530 --> 00:10:10,065
0,395 395,695 695,1000 1080,1355 1355,1535
relative to all the data
相对于数据库中的所有数据。

358
00:10:10,065 --> 00:10:11,400
0,150 150,255 255,515
in the database

359
00:10:11,410 --> 00:10:12,450
0,335 335,515 515,620 620,785 785,1040
right.| So the first query
|这里的第一个查询将是获取，

360
00:10:12,450 --> 00:10:13,610
0,255 255,450 450,585 585,810 810,1160
here is just going get

361
00:10:13,690 --> 00:10:15,375
0,400 840,1085 1085,1175 1175,1355 1355,1685
the,| for a given page,
|对于给定页面，给出它的 pageID ，

362
00:10:15,375 --> 00:10:17,115
0,390 390,660 660,810 810,1085 1435,1740
given its {pageID -},| go
|为我获取它的最新版本，

363
00:10:17,115 --> 00:10:18,540
0,180 180,455 715,975 975,1125 1125,1425
get me the latest revision

364
00:10:18,540 --> 00:10:19,875
0,180 180,440 550,855 855,1050 1050,1335
for it,| so to JOIN
|所以，对 revision 表做 JOIN ，

365
00:10:19,875 --> 00:10:21,255
0,255 255,360 360,615 615,965 1135,1380
against the revision table,| but
|但它只有一页和一个版本，

366
00:10:21,255 --> 00:10:22,560
0,165 165,360 360,695 865,1140 1140,1305
it's one page and one

367
00:10:22,560 --> 00:10:25,100
0,380 970,1290 1290,1590 1590,1850
revision,| it's retrieving that.|
|它获取的。|

368
00:10:25,100 --> 00:10:26,255
0,165 165,315 315,480 480,740 850,1155
The next one is the
下一个是更新查询，

369
00:10:26,255 --> 00:10:27,305
0,165 165,330 330,465 465,660 660,1050
UPDATE query,| is somebody {login
|有人在登录吗，

370
00:10:27,305 --> 00:10:28,580
0,275 535,855 855,1020 1020,1110 1110,1275
-},| you have a {userID
|你有一个 userID ，假设他们已经过身份验证，

371
00:10:28,580 --> 00:10:30,370
0,320 610,900 900,1065 1065,1215 1215,1790
-}, assuming they've been authenticated|
|

372
00:10:30,630 --> 00:10:32,045
0,305 305,560 560,910 930,1205 1205,1415
and you update the user
你更新用户账户，

373
00:10:32,045 --> 00:10:33,680
0,270 270,605 775,1125 1125,1560 1560,1635
account,| with the timestamp at
|使用他们最后一次登录的时间戳，

374
00:10:33,680 --> 00:10:34,415
0,75 75,210 210,360 360,480 480,735
the last time they {login

375
00:10:34,415 --> 00:10:35,420
0,240 240,525 525,660 660,810 810,1005
-}| and the {hostname -}
|和他们登录的主机名。

376
00:10:35,420 --> 00:10:36,170
0,150 150,285 285,435 435,630 630,750
from where they {login -}

377
00:10:36,170 --> 00:10:37,445
0,290 760,990 990,1050 1050,1155 1155,1275
from.| Or if I do
|或者，如果我在 revision 表中执行 INSERT ，

378
00:10:37,445 --> 00:10:38,255
0,90 90,405 405,510 510,600 600,810
an INSERT into the revision

379
00:10:38,255 --> 00:10:40,145
0,270 270,645 645,1025 1105,1710 1710,1890
table,| it's, it's inserting a
|它会插入一行。

380
00:10:40,145 --> 00:10:42,020
0,195 195,515 775,1175
single row, right.|
|

381
00:10:42,310 --> 00:10:43,350
0,305 305,485 485,620 620,770 770,1040
And this is what usually
这通常是人们得到的结果，

382
00:10:43,350 --> 00:10:44,205
0,285 285,465 465,600 600,735 735,855
people end up with,| when
|当他们在构建一个全新的应用程序时，

383
00:10:44,205 --> 00:10:44,910
0,120 120,255 255,360 360,480 480,705
they build a brand new

384
00:10:44,910 --> 00:10:46,095
0,350 580,825 825,915 915,1080 1080,1185
application,| like if you're, if
|比如，如果你要创建一家初创公司，

385
00:10:46,095 --> 00:10:47,205
0,285 285,510 510,735 735,975 975,1110
you're, you know, if you're

386
00:10:47,205 --> 00:10:47,960
0,45 45,120 120,210 210,330 330,755
going to create a startup|
|

387
00:10:48,040 --> 00:10:49,170
0,245 245,395 395,590 590,860 860,1130
and you start building some
你开始构建一些在线服务，

388
00:10:49,170 --> 00:10:50,970
0,270 270,650 1060,1350 1350,1590 1590,1800
online service,| you usually end
|你通常会得到这样的结果，

389
00:10:50,970 --> 00:10:51,855
0,135 135,330 330,570 570,750 750,885
up with something that looks

390
00:10:51,855 --> 00:10:53,250
0,165 165,435 435,815 985,1230 1230,1395
like this,| because you don't
|因为你一开始没有任何数据，

391
00:10:53,250 --> 00:10:54,030
0,105 105,285 285,495 495,645 645,780
have any data in the

392
00:10:54,030 --> 00:10:55,260
0,290 610,870 870,990 990,1095 1095,1230
beginning,| you need to get
|你需要得到它，

393
00:10:55,260 --> 00:10:56,400
0,240 240,590 700,945 945,1050 1050,1140
it| and you make a
|你做了一个网站，

394
00:10:56,400 --> 00:10:57,675
0,230 280,540 540,800 850,1110 1110,1275
website| and then your website
|然后你的网站会运行这些查询。

395
00:10:57,675 --> 00:10:58,440
0,150 150,240 240,420 420,630 630,765
is going to run these

396
00:10:58,440 --> 00:11:01,590
0,105 105,180 180,590 2740,3015 3015,3150
kind of queries.| And for
|而对于 OLAP ，我们将做更复杂的事情，

397
00:11:01,590 --> 00:11:02,340
0,375 375,555 555,600 600,660 660,750
OLAP, we're going to do

398
00:11:02,340 --> 00:11:04,815
0,120 120,380 400,800 1300,1700 2170,2475
more complicated things,| that require
|需要我们查看表的更大部分，

399
00:11:04,815 --> 00:11:06,105
0,165 165,285 285,435 435,725 895,1290
us to look at larger

400
00:11:06,105 --> 00:11:08,370
0,510 510,825 825,1080 1080,1355 2005,2265
portions of the table,| so
|这是真实查询的粗略近似值，

401
00:11:08,370 --> 00:11:10,260
0,120 120,315 315,650 940,1340 1570,1890
this is actually a rough

402
00:11:10,260 --> 00:11:11,780
0,560 610,855 855,975 975,1170 1170,1520
approximation of a real query,|
|

403
00:11:11,800 --> 00:11:14,210
0,400 1110,1445 1445,1670 1670,1960 2010,2410
where people were running, {}|
当人们运行，|

404
00:11:15,010 --> 00:11:16,005
0,365 365,620 620,755 755,860 860,995
{} you, you would look
你看一下维基百科的用户账号，

405
00:11:16,005 --> 00:11:16,935
0,135 135,255 255,465 465,735 735,930
at the user accounts in

406
00:11:16,935 --> 00:11:18,810
0,695 865,1110 1110,1260 1260,1530 1530,1875
Wikipedia| and you find all
|你会发现所有来自用户的登录尝试，

407
00:11:18,810 --> 00:11:21,590
0,345 345,710 820,1460 1510,1910 2380,2780
the, the login attempts from,

408
00:11:21,970 --> 00:11:23,820
0,320 320,640 750,1150 1470,1730 1730,1850
from users| that had an
|有 IP 地址或主机名以 .gov 结尾，

409
00:11:23,820 --> 00:11:24,900
0,260 280,600 600,780 780,900 900,1080
IP address or a {hostname

410
00:11:24,900 --> 00:11:26,085
0,320 400,660 660,810 810,975 975,1185
-} that ended with {.gov

411
00:11:26,085 --> 00:11:27,540
0,515 925,1215 1215,1350 1350,1410 1410,1455
-}, right,| because it was
|因为，有一起丑闻发生在 2000 年代末，2010 年代初，

412
00:11:27,540 --> 00:11:28,155
0,75 75,225 225,375 375,465 465,615
like a, there was a

413
00:11:28,155 --> 00:11:30,135
0,515 775,1065 1065,1215 1215,1475 1675,1980
scandal late {2000s -}, early

414
00:11:30,135 --> 00:11:31,790
0,255 255,390 390,600 600,935 1255,1655
{2010s - -},| where like
|国会里的人让他们的工作人员更新维基百科，

415
00:11:32,080 --> 00:11:33,210
0,275 275,440 440,710 710,950 950,1130
people in congress were having

416
00:11:33,210 --> 00:11:35,180
0,255 255,590 610,975 975,1245 1245,1970
their staff go update Wikipedia|
|

417
00:11:35,320 --> 00:11:36,660
0,275 275,485 485,725 725,1100 1100,1340
to say more flattering things
对国会议员或国会女议员说更多恭维的话，

418
00:11:36,660 --> 00:11:38,510
0,350 430,690 690,1065 1065,1170 1170,1850
about the congressman or congresswoman|
|

419
00:11:39,100 --> 00:11:40,365
0,305 305,545 545,725 725,995 995,1265
like Pence did this, Joe
比如 Pence 做了这个， Joe Biden 做了这个，

420
00:11:40,365 --> 00:11:42,240
0,300 300,405 405,600 600,935 1645,1875
Biden did this, right,| so
|所以，这个查询可以找到执行这个操作的所有人，

421
00:11:42,240 --> 00:11:43,215
0,120 120,375 375,555 555,750 750,975
this query could find all

422
00:11:43,215 --> 00:11:44,085
0,240 240,465 465,585 585,720 720,870
people that were doing that,|
|

423
00:11:44,085 --> 00:11:45,285
0,150 150,425 445,720 720,915 915,1200
so basically were paying government
所以，基本上是付钱让政府雇员更新维基百科，

424
00:11:45,285 --> 00:11:46,600
0,315 315,510 510,755
employees to go

425
00:11:46,700 --> 00:11:48,685
0,275 275,940 1470,1715 1715,1820 1925,1985
update Wikipedia,| and they shouldn't
|他们不应该这么做。

426
00:11:48,685 --> 00:11:49,560
0,215
have.|
|

427
00:11:49,720 --> 00:11:51,075
0,400 420,680 680,830 830,1010 1010,1355
Again, so this is queries
这个我们要在数据上执行的查询，

428
00:11:51,075 --> 00:11:51,855
0,120 120,165 165,360 360,600 600,780
we're going to execute on

429
00:11:51,855 --> 00:11:53,175
0,255 255,555 555,795 795,1005 1005,1320
data| after we've already collected
|在应用程序的 OLTP 部分收集数据后。

430
00:11:53,175 --> 00:11:54,885
0,335 565,965 1165,1470 1470,1620 1620,1710
it from, from sort of

431
00:11:54,885 --> 00:11:55,740
0,75 75,225 225,495 495,690 690,855
the {OLTP -} portion of

432
00:11:55,740 --> 00:11:57,280
0,240 240,620
the application.|
|

433
00:11:59,270 --> 00:12:00,280
0,400 420,680 680,800 800,905 905,1010
So the thing we need
所以我们现在要谈的是，

434
00:12:00,280 --> 00:12:01,320
0,165 165,330 330,465 465,690 690,1040
to talk about now is,|
|

435
00:12:02,000 --> 00:12:02,935
0,245 245,395 395,560 560,755 755,935
what I'll call the, the,
我所说的存储模型，

436
00:12:02,935 --> 00:12:04,975
0,255 255,585 585,965 1585,1860 1860,2040
the storage model,| and this
|这将是，

437
00:12:04,975 --> 00:12:06,685
0,305 385,660 660,810 810,1085 1345,1710
is going to be,| how
|数据库系统如何在物理上组织 tuple 在磁盘和内存中，

438
00:12:06,685 --> 00:12:07,510
0,225 225,405 405,600 600,735 735,825
the database system is going

439
00:12:07,510 --> 00:12:09,625
0,120 120,410 520,975 975,1460 1750,2115
to physically organize tuples in,

440
00:12:09,625 --> 00:12:10,620
0,270 270,585 585,645 645,735 735,995
in disk and in memory|
|

441
00:12:11,300 --> 00:12:13,690
0,400 720,1120 1230,1630 1800,2120 2120,2390
relative to their other tuples
相对于它们各自的属性中的其他 tuple 。

442
00:12:13,690 --> 00:12:15,280
0,105 105,195 195,435 435,920
in their own attributes.|
|

443
00:12:15,280 --> 00:12:16,945
0,320 760,1035 1035,1185 1185,1410 1410,1665
{} And so up until
到目前为止，

444
00:12:16,945 --> 00:12:18,310
0,305 475,750 750,900 900,1065 1065,1365
now,| again, I've been assuming
|我假设所有的属性对于 tuple 来说都是连续的，

445
00:12:18,310 --> 00:12:19,405
0,210 210,420 420,615 615,810 810,1095
that all of the attributes

446
00:12:19,405 --> 00:12:20,640
0,150 150,600 600,705 705,795 795,1235
are contiguous for a tuple|
|

447
00:12:21,050 --> 00:12:22,015
0,290 290,545 545,635 635,740 740,965
and that's sort of roughly
这叫做行存储，

448
00:12:22,015 --> 00:12:25,090
0,365 655,945 945,1170 1170,1505 2785,3075
called a row store,| but
|但是，对于 OLAP ，这可能不是最好的事情，

449
00:12:25,090 --> 00:12:26,860
0,270 270,650 670,990 990,1310 1510,1770
again, for OLAP, that actually

450
00:12:26,860 --> 00:12:27,600
0,120 120,255 255,390 390,495 495,740
may not be the best

451
00:12:27,620 --> 00:12:29,290
0,400 660,1010 1010,1280 1280,1415 1415,1670
thing,| and we'll see why
|我们很快就会知道为什么。

452
00:12:29,290 --> 00:12:30,660
0,240 240,360 360,620
in a second.|
|

453
00:12:30,730 --> 00:12:31,440
0,245 245,320 320,455 455,620 620,710
And the reason why we
我们之所以要讨论系统的这一部分，

454
00:12:31,440 --> 00:12:32,910
0,75 75,225 225,495 495,860 1210,1470
have to discuss this part

455
00:12:32,910 --> 00:12:34,455
0,90 90,180 180,420 420,800 1270,1545
of a system,| because there
|因为在数据库世界现在的市场中，存在明显的区别，

456
00:12:34,455 --> 00:12:35,790
0,195 195,435 435,660 660,1095 1095,1335
is a clear distinction in

457
00:12:35,790 --> 00:12:37,320
0,120 120,380 400,800 850,1215 1215,1530
the marketplace now in, in,

458
00:12:37,320 --> 00:12:39,050
0,350 370,720 720,915 915,1160 1330,1730
in, in the database world|
|

459
00:12:39,400 --> 00:12:40,620
0,275 275,440 440,665 665,920 920,1220
between a row store system
在行存储系统和列存储系统之间，

460
00:12:40,620 --> 00:12:41,690
0,225 225,345 345,570 570,795 795,1070
and a column store system,|
|

461
00:12:41,980 --> 00:12:42,990
0,245 245,365 365,575 575,800 800,1010
like a row store system,
对于行存储系统，你想要将其用于 OLTP ，

462
00:12:42,990 --> 00:12:43,830
0,255 255,360 360,480 480,645 645,840
you'd want to use that

463
00:12:43,830 --> 00:12:45,510
0,165 165,770 1120,1440 1440,1590 1590,1680
for OLTP| and for a
|对于列存储系统，你想要将其用于 OLAP ，

464
00:12:45,510 --> 00:12:46,560
0,210 210,435 435,660 660,945 945,1050
column store system, you'd want

465
00:12:46,560 --> 00:12:47,810
0,90 90,195 195,420 420,735 735,1250
to use that for OLAP.|
|

466
00:12:47,950 --> 00:12:49,110
0,245 245,440 440,725 725,980 980,1160
And if anybody tries to
如果有人试图说，

467
00:12:49,110 --> 00:12:49,785
0,135 135,300 300,420 420,510 510,675
say,| hey, I have a
|嘿，我有一个快速的行存储，你可以用来进行分析，

468
00:12:49,785 --> 00:12:51,825
0,305 1225,1560 1560,1815 1815,1965 1965,2040
fast row store that you

469
00:12:51,825 --> 00:12:53,745
0,75 75,180 180,285 285,815 1675,1920
can use for analytics,| you
|你应该非常怀疑。

470
00:12:53,745 --> 00:12:54,480
0,165 165,360 360,465 465,555 555,735
know, you should be very

471
00:12:54,480 --> 00:12:55,620
0,560
skeptical.|
|

472
00:12:56,130 --> 00:12:56,990
0,290 290,410 410,500 500,650 650,860
{All,right}, so the three choices
好的，三个选择是，

473
00:12:56,990 --> 00:12:58,415
0,165 165,360 360,705 705,1100 1180,1425
to do are| the the
|N-ary 存储模型或 NSM ，这是行存储，

474
00:12:58,415 --> 00:13:00,130
0,225 225,525 525,845 955,1215 1215,1715
N-ary Storage Model or NSM,

475
00:13:00,330 --> 00:13:02,240
0,350 350,440 440,635 635,970 1170,1910
that's the row store,| Decomposition
|分解存储模型， DSM ，这是列存储，

476
00:13:02,240 --> 00:13:03,950
0,285 285,620 730,1320 1320,1620 1620,1710
Storage Model, DSM, that's the

477
00:13:03,950 --> 00:13:05,285
0,210 210,560 730,1005 1005,1170 1170,1335
column store| and then a
|然后是混合方法，这是列存储最常见的方法，

478
00:13:05,285 --> 00:13:06,380
0,345 345,570 570,810 810,990 990,1095
hybrid approach is actually, this

479
00:13:06,380 --> 00:13:07,190
0,120 120,210 210,345 345,570 570,810
is the most common one

480
00:13:07,190 --> 00:13:08,510
0,240 240,495 495,765 765,1065 1065,1320
for column stores,| well, we'll
|我们一会儿就会知道原因，

481
00:13:08,510 --> 00:13:09,070
0,90 90,180 180,240 240,315 315,560
see why in a second,|
|

482
00:13:09,510 --> 00:13:11,320
0,320 320,550 810,1265 1265,1400 1400,1810
it's called PAX or partition
它被称为 PAX 或分区属性访问，

483
00:13:11,340 --> 00:13:13,955
0,365 365,670 1920,2210 2210,2420 2420,2615
attribute across,| and most time
|大多数时候，人们说他们有一个列存储，

484
00:13:13,955 --> 00:13:14,570
0,180 180,345 345,435 435,510 510,615
people say they have a

485
00:13:14,570 --> 00:13:15,970
0,210 210,560 580,870 870,1080 1080,1400
column store,| they really have
|他们有的是 PAX ，

486
00:13:16,020 --> 00:13:17,420
0,275 275,575 575,850 900,1145 1145,1400
the PAX one,| but it's,
|但这不是很大的区别。

487
00:13:17,420 --> 00:13:20,375
0,255 255,500 1810,2235 2235,2625 2625,2955
it's a, it's, it's, it's

488
00:13:20,375 --> 00:13:21,575
0,120 120,270 270,480 480,815 895,1200
not a major, major, major

489
00:13:21,575 --> 00:13:23,360
0,305
difference.|
|

490
00:13:24,570 --> 00:13:25,235
0,290 290,365 365,440 440,530 530,665
Let's start with the first
让我们从第一个开始， NSM 行存储，

491
00:13:25,235 --> 00:13:26,740
0,255 255,570 570,1020 1020,1215 1215,1505
one, the NSM row store,|
|

492
00:13:27,270 --> 00:13:28,625
0,290 290,425 425,670 870,1145 1145,1355
again, this is what we've
这是我们本学期到目前为止已经说过的内容，

493
00:13:28,625 --> 00:13:29,435
0,165 165,330 330,495 495,675 675,810
already said so far this

494
00:13:29,435 --> 00:13:31,385
0,305 655,975 975,1245 1245,1595 1675,1950
semester,| we assume that almost
|我们假设给定 tuple 的几乎所有属性

495
00:13:31,385 --> 00:13:32,405
0,210 210,480 480,780 780,930 930,1020
all the attributes for a

496
00:13:32,405 --> 00:13:33,230
0,150 150,540 540,705 705,780 780,825
given tuple| are going to
|都连续存储在一个页面中，

497
00:13:33,230 --> 00:13:34,190
0,75 75,315 315,780 780,870 870,960
be stored continuously in a

498
00:13:34,190 --> 00:13:36,100
0,180 180,500 850,1095 1095,1340 1510,1910
single page,| you know, one
|一个接一个，

499
00:13:36,450 --> 00:13:37,720
0,335 335,670
after another,|
|

500
00:13:37,720 --> 00:13:38,410
0,165 165,300 300,435 435,555 555,690
and the idea is,| again,
我们的想法是，|你要在页面上，

501
00:13:38,410 --> 00:13:39,415
0,150 150,360 360,690 690,885 885,1005
you're going across in the

502
00:13:39,415 --> 00:13:40,465
0,255 255,465 465,615 615,780 780,1050
page| and you're laying out
|放置给定 tuple 的所有数据，

503
00:13:40,465 --> 00:13:41,380
0,240 240,420 420,555 555,750 750,915
all the the data for

504
00:13:41,380 --> 00:13:42,325
0,60 60,195 195,375 375,650 700,945
a given {tuple -}| and
|你不会开始任何东西，

505
00:13:42,325 --> 00:13:43,525
0,105 105,330 330,600 600,975 975,1200
you don't start anything,| you
|你不会为下一个 tuple 放下任何比特，

506
00:13:43,525 --> 00:13:44,440
0,225 225,315 315,585 585,795 795,915
don't, you don't lay down

507
00:13:44,440 --> 00:13:45,265
0,180 180,420 420,585 585,675 675,825
any bits for the next

508
00:13:45,265 --> 00:13:46,105
0,165 165,345 345,510 510,615 615,840
{tuple -}| until you finish
|直到你完成当前的 tuple 。

509
00:13:46,105 --> 00:13:48,260
0,365 565,840 840,1020 1020,1445
the the current tuple.|
|

510
00:13:48,730 --> 00:13:49,590
0,245 245,350 350,530 530,725 725,860
And the reason why this
这对于 OLTP 系统来说会更好的原因，

511
00:13:49,590 --> 00:13:50,265
0,150 150,270 270,345 345,465 465,675
is going to be better

512
00:13:50,265 --> 00:13:51,440
0,165 165,240 240,615 615,840 840,1175
for an OLTP system,| as
|正如我之前已经说过的，

513
00:13:51,670 --> 00:13:53,160
0,260 260,410 410,560 560,820 960,1490
I already said before,| OLTP
|OLTP 应用程序是，

514
00:13:53,160 --> 00:13:54,780
0,270 270,480 480,740
application is that,|
|

515
00:13:54,970 --> 00:13:55,995
0,335 335,515 515,620 620,935 935,1025
most of the queries are
大多数查询将访问单个条目或单个 tuple ，

516
00:13:55,995 --> 00:13:56,835
0,75 75,135 135,315 315,675 675,840
going to be accessing a

517
00:13:56,835 --> 00:13:58,370
0,305 325,570 570,720 720,1005 1005,1535
single entry or single tuple,

518
00:13:59,160 --> 00:14:00,905
0,400 690,980 980,1205 1205,1505 1505,1745
right,| and so now I
|现在，我可以转到一个页面，

519
00:14:00,905 --> 00:14:01,625
0,135 135,300 300,420 420,510 510,720
can go to a single

520
00:14:01,625 --> 00:14:02,720
0,300 300,540 540,690 690,900 900,1095
page| and get all the
|获取单一属性所需的所有数据，

521
00:14:02,720 --> 00:14:03,665
0,165 165,345 345,570 570,780 780,945
data I need for that

522
00:14:03,665 --> 00:14:05,570
0,270 270,665 715,960 960,1740 1740,1905
single attribute,| and that's really
|这就是我满足该查询所需的全部数据。

523
00:14:05,570 --> 00:14:07,055
0,165 165,300 300,560 640,1020 1020,1485
all I need to satisfy

524
00:14:07,055 --> 00:14:08,100
0,165 165,485
that query.|
|

525
00:14:08,930 --> 00:14:09,775
0,260 260,395 395,530 530,680 680,845
We already talk about page
我们已经谈到了页面大小，

526
00:14:09,775 --> 00:14:10,735
0,285 285,540 540,660 660,840 840,960
sizes,| but again, it's always
|但是，它总是硬件页面的倍数。

527
00:14:10,735 --> 00:14:12,595
0,150 150,425 745,1145 1375,1665 1665,1860
been some multiple of hardware

528
00:14:12,595 --> 00:14:13,940
0,305
pages.|
|

529
00:14:14,280 --> 00:14:15,290
0,245 245,365 365,515 515,770 770,1010
So this is basically the
所以这基本上是我们之前看到的相同的布局，

530
00:14:15,290 --> 00:14:16,055
0,165 165,420 420,525 525,630 630,765
same layout that we saw

531
00:14:16,055 --> 00:14:17,915
0,275 655,1055 1255,1560 1560,1725 1725,1860
before, right,| that we have
|我们有一些数据库页面，

532
00:14:17,915 --> 00:14:19,280
0,150 150,405 405,785 1045,1290 1290,1365
some database page,| we have
|我们在前面有一个 header ，接着 slot array ，

533
00:14:19,280 --> 00:14:19,970
0,90 90,270 270,345 345,465 465,690
a header in the front,

534
00:14:19,970 --> 00:14:21,460
0,315 315,540 540,855 855,1185 1185,1490
with the slot, slot array,|
|

535
00:14:21,810 --> 00:14:23,465
0,290 290,580 630,1030 1050,1385 1385,1655
and then as we start
然后，当我们开始扫描我们的表，

536
00:14:23,465 --> 00:14:24,575
0,330 330,435 435,555 555,840 840,1110
scanning through our table and

537
00:14:24,575 --> 00:14:26,420
0,120 120,225 225,1125 1125,1385 1525,1845
want to {start,or,scanning} through,| the
|开始插入数据的应用程序，

538
00:14:26,420 --> 00:14:27,700
0,225 225,390 390,555 555,1020 1020,1280
application, which starts inserting data,|
|

539
00:14:28,020 --> 00:14:28,990
0,320 320,440 440,575 575,695 695,970
it's just going to go
它只会将条目追加到末尾，

540
00:14:29,070 --> 00:14:30,605
0,560 560,890 890,1310 1310,1445 1445,1535
append the entries to the

541
00:14:30,605 --> 00:14:33,695
0,245 1345,1665 1665,1985 2125,2525 2755,3090
end| and keep adding, adding
|并不断添加越来越多，

542
00:14:33,695 --> 00:14:35,410
0,180 180,270 270,515 1225,1470 1470,1715
more and more| and then
|然后认为它已经填满了，

543
00:14:35,760 --> 00:14:37,060
0,275 275,425 425,575 575,850 900,1300
think it filled up, right,|
|

544
00:14:37,740 --> 00:14:38,570
0,275 275,440 440,590 590,695 695,830
and again, now if any
现在，如果出现任何查询，

545
00:14:38,570 --> 00:14:39,845
0,210 210,405 405,660 660,960 960,1275
query comes along,| says you
|比如 SELECT * FROM 从这个表中， id 等于某个东西，

546
00:14:39,845 --> 00:14:41,800
0,365 415,815 925,1325 1405,1680 1680,1955
SELECT * FROM this table,

547
00:14:42,660 --> 00:14:44,540
0,335 335,670 720,995 995,1270
where id equals something,|
|

548
00:14:44,540 --> 00:14:45,080
0,150 150,255 255,360 360,450 450,540
we could go to get
我们可以获取这一页，

549
00:14:45,080 --> 00:14:46,355
0,135 135,300 300,590 820,1125 1125,1275
this one page,| jump to
|跳到 slot array 中定义的偏移量，

550
00:14:46,355 --> 00:14:47,630
0,180 180,515 595,945 945,1170 1170,1275
the offset as defined in

551
00:14:47,630 --> 00:14:48,815
0,90 90,285 285,590 820,1080 1080,1185
the slot array,| and we
|我们就可以获得所需的所有数据。

552
00:14:48,815 --> 00:14:49,520
0,105 105,240 240,375 375,540 540,705
get all the data that

553
00:14:49,520 --> 00:14:50,500
0,105 105,350
we need.|
|

554
00:14:51,830 --> 00:14:52,895
0,60 60,135 135,240 240,500 820,1065
So let's see now how
让我们看看这在我们的维基百科示例是如何工作的，

555
00:14:52,895 --> 00:14:53,780
0,105 105,240 240,345 345,420 420,885
this works in our Wikipedia

556
00:14:53,780 --> 00:14:55,220
0,290
example,|
|

557
00:14:55,350 --> 00:14:55,955
0,215 215,260 260,335 335,425 425,605
say you have a query
假设你在这里有一个查询，

558
00:14:55,955 --> 00:14:56,855
0,255 255,495 495,660 660,795 795,900
here,| where someone wants a
|其中有人想要登录，

559
00:14:56,855 --> 00:14:59,090
0,425 1075,1380 1380,1590 1590,1815 1815,2235
login,| they're passing a username
|他们传入用户名和密码，

560
00:14:59,090 --> 00:15:00,845
0,255 255,450 450,710 1300,1605 1605,1755
and a password,| we're just
|我们检查一下是否匹配，

561
00:15:00,845 --> 00:15:01,625
0,225 225,360 360,465 465,615 615,780
checking to see whether that

562
00:15:01,625 --> 00:15:02,960
0,275 295,540 540,765 765,1095 1095,1335
matches,| this is roughly how
|这大致就是登录到基于数据库应用程序的方式，

563
00:15:02,960 --> 00:15:04,580
0,150 150,315 315,620 1150,1410 1410,1620
you log into a database

564
00:15:04,580 --> 00:15:06,725
0,350 520,920 1420,1820 1840,2070 2070,2145
back application,| using,| if you
|使用，|如果你对数据库进行身份验证，它大致就是这样。

565
00:15:06,725 --> 00:15:07,820
0,135 135,480 480,720 720,915 915,1095
do authentication database, it roughly

566
00:15:07,820 --> 00:15:09,020
0,195 195,330 330,590
looks like this.|
|

567
00:15:09,430 --> 00:15:10,740
0,400 510,755 755,845 845,1010 1010,1310
Again, so we can ignore
我们可以忽略如何为一个给定的用户找到我们想要的数据，

568
00:15:10,740 --> 00:15:11,760
0,270 270,450 450,630 630,840 840,1020
how we actually find the

569
00:15:11,760 --> 00:15:13,200
0,180 180,450 450,690 690,980 1150,1440
data that we want for

570
00:15:13,200 --> 00:15:14,775
0,240 240,495 495,800 1060,1365 1365,1575
one given user,| but assume
|但假设有某种索引，

571
00:15:14,775 --> 00:15:15,680
0,225 225,315 315,420 420,585 585,905
there's some kind of index,|
|

572
00:15:16,030 --> 00:15:17,295
0,395 395,635 635,860 860,1025 1025,1265
hash table, {B+ -} tree,
哈希表，还是 B+ 树，并不重要，

573
00:15:17,295 --> 00:15:18,750
0,180 180,405 405,665 955,1290 1290,1455
it doesn't matter,| we'll cover
|我们将在第 8 课中讨论这个，

574
00:15:18,750 --> 00:15:19,635
0,195 195,315 315,495 495,735 735,885
that in lecture 8,| but
|但有一种方法可以说明，

575
00:15:19,635 --> 00:15:20,420
0,135 135,210 210,360 360,525 525,785
there's a way to say,|
|

576
00:15:20,680 --> 00:15:22,560
0,350 350,700 1290,1535 1535,1655 1655,1880
for this, for this user
对于这个用户帐户，这是记录 ID 和偏移量。

577
00:15:22,560 --> 00:15:24,120
0,350 640,1050 1050,1170 1170,1350 1350,1560
account, here's the record ID

578
00:15:24,120 --> 00:15:25,280
0,225 225,560
and offset.|
|

579
00:15:25,620 --> 00:15:26,285
0,245 245,380 380,530 530,605 605,665
So now we go into
现在，我们进入页面目录，

580
00:15:26,285 --> 00:15:27,665
0,120 120,345 345,905 985,1245 1245,1380
our page directory| and we
|找到包含我们要查找的数据的页面，

581
00:15:27,665 --> 00:15:28,880
0,225 225,450 450,705 705,960 960,1215
find the page that has

582
00:15:28,880 --> 00:15:29,830
0,225 225,345 345,510 510,645 645,950
the data we're looking for,|
|

583
00:15:30,210 --> 00:15:30,995
0,260 260,365 365,455 455,560 560,785
we look in the slot
我们查看 slot array ，

584
00:15:30,995 --> 00:15:32,240
0,335 415,675 675,840 840,1005 1005,1245
array,| we jump to some
|跳到某个偏移量，

585
00:15:32,240 --> 00:15:34,250
0,380 610,1010 1420,1740 1740,1890 1890,2010
offset,| and now we have
|现在我们有了查询所需的所有数据，

586
00:15:34,250 --> 00:15:34,985
0,195 195,330 330,465 465,630 630,735
all the data that we

587
00:15:34,985 --> 00:15:36,100
0,135 135,270 270,375 375,690 690,1115
need for this query, query|
|

588
00:15:36,270 --> 00:15:37,565
0,365 365,710 710,980 980,1145 1145,1295
and we can produce the
我们可以生成结果。

589
00:15:37,565 --> 00:15:38,360
0,275
result.|
|

590
00:15:38,490 --> 00:15:39,425
0,320 320,470 470,560 560,740 740,935
Again, so this is ideal
这是 OLTP 的理想选择，

591
00:15:39,425 --> 00:15:40,445
0,120 120,525 525,720 720,885 885,1020
for OLTP,| because all the
|因为所有数据都是连续的。

592
00:15:40,445 --> 00:15:42,340
0,165 165,465 465,1145
data is contiguous.|
|

593
00:15:42,820 --> 00:15:43,500
0,275 275,395 395,500 500,605 605,680
Same thing, we want to
同样的事情，我们想要做插入，

594
00:15:43,500 --> 00:15:44,670
0,60 60,135 135,560 730,1020 1020,1170
do an insert,| all we
|我们所需要做的就是查看页面目录，

595
00:15:44,670 --> 00:15:45,450
0,105 105,195 195,420 420,660 660,780
need to do is look

596
00:15:45,450 --> 00:15:47,355
0,260 430,750 750,1095 1095,1400 1630,1905
at page directory,| find a
|找到一个有空闲空间的页面，

597
00:15:47,355 --> 00:15:48,030
0,165 165,300 300,405 405,525 525,675
page that has a free

598
00:15:48,030 --> 00:15:49,470
0,320 820,1125 1125,1275 1275,1350 1350,1440
slot,| go bring it a
|给它一个内存，假设就是这个，

599
00:15:49,470 --> 00:15:50,480
0,225 225,450 450,600 600,720 720,1010
memory, assume it's this one,|
|

600
00:15:51,550 --> 00:15:53,100
0,275 275,550 660,890 890,1120 1140,1550
and then, you know, append
然后，把它追加到末尾。

601
00:15:53,100 --> 00:15:53,580
0,120 120,225 225,315 315,405 405,480
it to the end of

602
00:15:53,580 --> 00:15:54,280
0,230
it,

603
00:15:54,280 --> 00:15:55,300
0,105 105,320
{right -}.|
|

604
00:15:55,650 --> 00:15:56,840
0,120 120,380
That's fine.|
那很好。|

605
00:15:57,200 --> 00:15:57,925
0,260 260,395 395,515 515,620 620,725
But now if I try
但是现在，如果我尝试运行这个查询，

606
00:15:57,925 --> 00:15:58,740
0,90 90,210 210,360 360,540 540,815
to run that query,| before
|其中我想找到所有，

607
00:15:58,760 --> 00:15:59,635
0,275 275,365 365,530 530,695 695,875
again where I'm trying to

608
00:15:59,635 --> 00:16:01,675
0,275 325,725 805,1205 1705,1950 1950,2040
find all the,| get the
|获得人们每月登录的次数，

609
00:16:01,675 --> 00:16:02,350
0,105 105,225 225,405 405,570 570,675
number of times people have

610
00:16:02,350 --> 00:16:03,655
0,225 225,345 345,525 525,830 1030,1305
logged in per month,| if
|如果它们的主机名以 .gov 结尾，

611
00:16:03,655 --> 00:16:04,705
0,150 150,300 300,435 435,695 745,1050
they end with a {hostname

612
00:16:04,705 --> 00:16:07,660
0,285 285,630 630,1205 2545,2820 2820,2955
-} with .gov,| now, you
|现在，在本例中你可以看到，

613
00:16:07,660 --> 00:16:08,520
0,90 90,165 165,315 315,540 540,860
see, in this case here,|
|

614
00:16:08,570 --> 00:16:10,015
0,275 275,410 410,670 810,1145 1145,1445
I got to scan all
我必须扫描表中的所有页面，

615
00:16:10,015 --> 00:16:11,010
0,225 225,435 435,630 630,735 735,995
the pages in the table,|
|

616
00:16:11,510 --> 00:16:13,075
0,400 1020,1265 1265,1370 1370,1475 1475,1565
because I need to look
因为我需要查看所有内容，所有用户帐户，

617
00:16:13,075 --> 00:16:14,260
0,225 225,585 585,870 870,1005 1005,1185
at everything, all the user

618
00:16:14,260 --> 00:16:15,340
0,350
accounts,|
|

619
00:16:15,350 --> 00:16:16,285
0,260 260,440 440,620 620,770 770,935
and then when I bring
然后当我带入一个页面，

620
00:16:16,285 --> 00:16:17,820
0,150 150,345 345,665
a page in,|
|

621
00:16:18,600 --> 00:16:19,625
0,320 320,500 500,725 725,965 965,1025
the, the way, we're going
我们将粗略地执行查询的方式，

622
00:16:19,625 --> 00:16:21,065
0,245 385,785 865,1125 1125,1245 1245,1440
to roughly execute the query,|
|

623
00:16:21,065 --> 00:16:21,665
0,135 135,285 285,390 390,510 510,600
we haven't got through how
我们还没有了解如何执行查询，

624
00:16:21,665 --> 00:16:22,445
0,75 75,165 165,375 375,600 600,780
to do query execution yet,|
|

625
00:16:22,445 --> 00:16:23,240
0,120 120,210 210,375 375,615 615,795
but the roughly the idea
但大致的想法是，

626
00:16:23,240 --> 00:16:24,425
0,150 150,440 670,915 915,1035 1035,1185
is that,| we got this
|我们有这个 WHERE 子句，这是关于主机名的，

627
00:16:24,425 --> 00:16:25,910
0,195 195,480 480,815 1045,1380 1380,1485
WHERE clause thing, that's look

628
00:16:25,910 --> 00:16:28,205
0,120 120,255 255,740 1060,1460 2050,2295
up on hostname,| we, we
|我们需要在一个页面中找到 tuple ，

629
00:16:28,205 --> 00:16:29,015
0,105 105,225 225,390 390,615 615,810
need to go find the

630
00:16:29,015 --> 00:16:30,460
0,150 150,425 775,1050 1050,1185 1185,1445
{tuples -} in a page,|
|

631
00:16:30,480 --> 00:16:32,825
0,400 750,1145 1145,1540 1740,2030 2030,2345
that where that that predicate
主机名上的谓词是满足的。

632
00:16:32,825 --> 00:16:33,515
0,90 90,165 165,285 285,435 435,690
on the {hostname -} is

633
00:16:33,515 --> 00:16:34,580
0,395
satisfied.|
|

634
00:16:34,710 --> 00:16:35,555
0,245 245,335 335,500 500,710 710,845
So the only data we
所以，我们真正需要查看的唯一数据就是这里的 hostname ，

635
00:16:35,555 --> 00:16:36,430
0,165 165,345 345,465 465,600 600,875
really need to look at

636
00:16:36,720 --> 00:16:38,420
0,400 660,1060 1140,1385 1385,1520 1520,1700
is just the {hostname -}

637
00:16:38,420 --> 00:16:40,120
0,290
here,|
|

638
00:16:40,910 --> 00:16:41,770
0,290 290,455 455,515 515,620 620,860
then we've got to do
然后我们必须对 lastLogin 进行聚合，对于 GROUP BY ，

639
00:16:41,770 --> 00:16:43,975
0,345 345,570 570,1130 1780,2070 2070,2205
the, the aggregate on the

640
00:16:43,975 --> 00:16:45,475
0,180 180,390 390,665 1135,1395 1395,1500
{lastLogin - -}, for the

641
00:16:45,475 --> 00:16:47,635
0,135 135,425 1705,1965 1965,2055 2055,2160
GROUP BY,| and so that
|这意味着我们需要查看的唯一数据，

642
00:16:47,635 --> 00:16:48,385
0,150 150,255 255,390 390,600 600,750
means the only data we

643
00:16:48,385 --> 00:16:49,090
0,165 165,315 315,390 390,495 495,705
really need to look at|
|

644
00:16:49,090 --> 00:16:49,825
0,210 210,375 375,555 555,660 660,735
for that portion of the
对于那个查询部分来说，就是这些属性。

645
00:16:49,825 --> 00:16:51,925
0,275 595,870 870,1145 1435,1800 1800,2100
query is just these attributes

646
00:16:51,925 --> 00:16:52,860
0,275
here.|
|

647
00:16:54,205 --> 00:16:54,960
0,75 75,150 150,300 300,480 480,755
So what's the obvious problem?|
那么最明显的问题是什么？|

648
00:16:59,820 --> 00:17:00,350
0,230 230,305 305,380 380,455 455,530
You have to go through
你必须遍历所有的行，

649
00:17:00,350 --> 00:17:01,055
0,75 75,165 165,435 435,570 570,705
all the rows| and you
|你带来了一堆数据，而你实际上并不需要，

650
00:17:01,055 --> 00:17:01,700
0,135 135,240 240,360 360,480 480,645
brought a bunch of data

651
00:17:01,700 --> 00:17:02,620
0,180 180,345 345,495 495,690 690,920
and you actually don't need,|
|

652
00:17:03,690 --> 00:17:04,805
0,305 305,470 470,665 665,890 890,1115
so in order to get
所以，为了获得我需要的属性，

653
00:17:04,805 --> 00:17:06,010
0,210 210,435 435,720 720,900 900,1205
just the attributes I needed,|
|

654
00:17:06,270 --> 00:17:07,145
0,260 260,395 395,545 545,710 710,875
I had to bring in
我必须引入整个页面，

655
00:17:07,145 --> 00:17:08,210
0,180 180,435 435,735 735,930 930,1065
the entire page,| but the
|但是整个页面带来了一些我不需要的属性，

656
00:17:08,210 --> 00:17:09,470
0,285 285,645 645,915 915,1110 1110,1260
entire page brings on a

657
00:17:09,470 --> 00:17:11,050
0,135 135,330 330,710 940,1260 1260,1580
bunch of attributes,| {userID -},
|userID, userName, userPass ，我在这个查询中不需要的，

658
00:17:11,400 --> 00:17:12,935
0,530 530,740 740,1060 1140,1385 1385,1535
userName, {userPass -} that I

659
00:17:12,935 --> 00:17:13,930
0,285 285,420 420,540 540,675 675,995
don't need for this query,|
|

660
00:17:14,310 --> 00:17:15,815
0,230 230,410 410,670 720,1085 1085,1505
so I'm basically doing useless
所以我在做无用的 IO ，

661
00:17:15,815 --> 00:17:17,440
0,405 405,735 735,1065 1065,1290 1290,1625
IO,| I'm fetching data in
|我从磁盘中获取数据，

662
00:17:17,670 --> 00:17:19,280
0,305 305,850 1020,1280 1280,1415 1415,1610
from disk| and I don't
|但我根本不需要它，

663
00:17:19,280 --> 00:17:20,080
0,135 135,315 315,450 450,555 555,800
even need it at all,

664
00:17:21,820 --> 00:17:22,905
0,350 350,560 560,680 680,875 875,1085
right,| so not only is
|这不仅很慢，

665
00:17:22,905 --> 00:17:24,165
0,240 240,540 540,750 750,960 960,1260
that slow,| but in some
|而且在某些系统中，你为每个磁盘 IOPS 付费，

666
00:17:24,165 --> 00:17:26,160
0,365 595,900 900,1155 1155,1505 1675,1995
systems you pay per disk

667
00:17:26,160 --> 00:17:28,725
0,380 1330,1575 1575,2040 2040,2295 2295,2565
IOPS,| in Aurora on Amazon,
|在亚马逊的 Aurora 上，你付费，

668
00:17:28,725 --> 00:17:29,850
0,195 195,485 535,810 810,960 960,1125
you pay,| if you read
|如果你从磁盘上读取某些东西，

669
00:17:29,850 --> 00:17:31,425
0,180 180,375 375,920 1000,1320 1320,1575
something from disk,| you pay
|你按查询的 IO 操作次数付费，

670
00:17:31,425 --> 00:17:32,385
0,330 330,555 555,660 660,810 810,960
per the number of {IO

671
00:17:32,385 --> 00:17:33,585
0,210 210,480 480,705 705,935 955,1200
-} operations you're doing for

672
00:17:33,585 --> 00:17:35,085
0,90 90,365 895,1200 1200,1380 1380,1500
a query, right,| so in
|所以在这种情况下，

673
00:17:35,085 --> 00:17:36,015
0,150 150,345 345,555 555,750 750,930
this case here,| I be
|我是在为我实际上并不需要的数据付费。

674
00:17:36,015 --> 00:17:37,250
0,270 270,540 540,795 795,990 990,1235
paying for data that I,

675
00:17:37,390 --> 00:17:38,280
0,245 245,350 350,605 605,755 755,890
that I don't actually even

676
00:17:38,280 --> 00:17:39,300
0,290
need.|
|

677
00:17:41,830 --> 00:17:42,690
0,245 245,410 410,530 530,695 695,860
So that's the obvious problem
这就是 NSM 的明显问题所在，

678
00:17:42,690 --> 00:17:44,205
0,240 240,795 795,1095 1095,1320 1320,1515
with NSM,| again, great for
|它非常适用于插入、更新和删除，

679
00:17:44,205 --> 00:17:45,510
0,450 450,615 615,960 960,1125 1125,1305
inserts, updates, deletes,| great for
|也适用于需要获取数据库中单个实体的全部数据的查询，

680
00:17:45,510 --> 00:17:46,260
0,255 255,360 360,495 495,615 615,750
queries that need to get

681
00:17:46,260 --> 00:17:47,190
0,180 180,390 390,600 600,750 750,930
the entire, all the data

682
00:17:47,190 --> 00:17:48,960
0,225 225,530 940,1340 1360,1620 1620,1770
for a for a single

683
00:17:48,960 --> 00:17:50,775
0,360 360,435 435,525 525,770 1510,1815
entity in the database,| but
|但是，如果你想要扫描表的大部分，

684
00:17:50,775 --> 00:17:51,540
0,165 165,270 270,360 360,510 510,765
if you want to scan

685
00:17:51,540 --> 00:17:52,800
0,330 330,780 780,1005 1005,1155 1155,1260
large portions of of a

686
00:17:52,800 --> 00:17:54,630
0,260 910,1185 1185,1320 1320,1560 1560,1830
table| and you only need
|并且只需要一个子集的属性，

687
00:17:54,630 --> 00:17:55,725
0,195 195,525 525,615 615,780 780,1095
a subset of the attributes,|
|

688
00:17:55,725 --> 00:17:58,560
0,270 270,635 865,1305 1305,1745 2515,2835
which most OLAP queries only
大多数 OLAP 查询所需要的，

689
00:17:58,560 --> 00:18:00,435
0,320 790,1155 1155,1440 1440,1635 1635,1875
need, right,| it's very rare
|在一个很大的表上调用 SELECT * 是非常罕见的，

690
00:18:00,435 --> 00:18:01,110
0,135 135,225 225,345 345,480 480,675
what you call a SELECT

691
00:18:01,110 --> 00:18:02,220
0,285 285,525 525,705 705,870 870,1110
* on a and a

692
00:18:02,220 --> 00:18:03,705
0,300 300,620 730,1035 1035,1290 1290,1485
really wide, huge table,| because
|因为你基本上是在获取整个东西，

693
00:18:03,705 --> 00:18:04,680
0,120 120,330 330,765 765,870 870,975
you're basically dumping the whole

694
00:18:04,680 --> 00:18:06,750
0,120 120,380 1000,1365 1365,1790 1840,2070
thing out,| there's utilities to
|还有其他实用程序可以让它运行得更快，除了 SELECT * 。

695
00:18:06,750 --> 00:18:07,920
0,105 105,380 430,705 705,930 930,1170
make that go faster other

696
00:18:07,920 --> 00:18:09,080
0,210 210,420 420,710
than SELECT *.|
|

697
00:18:09,270 --> 00:18:10,010
0,245 245,380 380,500 500,590 590,740
So this can be bad
所以，这可能对 OLAP 不利，

698
00:18:10,010 --> 00:18:11,825
0,135 135,480 480,830 1150,1695 1695,1815
for OLAP,| because we're bringing
|因为我们带来了不需要的数据。

699
00:18:11,825 --> 00:18:12,530
0,150 150,315 315,450 450,540 540,705
in data that we don't

700
00:18:12,530 --> 00:18:13,600
0,230
need.|
|

701
00:18:14,620 --> 00:18:16,575
0,400 1320,1580 1580,1730 1730,1865 1865,1955
The this is sort of
这是一种低级别的详细信息，

702
00:18:16,575 --> 00:18:17,970
0,120 120,395 415,720 720,1025 1105,1395
low level detail,| but going
|但回到这里的这一部分，

703
00:18:17,970 --> 00:18:19,610
0,195 195,500 760,1050 1050,1290 1290,1640
back to this portion here,|
|

704
00:18:19,900 --> 00:18:20,730
0,290 290,425 425,530 530,680 680,830
like if you think about
考虑如何执行查询，运行这个谓词，

705
00:18:20,730 --> 00:18:21,570
0,150 150,270 270,420 420,660 660,840
how you would actually execute

706
00:18:21,570 --> 00:18:22,580
0,120 120,330 330,525 525,705 705,1010
the query to do this,

707
00:18:23,080 --> 00:18:25,160
0,400
to,

708
00:18:25,230 --> 00:18:27,250
0,275 275,455 455,970 1290,1730 1730,2020
run this predicate,| I'm jumping
|我跳转到内存中的不同位置，

709
00:18:27,300 --> 00:18:29,110
0,365 365,575 575,820 840,1240 1410,1810
around to different locations in

710
00:18:29,190 --> 00:18:31,265
0,305 305,610 1170,1570 1650,1925 1925,2075
in memory| to to do
|以执行我的扫描，

711
00:18:31,265 --> 00:18:32,470
0,195 195,480 480,780 780,960 960,1205
my scan, right,| so like
|我必须读取第一个 tuple 的 header ，

712
00:18:32,820 --> 00:18:34,060
0,275 275,455 455,635 635,800 800,1240
I gotta read this header

713
00:18:34,230 --> 00:18:35,675
0,245 245,350 350,515 515,820 1140,1445
for the first tuple,| figure
|找出我需要跳过多远才能获得 hostname ，

714
00:18:35,675 --> 00:18:37,355
0,210 210,465 465,675 675,935 1375,1680
out where you know how

715
00:18:37,355 --> 00:18:37,850
0,135 135,210 210,300 300,390 390,495
far I need to jump

716
00:18:37,850 --> 00:18:38,420
0,135 135,240 240,315 315,405 405,570
over to get the {hostname

717
00:18:38,420 --> 00:18:39,800
0,320 700,990 990,1140 1140,1230 1230,1380
-},| then I can maybe
|然后我也许可以查看 lastLogin ，

718
00:18:39,800 --> 00:18:40,865
0,165 165,330 330,495 495,630 630,1065
look at the {lastLogin -},|
|

719
00:18:40,865 --> 00:18:42,050
0,420 420,690 690,960 960,1065 1065,1185
I'm computing aggregate as I
我一直在计算聚合，

720
00:18:42,050 --> 00:18:43,175
0,150 150,440 610,855 855,975 975,1125
go along,| but then I
|但我跳到下一个 tuple ，

721
00:18:43,175 --> 00:18:44,060
0,165 165,390 390,570 570,675 675,885
jump down to the next

722
00:18:44,060 --> 00:18:45,290
0,225 225,500 700,945 945,1080 1080,1230
{tuple -}| and then jump
|然后跳过，以获得它的 hostname 属性。

723
00:18:45,290 --> 00:18:46,460
0,165 165,420 420,615 615,860 880,1170
over that to get get

724
00:18:46,460 --> 00:18:47,840
0,135 135,380 760,990 990,1170 1170,1380
to the, you know to

725
00:18:47,840 --> 00:18:49,690
0,195 195,420 420,645 645,1070 1450,1850
its {hostname -} attribute.| So
|在现代超大规模的 CPU 中，

726
00:18:49,800 --> 00:18:50,915
0,245 245,365 365,605 605,1025 1025,1115
in a modern super scale

727
00:18:50,915 --> 00:18:52,030
0,135 135,480 480,675 675,825 825,1115
of CPU,| this is terrible,|
|这是很糟糕的，|

728
00:18:52,140 --> 00:18:53,450
0,400 570,875 875,980 980,1160 1160,1310
because there's a bunch of
因为有一堆这样的非顺序操作，

729
00:18:53,450 --> 00:18:55,655
0,260 400,735 735,1310 1450,1850 1930,2205
these {non-sequential -} operations,| that
|也可能变得不确定，

730
00:18:55,655 --> 00:18:57,010
0,225 225,435 435,555 555,735 735,1355
could also became {non-deterministic -},|
|

731
00:18:57,090 --> 00:18:57,980
0,400
where,
我访问的内存位置是，

732
00:18:58,080 --> 00:19:00,310
0,400 870,1235 1235,1505 1505,1810 1830,2230
{} I, my memory locations

733
00:19:00,360 --> 00:19:01,715
0,245 245,485 485,875 875,1145 1145,1355
that I'm accessing is, is

734
00:19:01,715 --> 00:19:03,335
0,120 120,225 225,485 1135,1455 1455,1620
going to be,| it's not
|它不是随机的，

735
00:19:03,335 --> 00:19:04,310
0,300 300,510 510,660 660,765 765,975
random,| because you're always going
|因为你总是以递增的顺序进入，

736
00:19:04,310 --> 00:19:05,750
0,255 255,510 510,780 780,1100 1210,1440
in in increasing order,| but
|但这不会像我只是读取[步长的]内存，

737
00:19:05,750 --> 00:19:06,335
0,135 135,270 270,390 390,450 450,585
it's not going to be

738
00:19:06,335 --> 00:19:07,715
0,240 240,465 465,615 615,935 1075,1380
like I'm just reading strides

739
00:19:07,715 --> 00:19:08,930
0,135 135,390 390,690 690,900 900,1215
of memory| and and crunching
|并非常快地处理它。

740
00:19:08,930 --> 00:19:10,440
0,105 105,225 225,405 405,710
through it very quickly.|
|

741
00:19:11,690 --> 00:19:12,460
0,290 290,380 380,500 500,605 605,770
It's a low level of
这是一个低层次的细节，

742
00:19:12,460 --> 00:19:13,600
0,315 315,675 675,885 885,1020 1020,1140
detail,| that we don't really
|我们在本学期没有真正涉及到，

743
00:19:13,600 --> 00:19:14,440
0,150 150,255 255,345 345,570 570,840
cover in the semester,| but
|但它至少值得讨论。

744
00:19:14,440 --> 00:19:16,200
0,440 760,1080 1080,1260 1260,1470 1470,1760
it's, it's at least worth

745
00:19:16,790 --> 00:19:18,040
0,400
discussing.|
|

746
00:19:18,240 --> 00:19:19,210
0,260 260,410 410,620 620,725 725,970
And then we'll see this,|
然后我们会看到这个，|

747
00:19:19,650 --> 00:19:21,020
0,305 305,440 440,785 785,1070 1070,1370
we'll cover compression later in
我们将在这节课的后面部分讨论压缩，

748
00:19:21,020 --> 00:19:22,580
0,195 195,315 315,570 570,950 1300,1560
in this lecture,| but in
|但在这里，

749
00:19:22,580 --> 00:19:23,570
0,165 165,375 375,600 600,855 855,990
this case here,| we're not
|我们将无法获得良好的压缩率，

750
00:19:23,570 --> 00:19:23,945
0,105 105,150 150,210 210,285 285,375
going to be able to

751
00:19:23,945 --> 00:19:24,980
0,180 180,345 345,465 465,645 645,1035
get, you know, good compression

752
00:19:24,980 --> 00:19:25,760
0,255 255,420 420,525 525,615 615,780
rate,| if you want to
|如果你想要减少单个页面中的数据量或在单个页面中填充更多数据，

753
00:19:25,760 --> 00:19:26,855
0,255 255,435 435,555 555,765 765,1095
reduce the amount of or

754
00:19:26,855 --> 00:19:27,995
0,285 285,480 480,690 690,915 915,1140
pack in more data within

755
00:19:27,995 --> 00:19:30,040
0,165 165,345 345,665 715,1115 1645,2045
a single page,| because all
|因为给定表的所有属性都被放在该页面中，

756
00:19:30,060 --> 00:19:31,610
0,400 420,910 990,1250 1250,1355 1355,1550
the attributes for a given

757
00:19:31,610 --> 00:19:32,765
0,285 285,465 465,630 630,900 900,1155
table are just thrown together

758
00:19:32,765 --> 00:19:33,680
0,165 165,315 315,525 525,690 690,915
in that page,| and there's
|重复性的机会会更少，

759
00:19:33,680 --> 00:19:35,450
0,290 970,1485 1485,1590 1590,1650 1650,1770
no, there's going to be

760
00:19:35,450 --> 00:19:37,115
0,225 225,465 465,770 820,1365 1365,1665
less chance for repeatability| or
|识别的机会也会更少，

761
00:19:37,115 --> 00:19:39,140
0,270 270,510 510,845 1105,1740 1740,2025
less chance for identifying,| hey,
|嘿，这些值是一样的，

762
00:19:39,140 --> 00:19:40,115
0,240 240,465 465,675 675,855 855,975
these these values are the

763
00:19:40,115 --> 00:19:41,315
0,275 445,720 720,840 840,1050 1050,1200
same,| I can compress them
|我可以把它们压缩得很好，

764
00:19:41,315 --> 00:19:42,300
0,180 180,485
really well,

765
00:19:42,910 --> 00:19:43,970
0,305 305,470 470,605 605,770 770,1060
right,| again, is going back,|
|回来这里，|

766
00:19:44,380 --> 00:19:45,150
0,260 260,410 410,545 545,635 635,770
we have, we have a
我们有 userID ，是一个整数，

767
00:19:45,150 --> 00:19:45,945
0,195 195,450 450,720 720,765 765,795
{userID -}, that's going to

768
00:19:45,945 --> 00:19:47,625
0,75 75,545 1045,1530 1530,1620 1620,1680
be integer,| userName is going
|userName 是随机字符串，

769
00:19:47,625 --> 00:19:48,615
0,30 30,120 120,360 360,705 705,990
to be random string,| {userPass
|userPass 是随机字符串，

770
00:19:48,615 --> 00:19:50,100
0,210 210,465 465,815 1135,1425 1425,1485
-} random string,| it's going
|这将是所有不同的值域，

771
00:19:50,100 --> 00:19:52,140
0,60 60,135 135,380 970,1370 1690,2040
to be all different value

772
00:19:52,140 --> 00:19:53,835
0,470 820,1125 1125,1455 1455,1590 1590,1695
domains| and that's not going
|这对于压缩来说并不是理想的。

773
00:19:53,835 --> 00:19:54,710
0,30 30,150 150,360 360,525 525,875
to be ideal for compression.|
|

774
00:19:58,450 --> 00:19:59,745
0,245 245,425 425,725 725,1040 1040,1295
So the alternative approach is
另一种方法是 DSM ，列存，分解存储模型，

775
00:19:59,745 --> 00:20:02,595
0,180 180,665 775,1175 1255,1895 2215,2850
the DSM, the {column,store}, decomposition

776
00:20:02,595 --> 00:20:04,590
0,240 240,545 1075,1335 1335,1595 1675,1995
storage model,| and the idea
|这里的想法是，

777
00:20:04,590 --> 00:20:05,910
0,195 195,330 330,590 910,1170 1170,1320
here is that,| instead of
|不是在一个页面中存储单个 tuple 的所有属性，

778
00:20:05,910 --> 00:20:08,610
0,350 1390,1770 1770,2150 2260,2595 2595,2700
storing all the attributes for

779
00:20:08,610 --> 00:20:09,660
0,75 75,270 270,705 705,930 930,1050
a single tuple together in

780
00:20:09,660 --> 00:20:11,130
0,90 90,350 1030,1350 1350,1395 1395,1470
a page,| we're going to
|我们将存储所有 tuple 的所有属性，

781
00:20:11,130 --> 00:20:12,540
0,150 150,420 420,800 850,1215 1215,1410
store all the attributes for

782
00:20:12,540 --> 00:20:14,260
0,320 340,630 630,920
all {tuples -},|
|

783
00:20:14,510 --> 00:20:16,555
0,400 480,880 1200,1535 1535,1820 1820,2045
sorry, for all tuple, to
抱歉，对于所有 tuple ，在一个页面中存储单个属性。

784
00:20:16,555 --> 00:20:17,545
0,150 150,300 300,555 555,870 870,990
store a single attribute in

785
00:20:17,545 --> 00:20:18,960
0,105 105,300 300,635
a single page,

786
00:20:18,970 --> 00:20:20,030
0,290 290,515 515,605 605,770 770,1060
right.| I've just had that
|我有 lastLogin 字段，

787
00:20:20,110 --> 00:20:21,720
0,335 335,710 710,1000 1260,1505 1505,1610
{lastLogin -} field,| instead of
|不是将所有属性与单个页面中其他属性混合在一起，

788
00:20:21,720 --> 00:20:23,325
0,255 255,585 585,1125 1125,1440 1440,1605
having all intermix with the

789
00:20:23,325 --> 00:20:24,645
0,225 225,645 645,960 960,1140 1140,1320
other attributes within a single

790
00:20:24,645 --> 00:20:25,845
0,255 255,495 495,780 780,1035 1035,1200
page,| I only just have
|我只有 lastLogin 属性。

791
00:20:25,845 --> 00:20:28,700
0,165 165,635 865,1170 1170,1625 2395,2855
that login {lastLogin -} attribute.|
|

792
00:20:29,780 --> 00:20:30,385
0,260 260,395 395,515 515,575 575,605
And this is going to
这对于 OLAP 查询来说将是理想的，

793
00:20:30,385 --> 00:20:31,765
0,165 165,450 450,750 750,1020 1020,1380
be ideal now for OLAP

794
00:20:31,765 --> 00:20:33,310
0,360 360,695 1045,1350 1350,1395 1395,1545
queries,| because they're going to
|因为它们将扫描整个表，

795
00:20:33,310 --> 00:20:35,130
0,270 270,480 480,690 690,1040 1420,1820
scan the entire table| and
|只扫描属性的一部分，

796
00:20:35,240 --> 00:20:36,595
0,400 450,695 695,830 830,1025 1025,1355
only for, only a subset

797
00:20:36,595 --> 00:20:38,080
0,75 75,255 255,695 1015,1290 1290,1485
of the attributes,| and now
|现在，当我从磁盘获取页面时，

798
00:20:38,080 --> 00:20:38,905
0,165 165,315 315,495 495,675 675,825
when I go fetch a

799
00:20:38,905 --> 00:20:40,435
0,165 165,345 345,935 955,1320 1320,1530
page from disk,| I'm only
|我只获取数据，

800
00:20:40,435 --> 00:20:41,500
0,315 315,585 585,780 780,915 915,1065
getting data,| I know I'm
|我知道我只获取实际需要的属性的数据，

801
00:20:41,500 --> 00:20:42,450
0,120 120,315 315,540 540,705 705,950
only getting data from the

802
00:20:42,470 --> 00:20:43,500
0,320 320,425 425,560 560,740 740,1030
attributes that I actually need,|
|

803
00:20:44,410 --> 00:20:45,450
0,260 260,440 440,605 605,770 770,1040
and not for other things
而不是其他[顺带]的东西。

804
00:20:45,450 --> 00:20:46,860
0,270 270,590 970,1200 1200,1275 1275,1410
that just sort of gets

805
00:20:46,860 --> 00:20:47,660
0,195 195,360 360,465 465,555 555,800
carried along for the ride.|
|

806
00:20:49,340 --> 00:20:51,020
0,400 450,850
So the,|
所以，|

807
00:20:51,240 --> 00:20:52,175
0,320 320,485 485,695 695,890 890,935
again, the benefit of a
像 SQL 这样的声明语言的好处是，

808
00:20:52,175 --> 00:20:53,255
0,300 300,450 450,660 660,960 960,1080
declared language like SQL is

809
00:20:53,255 --> 00:20:54,305
0,275 385,645 645,825 825,915 915,1050
that,| you don't have to
|你不必知道，不必关心，

810
00:20:54,305 --> 00:20:55,750
0,275 295,570 570,750 750,1050 1050,1445
know, not to care,| whether
|自己是在行存储系统上运行，还是在列存储系统上运行，

811
00:20:55,770 --> 00:20:56,600
0,320 320,440 440,560 560,650 650,830
you're running on a row

812
00:20:56,600 --> 00:20:57,635
0,195 195,420 420,675 675,840 840,1035
store system versus a column

813
00:20:57,635 --> 00:20:59,120
0,210 210,485 625,915 915,1155 1155,1485
store system,| your same SQL
|你相同的 SQL 查询，可以很好地工作，（结果）是一样的，

814
00:20:59,120 --> 00:21:00,560
0,240 240,590 670,975 975,1215 1215,1440
query works just fine, just

815
00:21:00,560 --> 00:21:02,600
0,150 150,410 1540,1800 1800,1905 1905,2040
the same,| but now it's
|但现在这是数据库系统的责任，

816
00:21:02,600 --> 00:21:04,805
0,90 90,300 300,650 1030,1430 1900,2205
the database system responsibility,| meaning
|意味着我们实际构建它的人，

817
00:21:04,805 --> 00:21:06,190
0,300 300,630 630,840 840,1050 1050,1385
us people actually building it,|
|

818
00:21:06,390 --> 00:21:07,940
0,380 380,695 695,965 965,1325 1325,1550
it's, it's our responsibility| to
这是我们的责任，|获取数据，将其拆分成单独的列，分隔属性，

819
00:21:07,940 --> 00:21:09,815
0,165 165,500 970,1275 1275,1580 1630,1875
be to take data, split

820
00:21:09,815 --> 00:21:11,060
0,75 75,180 180,455 475,825 825,1245
it up into separate columns,

821
00:21:11,060 --> 00:21:12,500
0,240 240,680 850,1110 1110,1260 1260,1440
separate attributes,| and then stitch
|然后在需要产生结果时将其缝合在一起。

822
00:21:12,500 --> 00:21:14,030
0,105 105,285 285,620 700,1100 1270,1530
it back together to when

823
00:21:14,030 --> 00:21:15,700
0,120 120,380 790,1080 1080,1320 1320,1670
we need to produce results.|
|

824
00:21:19,640 --> 00:21:21,100
0,335 335,670 900,1175 1175,1310 1310,1460
{All,right}, so this is just
好的，这只是我之前分享的另一个相同的图表，

825
00:21:21,100 --> 00:21:22,210
0,210 210,420 420,645 645,1005 1005,1110
another the same diagram I

826
00:21:22,210 --> 00:21:23,605
0,105 105,350 910,1185 1185,1305 1305,1395
shared before,| again, the way
|同样，考虑这一点的方法是，

827
00:21:23,605 --> 00:21:24,145
0,90 90,195 195,315 315,435 435,540
to think about this is

828
00:21:24,145 --> 00:21:25,630
0,240 240,510 510,675 675,965 1135,1485
that,| for the first column
|对于这里的第一列，第一个属性列 A ，

829
00:21:25,630 --> 00:21:26,850
0,255 255,510 510,780 780,930 930,1220
here, first attribute column A,|
|

830
00:21:27,140 --> 00:21:28,240
0,305 305,425 425,575 575,800 800,1100
we have a separate file
我们有一个单独的文件，其中有一系列页面，

831
00:21:28,240 --> 00:21:28,950
0,180 180,240 240,330 330,450 450,710
with a bunch of pages,|
|

832
00:21:29,720 --> 00:21:30,840
0,380 380,485 485,620 620,860 860,1120
it'll have a header, now,|
现在，它会有一个 header ，|

833
00:21:30,860 --> 00:21:31,930
0,400 480,725 725,845 845,965 965,1070
just, you know, tell us
告诉我们页面里面有什么，

834
00:21:31,930 --> 00:21:32,920
0,135 135,315 315,465 465,810 810,990
what, what's in, what's inside

835
00:21:32,920 --> 00:21:34,540
0,120 120,380 1000,1260 1260,1410 1410,1620
the page,| and then now
|然后我们就有了这个 null bitmap ，

836
00:21:34,540 --> 00:21:35,575
0,210 210,345 345,555 555,750 750,1035
we'll have this, the null

837
00:21:35,575 --> 00:21:36,760
0,545
bitmap,|
|

838
00:21:36,800 --> 00:21:38,440
0,290 290,575 575,845 845,1330 1350,1640
for all the columns, sorry,
对于所有列，抱歉，是该列中的所有值，

839
00:21:38,440 --> 00:21:39,565
0,150 150,330 330,510 510,765 765,1125
for all the values within

840
00:21:39,565 --> 00:21:43,585
0,365 1675,2075 2275,2550 2550,2825 3655,4020
that within this column,| followed
|接下来是表中所有 tuple 的连续值，

841
00:21:43,585 --> 00:21:45,150
0,365 415,735 735,900 900,1290 1290,1565
by now the contiguous values

842
00:21:45,470 --> 00:21:47,290
0,400 840,1175 1175,1370 1370,1655 1655,1820
for all the tuples in

843
00:21:47,290 --> 00:21:48,300
0,120 120,380
the table,|
|

844
00:21:49,490 --> 00:21:50,050
0,245 245,320 320,410 410,500 500,560
and we just do it
我们在下一个和下一个也是这样做的。

845
00:21:50,050 --> 00:21:50,860
0,75 75,165 165,315 315,585 585,810
for the next one and

846
00:21:50,860 --> 00:21:52,200
0,105 105,240 240,530
the next one.|
|

847
00:21:52,590 --> 00:21:56,315
0,400 1740,2030 2030,2320 3240,3530 3530,3725
{All,right}, and so these are
好的，所以这些仍然是，

848
00:21:56,315 --> 00:21:57,440
0,285 285,570 570,810 810,1005 1005,1125
still,| these files will still
|这些文件仍然会像我们之前谈到的那样被分解成数据库页，

849
00:21:57,440 --> 00:21:58,205
0,120 120,300 300,465 465,600 600,765
be broken up as as

850
00:21:58,205 --> 00:21:59,240
0,255 255,600 600,810 810,915 915,1035
database pages like we talked

851
00:21:59,240 --> 00:22:00,410
0,105 105,350 580,810 810,960 960,1170
about before,| so either four
|无论是 4 千字节还是 8 千字节，无论系统支持什么，

852
00:22:00,410 --> 00:22:02,270
0,375 375,480 480,945 945,1340 1570,1860
kilobytes, eight kilobytes, whatever, whatever

853
00:22:02,270 --> 00:22:04,510
0,150 150,375 375,740 1420,1820 1840,2240
the system supports,| but the,
|但是，文件本身将包含，仅仅是单个属性的数据，

854
00:22:04,590 --> 00:22:06,490
0,275 275,550 630,1030 1140,1520 1520,1900
the file itself will contain,

855
00:22:07,760 --> 00:22:08,855
0,225 225,420 420,660 660,855 855,1095
again, just just the data

856
00:22:08,855 --> 00:22:10,640
0,255 255,405 405,630 630,1055 1525,1785
for a single attribute| and
|现在这些不同文件的元数据开销

857
00:22:10,640 --> 00:22:12,430
0,165 165,345 345,885 885,1340 1390,1790
now the metadata overhead for

858
00:22:12,780 --> 00:22:14,060
0,275 275,470 470,770 770,1070 1070,1280
these different files| is actually
|实际上比行存储中的要少得多，

859
00:22:14,060 --> 00:22:16,340
0,225 225,540 540,920 1000,1400 2020,2280
much less than a in

860
00:22:16,340 --> 00:22:18,290
0,120 120,330 330,645 645,1010 1630,1950
a row store,| because I
|因为我不必像跟踪所有其他的，

861
00:22:18,290 --> 00:22:19,235
0,300 300,420 420,555 555,735 735,945
don't have to keep track

862
00:22:19,235 --> 00:22:20,890
0,210 210,515 715,1065 1065,1335 1335,1655
of like all additional,| like
|比如每一列，它是否为空，

863
00:22:22,890 --> 00:22:24,470
0,305 305,610 780,1070 1070,1280 1280,1580
every single, every single column,

864
00:22:24,470 --> 00:22:25,130
0,240 240,345 345,420 420,510 510,660
whether it could be null

865
00:22:25,130 --> 00:22:27,470
0,120 120,380 1150,1550 1870,2115 2115,2340
or not,| the, the different
|关于偏移量或在哪里找到东西的不同信息，

866
00:22:27,470 --> 00:22:28,790
0,315 315,585 585,795 795,1215 1215,1320
information about the offsets or

867
00:22:28,790 --> 00:22:29,980
0,75 75,165 165,300 300,590 790,1190
where to find things, right,|
|

868
00:22:30,000 --> 00:22:30,815
0,275 275,395 395,575 575,740 740,815
these are all going to
这些都将是存储中的元数据，

869
00:22:30,815 --> 00:22:32,510
0,245 835,1095 1095,1485 1485,1560 1560,1695
be the metadata at the

870
00:22:32,510 --> 00:22:33,470
0,210 210,375 375,555 555,705 705,960
store,| because it's just all
|因为它们都是相同的值域，相同的属性类型，

871
00:22:33,470 --> 00:22:34,745
0,225 225,405 405,660 660,1065 1065,1275
the same value domains or

872
00:22:34,745 --> 00:22:35,950
0,150 150,315 315,575 595,915 915,1205
all the same attribute type,|
|

873
00:22:36,180 --> 00:22:37,295
0,275 275,440 440,650 650,890 890,1115
it's being much less than
它比行存储小得多。

874
00:22:37,295 --> 00:22:38,440
0,165 165,285 285,450 450,755
than a row store.|
|

875
00:22:41,090 --> 00:22:42,820
0,245 245,455 455,820
All right, so,
好的，所以，这里的想法是，

876
00:22:42,820 --> 00:22:43,900
0,210 210,405 405,630 630,900 900,1080
the idea here again,| so
|所以我们回到维基百科的例子，

877
00:22:43,900 --> 00:22:44,395
0,75 75,195 195,330 330,420 420,495
we go back to our

878
00:22:44,395 --> 00:22:46,170
0,390 390,695 1045,1290 1290,1455 1455,1775
Wikipedia example,| we just take
|我们只获取表中的每一列，

879
00:22:48,260 --> 00:22:50,310
0,335 335,670 930,1330 1470,1760 1760,2050
every column for our table|
|

880
00:22:50,840 --> 00:22:51,985
0,260 260,520 690,995 995,1040 1040,1145
and then we're going to
然后将其存储为单独的页面，

881
00:22:51,985 --> 00:22:52,945
0,150 150,285 285,525 525,765 765,960
store that as a separate

882
00:22:52,945 --> 00:22:54,280
0,335
page,

883
00:22:54,320 --> 00:22:55,435
0,320 320,640 690,935 935,1025 1025,1115
right,| so if you go
|如果你回到主机名的示例，

884
00:22:55,435 --> 00:22:57,055
0,120 120,240 240,485 1135,1425 1425,1620
back to the {hostname -}

885
00:22:57,055 --> 00:22:58,525
0,305 475,810 810,990 990,1155 1155,1470
example,| within a single page,
|在单个页面中，我们只存储主机名列的值，

886
00:22:58,525 --> 00:23:00,180
0,375 375,705 705,960 960,1320 1320,1655
again, we're only storing values

887
00:23:00,200 --> 00:23:01,200
0,275 275,380 380,515 515,710 710,1000
for the {hostname -} column,|
|

888
00:23:04,255 --> 00:23:04,945
0,60 60,105 105,225 225,420 420,690
and we'll have separate pages
我们的所有属性都将有单独的页面。

889
00:23:04,945 --> 00:23:07,100
0,365 625,900 900,1095 1095,1475
for all our attributes.|
|

890
00:23:07,920 --> 00:23:08,810
0,260 260,455 455,650 650,755 755,890
So now if we go
所以，如果我们回到这里的 OLAP 查询，

891
00:23:08,810 --> 00:23:11,780
0,240 240,590 640,1040 2440,2685 2685,2970
back to this, the OLAP

892
00:23:11,780 --> 00:23:12,830
0,210 210,465 465,690 690,870 870,1050
query here,| then we're doing
|然后我们进行查找，政府地址每月登录的数量，

893
00:23:12,830 --> 00:23:13,790
0,195 195,450 450,615 615,795 795,960
the lookup the counting number

894
00:23:13,790 --> 00:23:16,115
0,105 105,680 760,1035 1035,1310 1310,1990 1990,2325
of logins per month, {with,for,the} government

895
00:23:16,115 --> 00:23:17,420
0,545
addresses,|
|

896
00:23:17,870 --> 00:23:19,015
0,275 275,455 455,740 740,965 965,1145
the first part {executing,the} query
执行查询的第一部分是获得 hostname ，

897
00:23:19,015 --> 00:23:20,095
0,165 165,360 360,675 675,915 915,1080
is going get the {hostname

898
00:23:20,095 --> 00:23:22,510
0,305 715,975 975,1365 1365,2015 2065,2415
-},| well, that's assuming it's
|好的，这是假设每个属性都有一个页面，

899
00:23:22,510 --> 00:23:24,415
0,195 195,510 510,870 870,1310 1510,1905
one page per attribute,| that's
|它将获取单个页面，

900
00:23:24,415 --> 00:23:25,620
0,135 135,435 435,600 600,855 855,1205
going fetching that one page|
|

901
00:23:26,150 --> 00:23:27,715
0,400 540,890 890,1145 1145,1340 1340,1565
and then doing the scan,
然后执行扫描，只需遍历列，

902
00:23:27,715 --> 00:23:28,800
0,225 225,525 525,675 675,810 810,1085
just ripping through the column|
|

903
00:23:29,300 --> 00:23:30,750
0,335 335,830 830,1055 1055,1205 1205,1450
and identifying all the matches
并识别与该 hostname 匹配的所有内容。

904
00:23:30,830 --> 00:23:32,590
0,335 335,670 1230,1475 1475,1595 1595,1760
for that for that {hostname

905
00:23:32,590 --> 00:23:33,520
0,290
-}.|
|

906
00:23:33,630 --> 00:23:35,915
0,275 275,550 660,1060 1230,1630 1980,2285
And again, I have complete
我已经完全利用了我引入的所有数据，

907
00:23:35,915 --> 00:23:37,220
0,540 540,750 750,960 960,1140 1140,1305
utilization of all the data

908
00:23:37,220 --> 00:23:38,045
0,165 165,270 270,405 405,615 615,825
that I brought in,| because
|因为我只引入了这个查询所需的数据，

909
00:23:38,045 --> 00:23:38,945
0,210 210,405 405,645 645,795 795,900
I'm only bringing in the

910
00:23:38,945 --> 00:23:40,175
0,135 135,300 300,510 510,845 985,1230
data I need for for

911
00:23:40,175 --> 00:23:41,470
0,120 120,425 535,825 825,975 975,1295
this query,| I'm not bringing
|我不会引入我不关心的属性。

912
00:23:41,520 --> 00:23:42,440
0,350 350,485 485,575 575,770 770,920
attributes that I don't care

913
00:23:42,440 --> 00:23:43,340
0,290
about.|
|

914
00:23:44,130 --> 00:23:45,395
0,260 260,395 395,670 840,1145 1145,1265
And then now we'll talk
然后我们将在后面讨论这个，

915
00:23:45,395 --> 00:23:46,115
0,120 120,225 225,420 420,600 600,720
about this later,| how we
|我们如何做，

916
00:23:46,115 --> 00:23:47,735
0,275 955,1215 1215,1305 1305,1395 1395,1620
do,| we talk about query
|我们讨论查询执行，如何进行匹配，

917
00:23:47,735 --> 00:23:49,460
0,255 255,540 540,905 1225,1530 1530,1725
execution, how we match things

918
00:23:49,460 --> 00:23:50,660
0,290 310,630 630,855 855,1035 1035,1200
up,| but assuming I keep
|但是假设我跟踪一个列表，

919
00:23:50,660 --> 00:23:51,455
0,165 165,285 285,405 405,585 585,795
track of a list of,|
|

920
00:23:51,455 --> 00:23:53,165
0,270 270,375 375,905 1195,1515 1515,1710
here's the offsets of the
这是该列中与我的谓词匹配的 tuple 的偏移量。

921
00:23:53,165 --> 00:23:54,170
0,150 150,315 315,540 540,765 765,1005
{tuples -} within this column

922
00:23:54,170 --> 00:23:56,220
0,285 285,555 555,780 780,1280
that match my predicate.|
|

923
00:23:56,320 --> 00:23:57,420
0,275 275,410 410,635 635,860 860,1100
Then I go to now
然后我现在转到 lastLogin 页面，

924
00:23:57,420 --> 00:23:59,120
0,375 375,735 735,1005 1005,1395 1395,1700
to the {lastLogin -} page,|
|

925
00:23:59,470 --> 00:24:00,870
0,260 260,485 485,820 990,1265 1265,1400
go fetch that, and again,
去取那个只有我们需要的数据，

926
00:24:00,870 --> 00:24:01,650
0,120 120,270 270,450 450,630 630,780
that only has data that

927
00:24:01,650 --> 00:24:02,880
0,120 120,380 700,945 945,1065 1065,1230
we need,| and then now
|然后，现在我知道如何跳到匹配 hostname 的不同偏移量，

928
00:24:02,880 --> 00:24:03,885
0,165 165,330 330,540 540,750 750,1005
I know how to jump

929
00:24:03,885 --> 00:24:05,985
0,365 805,1050 1050,1185 1185,1725 1725,2100
to the different offsets of

930
00:24:05,985 --> 00:24:07,335
0,270 270,600 600,810 810,1110 1110,1350
the matching {hostnames -}| to
|以找到正确的 login 偏移量，即登录时间戳，

931
00:24:07,335 --> 00:24:08,370
0,240 240,450 450,660 660,915 915,1035
find the right offset for

932
00:24:08,370 --> 00:24:10,455
0,90 90,560 1330,1590 1590,1905 1905,2085
the login, the login {timestamp

933
00:24:10,455 --> 00:24:11,340
0,305
-},|
|

934
00:24:11,340 --> 00:24:12,270
0,180 180,300 300,615 615,795 795,930
and then compute whatever I
然后计算出查询所需的内容。

935
00:24:12,270 --> 00:24:13,580
0,150 150,285 285,375 375,650
need for the query.|
|

936
00:24:16,270 --> 00:24:17,500
0,215 215,305 305,610
This is clear?|
这里清楚了吗？|

937
00:24:18,770 --> 00:24:19,450
0,260 260,365 365,470 470,575 575,680
Who here has heard a
今天在座的各位，有谁之前听说列存储？

938
00:24:19,450 --> 00:24:21,340
0,465 465,660 660,795 795,1070
{column,store} before {} today?|
|

939
00:24:22,320 --> 00:24:23,960
0,275 275,410 410,725 725,1090
Less than 10%, okay.|
少于 10% ，好的。|

940
00:24:24,220 --> 00:24:25,340
0,290 290,515 515,725 725,860 860,1120
Again, so this is a,|
所以，这是一种，|

941
00:24:26,500 --> 00:24:27,510
0,290 290,440 440,545 545,755 755,1010
it sort of seems obvious
这似乎是显而易见的，

942
00:24:27,510 --> 00:24:28,815
0,290 490,735 735,855 855,1080 1080,1305
now,| that this is clearly
|这显然是你想要做的方式，

943
00:24:28,815 --> 00:24:29,325
0,105 105,195 195,315 315,420 420,510
the way you want to

944
00:24:29,325 --> 00:24:31,440
0,105 105,255 255,545
do this,| but,
|但是，在 15 年前，在 20 年前，

945
00:24:31,440 --> 00:24:33,120
0,260 670,945 945,1155 1155,1440 1440,1680
before up to 15 years

946
00:24:33,120 --> 00:24:34,755
0,285 285,555 555,720 720,1010 1360,1635
ago, 20 years ago,| this
|任何数据库系统都不是这样构建的，

947
00:24:34,755 --> 00:24:35,970
0,180 180,390 390,690 690,1005 1005,1215
is not how any database

948
00:24:35,970 --> 00:24:36,795
0,180 180,375 375,555 555,705 705,825
system was actually built,| it
|这是非常罕见的。

949
00:24:36,795 --> 00:24:40,540
0,120 120,315 315,540 540,845
was very, very rare.|
|

950
00:24:40,680 --> 00:24:41,580
0,150 150,330 330,555 555,720 720,900

951
00:24:41,580 --> 00:24:42,080
0,225 225,450

952
00:24:45,560 --> 00:24:46,415
0,345 345,450 450,555 555,645 645,855

953
00:24:46,415 --> 00:24:47,225
0,240 240,435 435,570 570,615 615,810

954
00:24:47,225 --> 00:24:48,080
0,210 210,465 465,815

955
00:24:50,680 --> 00:24:52,200
0,365 365,590 590,770 770,1090 1260,1520
Sorry, your question is,| if
抱歉，你的问题是，|如果我回到行存储的例子，

956
00:24:52,200 --> 00:24:52,935
0,105 105,195 195,315 315,525 525,735
I go back to the

957
00:24:52,935 --> 00:24:54,560
0,210 210,465 465,785
row store example,|
|

958
00:24:54,560 --> 00:24:55,800
0,260

959
00:24:57,610 --> 00:24:58,905
0,260 260,380 380,640 870,1130 1130,1295
this one here,| your question
这里的这个，|你的问题是，

960
00:24:58,905 --> 00:25:00,510
0,180 180,435 435,815 1105,1410 1410,1605
is, what,| if even in
|即使在这里，我是否也必须。

961
00:25:00,510 --> 00:25:01,320
0,195 195,390 390,525 525,630 630,810
this one, do I have

962
00:25:01,320 --> 00:25:02,520
0,320
to.|
|

963
00:25:03,000 --> 00:25:04,065
0,135 135,300 300,570 570,870 870,1065

964
00:25:04,065 --> 00:25:04,920
0,240 240,605

965
00:25:04,920 --> 00:25:05,550
0,225 225,345 345,450 450,555 555,630

966
00:25:05,550 --> 00:25:06,160
0,120 120,345 345,570

967
00:25:07,780 --> 00:25:09,140
0,335 335,670
Oh, like,
哦，比如，这个，

968
00:25:09,440 --> 00:25:10,860
0,395 395,790
this one,|
|

969
00:25:11,740 --> 00:25:15,660
0,400 510,770 770,1030 2040,2440 3660,3920
literally, okay, yes, why.| {}
从字面上看，是的，为什么。|

970
00:25:15,660 --> 00:25:16,490
0,90 90,150 150,270 270,495 495,830

971
00:25:16,600 --> 00:25:17,460
0,305 305,610

972
00:25:18,800 --> 00:25:19,825
0,305 305,485 485,680 680,875 875,1025

973
00:25:19,825 --> 00:25:21,300
0,405 405,755

974
00:25:22,640 --> 00:25:24,030
0,350 350,680 680,920 920,1085 1085,1390
Oh, okay. The question is,|
哦，好的，问题是，|

975
00:25:24,530 --> 00:25:25,960
0,335 335,560 560,770 770,1000 1110,1430
I said there's some index,|
我说过有一些索引，|

976
00:25:25,960 --> 00:25:26,560
0,165 165,315 315,420 420,510 510,600
I didn't say what it
我没说那是什么，

977
00:25:26,560 --> 00:25:27,640
0,195 195,420 420,525 525,795 795,1080
was,| there's some magic way
|有一种神奇的方式可以说，

978
00:25:27,640 --> 00:25:28,960
0,165 165,440 880,1140 1140,1230 1230,1320
to say,| look at the
|看看 WHERE 子句，

979
00:25:28,960 --> 00:25:29,890
0,165 165,480 480,690 690,780 780,930
WHERE clause,| where it says
|它说 userName 等于某个东西，

980
00:25:29,890 --> 00:25:32,455
0,450 450,675 675,950 1960,2340 2340,2565
userName equals something,| because you
|因为你会走到 userName 的索引，

981
00:25:32,455 --> 00:25:33,085
0,105 105,210 210,345 345,510 510,630
would go to index on

982
00:25:33,085 --> 00:25:34,600
0,425 445,690 690,825 825,1115 1195,1515
userName| and I magically got
|而我神奇地得到了单一的记录，

983
00:25:34,600 --> 00:25:36,370
0,165 165,315 315,585 585,950 1510,1770
to the single record,| again,
|record ID ， page ID 和偏移量，

984
00:25:36,370 --> 00:25:37,440
0,165 165,375 375,600 600,795 795,1070
the record ID, page ID

985
00:25:37,550 --> 00:25:39,055
0,365 365,730 1080,1325 1325,1400 1400,1505
and offset,| how do I
|我怎么做的，

986
00:25:39,055 --> 00:25:40,435
0,135 135,395 865,1200 1200,1260 1260,1380
do that,| that's what the
|这就是索引的作用，

987
00:25:40,435 --> 00:25:41,430
0,165 165,360 360,585 585,705 705,995
index does,| that's next week,
|那是下个星期，

988
00:25:41,940 --> 00:25:43,470
0,380 760,1095 1095,1215 1215,1365 1365,1530
right,| it's just a key
|这只是一个键值，

989
00:25:43,470 --> 00:25:45,915
0,290 1630,1935 1935,2085 2085,2205 2205,2445
value,| you think about a
|你可以想象成键值映射或关联数组，

990
00:25:45,915 --> 00:25:47,025
0,240 240,480 480,735 735,900 900,1110
key value map or associate

991
00:25:47,025 --> 00:25:48,435
0,195 195,455 625,885 885,1095 1095,1410
{array -},| for given key,
|对于给出的 userName ，给出匹配的 record ID 或 record IDs（如果不是唯一的），

992
00:25:48,435 --> 00:25:50,340
0,255 255,815 1045,1380 1380,1665 1665,1905
the userName, give be the

993
00:25:50,340 --> 00:25:52,200
0,210 210,530 760,1020 1020,1185 1185,1860
record ID or record IDs

994
00:25:52,200 --> 00:25:53,760
0,210 210,375 375,510 510,800 1210,1560
if it's non unique, that

995
00:25:53,760 --> 00:25:55,920
0,375 375,650 1150,1550 1750,2040 2040,2160
matched this,| then then so
|我的索引给我 record ID ，

996
00:25:55,920 --> 00:25:57,045
0,75 75,195 195,435 435,800 850,1125
I get that my index

997
00:25:57,045 --> 00:25:57,860
0,150 150,285 285,375 375,510 510,815
gives me the record ID,|
|

998
00:25:58,060 --> 00:25:58,860
0,320 320,395 395,470 470,590 590,800
I look at my page
我查看我的页面目录，

999
00:25:58,860 --> 00:26:00,315
0,500 610,930 930,1125 1125,1275 1275,1455
directory,| said okay, I need
|说，好的，我需要页面 1 2 3 ，

1000
00:26:00,315 --> 00:26:01,470
0,225 225,420 420,585 585,810 810,1155
page one, two, three,| where's
|它在哪里，

1001
00:26:01,470 --> 00:26:02,565
0,260 400,690 690,810 810,960 960,1095
that,| it's on here on,
|它要么在内存中，要么在磁盘上，

1002
00:26:02,565 --> 00:26:03,360
0,165 165,330 330,525 525,675 675,795
it's either in memory or

1003
00:26:03,360 --> 00:26:04,125
0,90 90,360 360,450 450,600 600,765
on disk,| I go get
|我去拿它，

1004
00:26:04,125 --> 00:26:05,370
0,275 565,840 840,1005 1005,1140 1140,1245
it| and now I have
|现在我有了 record ID 中的插槽编号，

1005
00:26:05,370 --> 00:26:06,120
0,135 135,330 330,525 525,675 675,750
the slot number from the

1006
00:26:06,120 --> 00:26:07,110
0,150 150,450 450,675 675,825 825,990
record ID| and I look
|我查看那个页面，并跳到那个插槽，

1007
00:26:07,110 --> 00:26:07,920
0,105 105,225 225,435 435,660 660,810
in that page and jump

1008
00:26:07,920 --> 00:26:09,090
0,90 90,210 210,530 850,1095 1095,1170
to that slot,| get what
|获得我需要的东西，

1009
00:26:09,090 --> 00:26:09,760
0,90 90,350
I need,|
|

1010
00:26:09,760 --> 00:26:10,480
0,180 180,300 300,495 495,630 630,720
so that allows me to
所以，这使我可以准确地跳到我需要的页面，

1011
00:26:10,480 --> 00:26:11,965
0,240 240,620 970,1200 1200,1305 1305,1485
jump exactly to the page

1012
00:26:11,965 --> 00:26:12,850
0,165 165,360 360,540 540,675 675,885
I need| and then within
|然后在该页面中找到我需要的记录，

1013
00:26:12,850 --> 00:26:14,155
0,210 210,500 580,855 855,1065 1065,1305
that page go to get

1014
00:26:14,155 --> 00:26:15,360
0,305 355,630 630,795 795,945 945,1205
exactly the record I need,|
|

1015
00:26:16,240 --> 00:26:18,015
0,380 380,710 710,1060 1230,1505 1505,1775
but again, like I only
但是同样，如果我只需要一个，

1016
00:26:18,015 --> 00:26:20,805
0,375 375,755 1795,2100 2100,2505 2505,2790
need one,| assuming userNames are
|假设 userName 是唯一的，

1017
00:26:20,805 --> 00:26:22,320
0,395 655,915 915,1095 1095,1320 1320,1515
unique,| I only need one
|我只需要一个 userName ，

1018
00:26:22,320 --> 00:26:24,540
0,530
userName,|
|

1019
00:26:24,670 --> 00:26:25,335
0,245 245,350 350,470 470,560 560,665
but I had to go
但我不得不去取，我实际上并不需要的所有其他行。

1020
00:26:25,335 --> 00:26:26,175
0,180 180,315 315,435 435,585 585,840
fetch all these other rows

1021
00:26:26,175 --> 00:26:27,520
0,90 90,315 315,465 465,725
I don't actually need.|
|

1022
00:26:29,290 --> 00:26:31,170
0,365 365,730 1050,1325 1325,1580 1580,1880
Yes.| { - - -}
是的。|

1023
00:26:31,170 --> 00:26:33,210
0,210 210,375 375,630 630,1010 1720,2040

1024
00:26:33,210 --> 00:26:34,410
0,210 210,450 450,795 795,1080 1080,1200

1025
00:26:34,410 --> 00:26:36,120
0,230 280,1065 1065,1215 1215,1440 1440,1710

1026
00:26:36,120 --> 00:26:38,130
0,320 430,825 825,1200 1200,1580 1630,2010

1027
00:26:38,130 --> 00:26:39,830
0,380 490,780 780,930 930,1365 1365,1700
|

1028
00:26:40,650 --> 00:26:42,370
0,400 420,650 650,880 990,1250 1250,1720
{} {What,do} {you,mean}, {slightly,more} implementation?|
你说的是什么意思，稍微更多地实现？|

1029
00:26:42,480 --> 00:26:44,195
0,290 290,580 840,1145 1310,1505 1505,1715

1030
00:26:44,195 --> 00:26:46,115
0,105 105,225 225,515 1015,1415 1585,1920

1031
00:26:46,115 --> 00:26:47,000
0,210 210,360 360,525 525,690 690,885

1032
00:26:47,000 --> 00:26:48,730
0,255 255,555 555,915 915,1425 1425,1730

1033
00:26:48,780 --> 00:26:50,405
0,320 320,575 575,940 1230,1505 1505,1625

1034
00:26:50,405 --> 00:26:51,260
0,105 105,255 255,450 450,675 675,855

1035
00:26:51,260 --> 00:26:52,850
0,195 195,405 405,770 1120,1425 1425,1590

1036
00:26:52,850 --> 00:26:53,690
0,150 150,375 375,555 555,675 675,840

1037
00:26:53,690 --> 00:26:55,460
0,195 195,500 910,1200 1200,1485 1485,1770

1038
00:26:55,460 --> 00:26:56,420
0,180 180,405 405,615 615,750 750,960

1039
00:26:56,420 --> 00:26:57,710
0,225 225,360 360,750 750,1050 1050,1290

1040
00:26:57,710 --> 00:26:59,060
0,290 310,600 600,890 970,1245 1245,1350

1041
00:26:59,060 --> 00:27:00,340
0,105 105,285 285,585 585,930 930,1280

1042
00:27:01,040 --> 00:27:02,395
0,245 245,365 365,575 575,910 1050,1355

1043
00:27:02,395 --> 00:27:04,230
0,210 210,510 510,905 1015,1415 1435,1835

1044
00:27:05,060 --> 00:27:06,240
0,275 275,410 410,560 560,815 815,1180

1045
00:27:08,390 --> 00:27:09,610
0,400 630,905 905,1040 1040,1145 1145,1220
{} I would say they
我想说它们是一样难的，

1046
00:27:09,610 --> 00:27:12,480
0,75 75,270 270,510 510,800
are equally as hard,|
|

1047
00:27:12,770 --> 00:27:13,810
0,305 305,470 470,710 710,890 890,1040
if you don't care about
如果你不关心其他一堆保护措施，

1048
00:27:13,810 --> 00:27:16,405
0,150 150,440 640,960 960,1430 2320,2595
other bunch other protections,| we're
|我们不是在讨论事务，

1049
00:27:16,405 --> 00:27:17,460
0,60 60,135 135,240 240,515 655,1055
not talking about transactions,| but,
|但是，如果你不关心这些事情，

1050
00:27:18,760 --> 00:27:19,350
0,230 230,290 290,425 425,485 485,590
if you don't care about

1051
00:27:19,350 --> 00:27:21,300
0,180 180,500 1090,1395 1395,1650 1650,1950
those things,| then yeah, I
|那么，是的，我同意行存储将更容易实现，

1052
00:27:21,300 --> 00:27:22,215
0,210 210,345 345,555 555,750 750,915
would agree that a row

1053
00:27:22,215 --> 00:27:23,265
0,150 150,240 240,315 315,545 655,1050
store would be easier to

1054
00:27:23,265 --> 00:27:25,240
0,395
implement,|
|

1055
00:27:26,110 --> 00:27:27,540
0,305 305,470 470,575 575,820 1080,1430
again, you just like everything's
所有东西都在一起，那么是的，

1056
00:27:27,540 --> 00:27:28,310
0,135 135,315 315,435 435,525 525,770
here, I assume it all

1057
00:27:28,360 --> 00:27:29,780
0,335 335,440 440,575 575,850 1020,1420
packs in, then yeah,| then,
|假设每条记录都可以放在一个页面中，忽略溢出，

1058
00:27:29,800 --> 00:27:31,785
0,365 365,730 1170,1505 1505,1775 1775,1985
assuming that every record can

1059
00:27:31,785 --> 00:27:32,600
0,120 120,240 240,360 360,510 510,815
fit into a single page,

1060
00:27:32,740 --> 00:27:34,710
0,470 470,1060 1350,1595 1595,1730 1730,1970
ignoring overflows,| then a {row,store
|那么行存储可能会更容易，是的。

1061
00:27:34,710 --> 00:27:35,940
0,195 195,405 405,680 700,1005 1005,1230
-} would be potentially easier,

1062
00:27:35,940 --> 00:27:36,900
0,320
yes.|
|

1063
00:27:37,970 --> 00:27:39,280
0,400 540,800 800,950 950,1145 1145,1310
Yes.| { - - -}
是的。|

1064
00:27:39,280 --> 00:27:41,070
0,270 270,465 465,770 850,1230 1230,1790

1065
00:27:42,480 --> 00:27:44,060
0,400 450,845 845,1240

1066
00:27:45,470 --> 00:27:47,970
0,215 215,290 290,470 470,790 2100,2500
So his question is,| is
所以，他的问题是，|数据库系统存储是行存储还是列存储，

1067
00:27:48,080 --> 00:27:51,250
0,395 395,710 710,1030 2790,3035 3035,3170
the fact, that the database

1068
00:27:51,250 --> 00:27:52,060
0,195 195,360 360,465 465,600 600,810
system store is a row

1069
00:27:52,060 --> 00:27:52,900
0,180 180,315 315,465 465,660 660,840
store versus a column store,|
|

1070
00:27:52,900 --> 00:27:53,920
0,105 105,225 225,390 390,690 690,1020
is this something that's configurable
这是可以对表配置的东西，

1071
00:27:53,920 --> 00:27:55,980
0,180 180,500 1060,1460 1480,1770 1770,2060
by table| or is this
|还是一种全有或全无？

1072
00:27:56,120 --> 00:27:56,935
0,365 365,485 485,560 560,665 665,815
it sort of all or

1073
00:27:56,935 --> 00:27:58,760
0,275
nothing?|
|

1074
00:27:58,980 --> 00:28:00,980
0,400 480,880 1560,1835 1835,1940 1940,2000
Most systems are going to
大多数系统将只使用行或列，

1075
00:28:00,980 --> 00:28:03,620
0,230 940,1260 1260,1580 1750,2150 2320,2640
be row only or column

1076
00:28:03,620 --> 00:28:07,250
0,320 2380,2730 2730,2925 2925,3420 3420,3630
only,| the, the HTAP stuff,
|HTAP 的东西，混合的东西，试图同时做到这两种，

1077
00:28:07,250 --> 00:28:08,090
0,150 150,435 435,585 585,735 735,840
the hybrid stuff that sort

1078
00:28:08,090 --> 00:28:08,825
0,90 90,240 240,375 375,555 555,735
of tries to do sort

1079
00:28:08,825 --> 00:28:13,460
0,245 685,1085 2995,3395
of both,| the,
|所以通常你会说，

1080
00:28:13,650 --> 00:28:15,250
0,320 320,640 870,1115 1115,1280 1280,1600
so typically you would say,|
|

1081
00:28:15,570 --> 00:28:16,880
0,305 305,440 440,670 780,1085 1085,1310
yeah, so in most systems
是的，所以在大多数系统中你会说，

1082
00:28:16,880 --> 00:28:18,320
0,150 150,240 240,500
you would say,|
|

1083
00:28:18,510 --> 00:28:19,670
0,320 320,575 575,845 845,995 995,1160
I know I'm using the
我知道我在用这个系统，它将是一个列存储，

1084
00:28:19,670 --> 00:28:20,180
0,150 150,360 360,420 420,465 465,510
system, it's going to be

1085
00:28:20,180 --> 00:28:21,290
0,90 90,300 300,650 730,960 960,1110
a column store,| so I'll
|所以我将在那里存储所有内容，

1086
00:28:21,290 --> 00:28:24,305
0,195 195,390 390,510 510,770 2740,3015
store everything in there,| the
|表将成为列，

1087
00:28:24,305 --> 00:28:26,350
0,165 165,285 285,515 565,1175 1645,2045
tables will be column,| now,
|尽管我说过。

1088
00:28:27,600 --> 00:28:28,720
0,290 290,425 425,575 575,800 800,1120
even though I said, like

1089
00:28:28,800 --> 00:28:30,120
0,400
the,|
|

1090
00:28:30,480 --> 00:28:32,045
0,400 570,890 890,1115 1115,1370 1370,1565
like even though it's a,
尽管它是一个列存储，

1091
00:28:32,045 --> 00:28:34,000
0,270 270,375 375,615 615,965 1555,1955
it's a column store| and
|我们将针对只读查询进行优化，

1092
00:28:34,110 --> 00:28:35,080
0,275 275,320 320,365 365,530 530,970
we're going to be optimized

1093
00:28:35,130 --> 00:28:36,550
0,335 335,560 560,725 725,920 920,1420
for for {readonly -} queries,|
|

1094
00:28:36,750 --> 00:28:37,970
0,365 365,650 650,815 815,980 980,1220
people obviously want to update
人们显然想要更新数据，

1095
00:28:37,970 --> 00:28:40,535
0,320 760,1125 1125,1380 1380,1670 2290,2565
data, right,| and so the
|所以，通常的解决方法是，

1096
00:28:40,535 --> 00:28:41,495
0,210 210,405 405,585 585,780 780,960
way you typically get around

1097
00:28:41,495 --> 00:28:43,055
0,240 240,575 835,1125 1125,1350 1350,1560
that is,| these systems would
|这些系统会有一种行存储缓冲区，

1098
00:28:43,055 --> 00:28:44,645
0,255 255,635 1015,1305 1305,1440 1440,1590
have a, a sort of

1099
00:28:44,645 --> 00:28:47,330
0,285 285,665 1075,1500 1500,1745 2425,2685
row store buffer area,| and
|它通常是日志结构的，

1100
00:28:47,330 --> 00:28:49,450
0,195 195,530 550,900 900,1460 1720,2120
it typically {log-structured -},| where
|如果我有任何更新，

1101
00:28:49,650 --> 00:28:50,890
0,260 260,395 395,560 560,845 845,1240
if I have any updates,|
|

1102
00:28:50,940 --> 00:28:52,540
0,350 350,605 605,830 830,1150 1200,1600
I apply them to that
我会将它们应用到行部分，

1103
00:28:52,920 --> 00:28:54,650
0,305 305,590 590,830 830,1090 1170,1730
row portion| and then periodically
|然后定期将它们合并到列存储中，

1104
00:28:54,650 --> 00:28:55,430
0,75 75,180 180,360 360,660 660,780
I would then merge them

1105
00:28:55,430 --> 00:28:57,815
0,225 225,450 450,660 660,1010 1990,2385
into the column store,| that's
|这是解决这一问题的一种方法，

1106
00:28:57,815 --> 00:29:00,160
0,195 195,450 450,600 600,845
one approach to this,|
|

1107
00:29:00,300 --> 00:29:01,385
0,485 485,590 590,680 680,830 830,1085
Oracle does a different approach,|
Oracle 采用了一种不同的方法，|

1108
00:29:01,385 --> 00:29:02,900
0,335 595,885 885,1110 1110,1320 1320,1515
where the row store is
其中行存储被视为数据库的主存储位置，

1109
00:29:02,900 --> 00:29:04,310
0,195 195,360 360,650 790,1155 1155,1410
considered the primary storage location

1110
00:29:04,310 --> 00:29:05,480
0,120 120,180 180,410 760,1020 1020,1170
of the database,| but then
|但随后他们将以列存储格式制作表的副本，

1111
00:29:05,480 --> 00:29:07,270
0,210 210,345 345,555 555,890 1390,1790
they'll make a copy of

1112
00:29:07,500 --> 00:29:08,780
0,275 275,425 425,700 900,1145 1145,1280
of your tables in a

1113
00:29:08,780 --> 00:29:10,325
0,225 225,450 450,740 1120,1380 1380,1545
column store format| and they
|并负责为你保持更新，

1114
00:29:10,325 --> 00:29:11,330
0,285 285,465 465,600 600,765 765,1005
they're responsible for keeping the

1115
00:29:11,330 --> 00:29:12,185
0,165 165,270 270,465 465,690 690,855
sort of things updated for

1116
00:29:12,185 --> 00:29:13,430
0,275 385,675 675,885 885,1095 1095,1245
you,| so different approach, these
|所以不同的方法，不同的东西，

1117
00:29:13,430 --> 00:29:15,710
0,165 165,375 375,570 570,860 1990,2280
different things,| but typically if
|但通常如果系统支持我想用行存储而不是列存储，

1118
00:29:15,710 --> 00:29:16,610
0,135 135,345 345,600 600,750 750,900
the system supports I want

1119
00:29:16,610 --> 00:29:17,405
0,180 180,330 330,480 480,615 615,795
row store versus a column

1120
00:29:17,405 --> 00:29:18,845
0,285 285,635 835,1095 1095,1260 1260,1440
store,| you, you could define
|你可以在每张表的基础上定义它，

1121
00:29:18,845 --> 00:29:19,630
0,90 90,150 150,240 240,540 540,785
it on a {per,table} basis,|
|

1122
00:29:19,950 --> 00:29:21,350
0,400 570,860 860,1085 1085,1310 1310,1400
but most systems don't do
但大多数系统不这样做。

1123
00:29:21,350 --> 00:29:22,260
0,260
that.|
|

1124
00:29:22,540 --> 00:29:26,100
0,400
Yes.|
是的。|

1125
00:29:29,580 --> 00:29:31,220
0,255 255,390 390,555 555,860

1126
00:29:34,300 --> 00:29:35,530
0,285 285,570 570,855 855,1050 1050,1230

1127
00:29:35,530 --> 00:29:36,680
0,240 240,405 405,510 510,980

1128
00:29:37,080 --> 00:29:38,180
0,275 275,470 470,710 710,905 905,1100
This question is,| if I
这个问题是，|如果我有和列一样多的磁盘，

1129
00:29:38,180 --> 00:29:39,380
0,270 270,495 495,705 705,1110 1110,1200
have as many discs as

1130
00:29:39,380 --> 00:29:41,330
0,120 120,380 490,1100 1420,1725 1725,1950
I have columns,| assuming I
|假设我在列存储表中拆分，

1131
00:29:41,330 --> 00:29:42,470
0,210 210,495 495,750 750,870 870,1140
break up in a column

1132
00:29:42,470 --> 00:29:44,105
0,135 135,255 255,530 1150,1410 1410,1635
store {} table| and every
|每个属性转到单独的磁盘，

1133
00:29:44,105 --> 00:29:44,920
0,255 255,390 390,495 495,570 570,815
attribute goes to a separate,

1134
00:29:45,510 --> 00:29:47,020
0,305 305,440 440,530 530,790 840,1510
goes to a separate disk,|
|

1135
00:29:47,250 --> 00:29:47,990
0,245 245,365 365,470 470,575 575,740
would that be as fast
这会和行存储一样快吗。

1136
00:29:47,990 --> 00:29:50,735
0,135 135,255 255,435 435,740 2470,2745
as a row store.| Well,
|不，因为你必须要做，

1137
00:29:50,735 --> 00:29:51,880
0,240 240,480 480,630 630,825 825,1145
no, because you have to,|
|

1138
00:29:52,110 --> 00:29:52,745
0,275 275,395 395,485 485,560 560,635
you still have to do
你还是要做那个分裂，然后写出来，

1139
00:29:52,745 --> 00:29:54,290
0,225 225,600 600,945 945,1290 1290,1545
that, that that splitting apart

1140
00:29:54,290 --> 00:29:55,370
0,315 315,570 570,705 705,825 825,1080
and writing it all out,

1141
00:29:55,370 --> 00:29:57,740
0,380 1270,1545 1545,1820 1930,2235 2235,2370
right,| and then you also
|然后你也会有更多的内存压力，

1142
00:29:57,740 --> 00:29:58,715
0,90 90,270 270,525 525,780 780,975
would have more pressure in

1143
00:29:58,715 --> 00:30:01,060
0,275 355,755
memory,| because,
|因为，假设我有一千个属性，

1144
00:30:01,100 --> 00:30:02,200
0,275 275,455 455,695 695,890 890,1100
because again, say I have

1145
00:30:02,200 --> 00:30:04,315
0,240 240,530 580,1040 1660,1920 1920,2115
a thousand attributes,| so now
|所以现在，如果我必须更新一千个页面，

1146
00:30:04,315 --> 00:30:05,035
0,180 180,285 285,390 390,555 555,720
if I have to update

1147
00:30:05,035 --> 00:30:07,420
0,120 120,395 415,815 1285,1685 2035,2385
a thousand pages,| I have
|我的缓冲池中有一千个页面，

1148
00:30:07,420 --> 00:30:08,425
0,270 270,495 495,630 630,735 735,1005
thousand pages in my buffer

1149
00:30:08,425 --> 00:30:09,625
0,275 295,555 555,705 705,945 945,1200
pool| to do the update,
|进行更新，

1150
00:30:09,625 --> 00:30:12,640
0,180 180,455 1105,1505 2605,2925 2925,3015
to put each,| updating each
|使用一个新的属性更新它们，

1151
00:30:12,640 --> 00:30:13,180
0,90 90,165 165,255 255,330 330,540
of them with a new

1152
00:30:13,180 --> 00:30:14,245
0,405 405,615 615,765 765,945 945,1065
attribute| and then write them
|然后将它们全部写出来，

1153
00:30:14,245 --> 00:30:15,220
0,120 120,395
all out,

1154
00:30:15,340 --> 00:30:17,330
0,395 395,790 810,1160 1160,1510 1590,1990
right,| typically, again, doing updates
|通常，在列存储系统中更新，

1155
00:30:17,560 --> 00:30:18,960
0,275 275,425 425,650 650,1000 1170,1400
in a, in a, in

1156
00:30:18,960 --> 00:30:20,190
0,120 120,360 360,615 615,900 900,1230
a column store system| without
|在没有我刚才提到的这种缓冲区的情况下，

1157
00:30:20,190 --> 00:30:21,165
0,225 225,330 330,450 450,765 765,975
this sort of buffer thing

1158
00:30:21,165 --> 00:30:22,800
0,195 195,330 330,605 985,1380 1380,1635
I just mentioned| is always
|总是很慢的。

1159
00:30:22,800 --> 00:30:24,260
0,90 90,135 135,225 225,500
going to be slow.|
|

1160
00:30:25,590 --> 00:30:27,280
0,400
Yes.|
是的。|

1161
00:30:32,050 --> 00:30:32,955
0,290 290,440 440,605 605,785 785,905
{} Her question is,| what
她的问题是，|在行存储中，什么是与 null bitmap 相对应的，

1162
00:30:32,955 --> 00:30:34,140
0,195 195,405 405,630 630,1005 1005,1185
is the null bitmap is

1163
00:30:34,140 --> 00:30:36,195
0,165 165,555 555,900 900,1280 1690,2055
there equivalence in, {} in,

1164
00:30:36,195 --> 00:30:37,665
0,365 505,780 780,945 945,1215 1215,1470
{} in row store,| yeah,
|是的，我们上节课讨论过了，

1165
00:30:37,665 --> 00:30:38,630
0,195 195,375 375,510 510,675 675,965
we discussed this last class,|
|

1166
00:30:38,800 --> 00:30:40,995
0,305 305,610 960,1360 1830,2120 2120,2195
it basically {}, it's a
它是一种表示哪个属性为空的方式，

1167
00:30:40,995 --> 00:30:42,165
0,120 120,225 225,455 505,885 885,1170
way to represent which attribute

1168
00:30:42,165 --> 00:30:44,460
0,150 150,515 1075,1410 1410,1745 2005,2295
is null, right,| so I'm
|我没有在这里画出来，

1169
00:30:44,460 --> 00:30:45,240
0,90 90,255 255,405 405,585 585,780
not drawing here,| but the
|上一节课的 header ，图表，

1170
00:30:45,240 --> 00:30:46,130
0,120 120,225 225,495 495,615 615,890
header, the diagram last class,|
|

1171
00:30:46,390 --> 00:30:47,685
0,275 275,425 425,845 845,1070 1070,1295
in the header of every
在每行的 header 中，

1172
00:30:47,685 --> 00:30:49,095
0,365 655,930 930,990 990,1110 1110,1410
row,| there'll be a bitmap
|都有一个 bitmap ，说明哪个属性是空的，

1173
00:30:49,095 --> 00:30:51,825
0,135 135,395 1825,2220 2220,2550 2550,2730
and says which attribute is

1174
00:30:51,825 --> 00:30:53,565
0,270 270,450 450,695 835,1235 1315,1740
null or not, right,| that's
|这是一种你可以做到的常规的方法，

1175
00:30:53,565 --> 00:30:54,330
0,195 195,420 420,570 570,645 645,765
one approach to do it

1176
00:30:54,330 --> 00:30:55,920
0,120 120,240 240,465 465,800 1300,1590
in this common one,| you
|你可以这样做，

1177
00:30:55,920 --> 00:30:57,135
0,165 165,440 550,915 915,1125 1125,1215
could {do,this},| we talk about
|我们谈论特定值或每个属性，

1178
00:30:57,135 --> 00:30:58,890
0,150 150,390 390,725 1195,1485 1485,1755
the special value or each

1179
00:30:58,890 --> 00:30:59,430
0,240 240,315 315,405 405,480 480,540
attribute,| you could have a
|你可以在它前面放一个小标志，

1180
00:30:59,430 --> 00:31:00,570
0,230 460,765 765,930 930,1050 1050,1140
little flag in front of

1181
00:31:00,570 --> 00:31:01,770
0,230 490,750 750,930 930,1080 1080,1200
it,| the null bitmap that
|null bitmap 基本上表示属性，

1182
00:31:01,770 --> 00:31:03,525
0,225 225,590 940,1400 1420,1650 1650,1755
basically says attribute,| you know
|对于这个 tuple ，属性一是空，属性二是空，

1183
00:31:03,525 --> 00:31:04,365
0,120 120,255 255,420 420,600 600,840
for this {tuple -}, attribute

1184
00:31:04,365 --> 00:31:05,265
0,150 150,300 300,555 555,780 780,900
one is null, attribute two

1185
00:31:05,265 --> 00:31:06,615
0,105 105,425 745,1005 1005,1185 1185,1350
is null| and so think
|所以想一想，

1186
00:31:06,615 --> 00:31:07,610
0,90 90,335 385,630 630,735 735,995
of that,| instead of having
|不是在每个 tuple 的 header 中有 bitmap ，

1187
00:31:07,630 --> 00:31:09,360
0,320 320,770 770,1150
that bitmap per,

1188
00:31:09,360 --> 00:31:11,160
0,165 165,255 255,525 525,1190 1540,1800
in the header {per,tuple},| in
|在列存储中，对于整个列，这是 null bitmap 。

1189
00:31:11,160 --> 00:31:12,480
0,135 135,345 345,680 940,1185 1185,1320
the column store, for the

1190
00:31:12,480 --> 00:31:13,590
0,240 240,570 570,885 885,975 975,1110
entire column, here's the null

1191
00:31:13,590 --> 00:31:14,580
0,380
bitmap.|
|

1192
00:31:17,060 --> 00:31:18,340
0,400
Yes.|
是的。|

1193
00:31:18,340 --> 00:31:19,315
0,210 210,435 435,705 705,840 840,975
For an index in a

1194
00:31:19,315 --> 00:31:21,025
0,300 300,615 615,795 795,1055 1435,1710

1195
00:31:21,025 --> 00:31:22,240
0,135 135,300 300,555 555,1065 1065,1215

1196
00:31:22,240 --> 00:31:23,155
0,120 120,315 315,540 540,735 735,915

1197
00:31:23,155 --> 00:31:24,000
0,165 165,390 390,480 480,585 585,845

1198
00:31:26,080 --> 00:31:27,300
0,260 260,440 440,760 810,1070 1070,1220
His question is,| in a
他的问题是，|在列存储中，

1199
00:31:27,300 --> 00:31:28,760
0,270 270,650
column store,|
|

1200
00:31:29,930 --> 00:31:30,835
0,290 290,620 620,710 710,785 785,905
in {column,store}, what does the
在列存储中，索引是做什么的，

1201
00:31:30,835 --> 00:31:32,425
0,210 210,420 420,695 955,1305 1305,1590
index actually do,| so some
|所以一些 OLAP 系统是列存储，

1202
00:31:32,425 --> 00:31:34,090
0,335 505,900 900,1320 1320,1515 1515,1665
systems, some OLAP systems that

1203
00:31:34,090 --> 00:31:35,420
0,90 90,255 255,560
are column stores,|
|

1204
00:31:35,630 --> 00:31:36,550
0,60 60,120 120,195 195,390 390,920
you don't get any indexes,|
你不会有任何索引，|

1205
00:31:37,400 --> 00:31:38,485
0,260 260,410 410,560 560,935 935,1085
I don't think Snowflake gives
我不认为 Snowflake 给了你索引，

1206
00:31:38,485 --> 00:31:39,625
0,105 105,225 225,515 655,915 915,1140
you an index,| you can't,
|你不能创建一个，

1207
00:31:39,625 --> 00:31:40,435
0,135 135,330 330,450 450,645 645,810
you can't create one,| it
|它可能已经改变了[]，你不能有索引，

1208
00:31:40,435 --> 00:31:41,920
0,90 90,210 210,485 775,1175 1225,1485
might have changed [], you

1209
00:31:41,920 --> 00:31:45,415
0,150 150,270 270,740 880,1280 3160,3495
couldn't have indexes, right,| because
|因为，他们并不是试图进行点查询或单一事物查找，

1210
00:31:45,415 --> 00:31:46,390
0,255 255,495 495,660 660,855 855,975
again, they're not trying to

1211
00:31:46,390 --> 00:31:48,450
0,260 760,1080 1080,1485 1485,1725 1725,2060
do point queries or single

1212
00:31:48,500 --> 00:31:50,590
0,320 320,530 530,1090 1680,1925 1925,2090
single thing lookups,| to do
|来进行完整的扫描。

1213
00:31:50,590 --> 00:31:51,860
0,210 210,530
complete scans.|
|

1214
00:31:51,930 --> 00:31:53,795
0,400 960,1220 1220,1370 1370,1640 1640,1865
{} And so now you
所以现在你说到点子上了，你是对的，

1215
00:31:53,795 --> 00:31:54,575
0,90 90,180 180,420 420,675 675,780
have the point and you

1216
00:31:54,575 --> 00:31:55,790
0,135 135,425 445,735 735,930 930,1215
are correct,| you could have
|你可以拥有范围索引，

1217
00:31:55,790 --> 00:31:58,030
0,435 435,570 570,830 1330,1695 1695,2240
indexes that are range indexes,

1218
00:31:58,290 --> 00:31:59,540
0,400 450,755 755,995 995,1085 1085,1250
right,| so here's where to
|所以，如果你的 ID 是 0 和 100 ，可以在这里找到这个页面，

1219
00:31:59,540 --> 00:32:01,145
0,320 520,900 900,1140 1140,1365 1365,1605
find if your ID is

1220
00:32:01,145 --> 00:32:02,855
0,275 565,840 840,960 960,1295 1435,1710
when 0 and 100 go

1221
00:32:02,855 --> 00:32:06,035
0,135 135,315 315,635 2515,2955 2955,3180
to this page,| there's things
|有这样的东西，

1222
00:32:06,035 --> 00:32:06,920
0,150 150,425
like that,|
|

1223
00:32:06,920 --> 00:32:08,705
0,270 270,705 705,1155 1155,1455 1455,1785
there's inverted indexes, like find
有倒排索引，比如在所有记录中查找关键字 Andy ，

1224
00:32:08,705 --> 00:32:10,600
0,365 385,785 805,1110 1110,1415 1495,1895
all the the records where

1225
00:32:10,950 --> 00:32:13,600
0,305 305,790 870,1270 1440,1840 2250,2650
the keyword Andy exists, right,|
|

1226
00:32:13,980 --> 00:32:14,825
0,260 260,410 410,635 635,740 740,845
then that doesn't look like
这看起来不像是树形结构，

1227
00:32:14,825 --> 00:32:15,830
0,105 105,270 270,540 540,840 840,1005
a tree structure,| that's usually
|这通常是一个哈希表，

1228
00:32:15,830 --> 00:32:17,225
0,165 165,345 345,590 700,1155 1155,1395
a hash table,| there's different
|有不同类型的索引，

1229
00:32:17,225 --> 00:32:18,005
0,120 120,270 270,585 585,690 690,780
types of indexes,| but you
|但你不会，

1230
00:32:18,005 --> 00:32:19,380
0,120 120,395
would not,|
|

1231
00:32:19,540 --> 00:32:20,670
0,305 305,470 470,680 680,875 875,1130
maybe you wouldn't have the
也许你不会有执行点查询查找的索引。

1232
00:32:20,670 --> 00:32:21,630
0,210 210,360 360,555 555,765 765,960
index of do point query

1233
00:32:21,630 --> 00:32:22,700
0,500
lookups.|
|

1234
00:32:27,470 --> 00:32:28,920
0,230 230,350 350,640
All right, cool.|
好的，太酷了。|

1235
00:32:30,370 --> 00:32:33,440
0,400 1110,1475 1475,1655 1655,1960
So let's jump back.|
所以，让我们跳回去。|

1236
00:32:36,180 --> 00:32:37,190
0,245 245,410 410,680 680,890 890,1010
All right, so I was
好的，我试图解释这部分，

1237
00:32:37,190 --> 00:32:38,260
0,120 120,225 225,405 405,795 795,1070
kind of [hand wavy] about

1238
00:32:38,460 --> 00:32:40,160
0,305 305,515 515,820 1350,1580 1580,1700
this part here,| where I
|我说，好的，

1239
00:32:40,160 --> 00:32:41,390
0,240 240,590 790,1035 1035,1125 1125,1230
said, okay,| let me go
|让我去获取包含 hostname 的页面，

1240
00:32:41,390 --> 00:32:42,820
0,180 180,345 345,620 790,1110 1110,1430
fetch the page that has

1241
00:32:43,050 --> 00:32:44,765
0,245 245,380 380,670 1230,1520 1520,1715
the {hostname -},| run my
|运行我的 WHERE 子句，我会得到一堆匹配的，

1242
00:32:44,765 --> 00:32:45,920
0,240 240,575 745,1050 1050,1095 1095,1155
WHERE clause, I'll get a

1243
00:32:45,920 --> 00:32:47,240
0,90 90,180 180,410 820,1095 1095,1320
bunch of matches,| and then
|然后让我去获取 lastLogin 页面，

1244
00:32:47,240 --> 00:32:48,260
0,180 180,345 345,525 525,780 780,1020
let me go fetch the

1245
00:32:48,260 --> 00:32:49,940
0,180 180,540 540,830 1210,1470 1470,1680
{lastLogin -} page,| and then
|然后我有了一种神奇的方法在那里找到匹配的东西，

1246
00:32:49,940 --> 00:32:50,810
0,210 210,330 330,450 450,660 660,870
I had a magic way

1247
00:32:50,810 --> 00:32:51,790
0,120 120,285 285,435 435,630 630,980
of finding the matches there,

1248
00:32:52,560 --> 00:32:53,660
0,400
right,|
|

1249
00:32:53,860 --> 00:32:54,620
0,245 245,305 305,380 380,500 500,760
how do they do that.|
他们是怎么做到的。|

1250
00:32:55,460 --> 00:32:57,120
0,275 275,410 410,530 530,790
Well, the two approaches.|
好的，有两种方法。|

1251
00:32:57,450 --> 00:32:59,120
0,245 245,425 425,725 725,1090 1410,1670
The most common one is
最常见的一种是进行固定长度的偏移，

1252
00:32:59,120 --> 00:33:00,370
0,105 105,255 255,465 465,690 690,1250
to do {fixed-length -} offsets,|
|

1253
00:33:01,340 --> 00:33:02,700
0,260 260,425 425,665 665,980 980,1360
and that means that the,
这意味着，

1254
00:33:03,440 --> 00:33:06,415
0,400 1170,1570 1650,1970 1970,2500 2670,2975
the,| you identify rows not
|你不是通过插槽编号来标识行，

1255
00:33:06,415 --> 00:33:07,900
0,180 180,345 345,585 585,875 1255,1485
by a slot number,| but
|而是通过唯一 tuple 来标识，

1256
00:33:07,900 --> 00:33:09,355
0,195 195,540 540,870 870,1200 1200,1455
you identify {you,know} unique {tuples

1257
00:33:09,355 --> 00:33:10,675
0,275 595,810 810,870 870,1095 1095,1320
-},| this is why I
|这就是为什么我不想说行代替 tuple 记录，

1258
00:33:10,675 --> 00:33:11,260
0,120 120,150 150,195 195,330 330,585
don't want to say row

1259
00:33:11,260 --> 00:33:12,820
0,350 820,1065 1065,1170 1170,1305 1305,1560
versus instead of {tuples -}

1260
00:33:12,820 --> 00:33:15,415
0,380 940,1340 2140,2385 2385,2475 2475,2595
record,| because what does a
|因为列存储中的行是什么样子的，

1261
00:33:15,415 --> 00:33:16,930
0,255 255,525 525,735 735,1055 1255,1515
row look like in a

1262
00:33:16,930 --> 00:33:18,140
0,195 195,530
column store,|
|

1263
00:33:18,570 --> 00:33:19,205
0,260 260,335 335,410 410,500 500,635
{tuple -} is the better
tuple 是更好的术语，

1264
00:33:19,205 --> 00:33:22,385
0,305 415,815 1675,2075 2335,2700 2700,3180
term,| but the unique identifier
|但是 tuple 的唯一标识符将是它在表中的偏移量，

1265
00:33:22,385 --> 00:33:23,180
0,135 135,240 240,540 540,690 690,795
for a tuple is going

1266
00:33:23,180 --> 00:33:24,670
0,75 75,150 150,380 520,920 1090,1490
to be its offset within

1267
00:33:24,930 --> 00:33:26,820
0,400 720,1120
the table,|
|

1268
00:33:27,060 --> 00:33:28,355
0,290 290,575 575,830 830,1070 1070,1295
so now if I'm at,
所以现在如果我在一个列中的偏移量 3 ，

1269
00:33:28,355 --> 00:33:30,935
0,365 535,935 1135,1535 2005,2325 2325,2580
like offset three in one

1270
00:33:30,935 --> 00:33:32,405
0,335 805,1050 1050,1155 1155,1305 1305,1470
column,| I would then know
|我就知道如何跳到偏移量 3 和另一列，

1271
00:33:32,405 --> 00:33:33,305
0,120 120,365 445,660 660,750 750,900
how to, you know, jump

1272
00:33:33,305 --> 00:33:34,445
0,240 240,510 510,690 690,885 885,1140
to offset three and another

1273
00:33:34,445 --> 00:33:35,360
0,300 300,510 510,630 630,765 765,915
column,| and then I can
|然后我可以把 tuple 缝合在一起，

1274
00:33:35,360 --> 00:33:36,850
0,300 300,600 600,885 885,1125 1125,1490
stitch that tuple back together,|
|

1275
00:33:37,710 --> 00:33:38,950
0,245 245,410 410,620 620,875 875,1240
but again, this only works
但是，这仅在值是固定长度的情况下有效，

1276
00:33:39,090 --> 00:33:40,790
0,400 870,1130 1130,1325 1325,1520 1520,1700
if the values are {fixed-length

1277
00:33:40,790 --> 00:33:42,120
0,320
-},|
|

1278
00:33:42,160 --> 00:33:43,200
0,260 260,410 410,590 590,800 800,1040
of course, what breaks that
当然，是什么打破了这一假设，

1279
00:33:43,200 --> 00:33:44,300
0,500
assumption,|
|

1280
00:33:46,350 --> 00:33:48,170
0,305 305,515 515,935 935,1300 1320,1820
variable length VARCHAR strings, BLOB,
可变长度 VARCHAR 字符串， BLOB,  TEXT ，

1281
00:33:48,170 --> 00:33:50,105
0,285 285,680 1330,1650 1650,1875 1875,1935
text, right,| so we'll talk
|我们稍后将讨论如何处理，

1282
00:33:50,105 --> 00:33:50,645
0,90 90,165 165,240 240,390 390,540
about how to handle that

1283
00:33:50,645 --> 00:33:52,535
0,75 75,165 165,425 1435,1695 1695,1890
in a second,| so that
|所以这种方法，固定长度的列，

1284
00:33:52,535 --> 00:33:54,020
0,335 505,840 840,1095 1095,1260 1260,1485
that this approach, the {fixed-length

1285
00:33:54,020 --> 00:33:55,085
0,270 270,465 465,660 660,900 900,1065
-} column one,| that's the,
|这是最常见的。

1286
00:33:55,085 --> 00:33:56,080
0,285 285,345 345,465 465,675 675,995
that's the most common one.|
|

1287
00:33:57,480 --> 00:34:00,065
0,335 335,670 840,1240 1470,1870 2340,2585
A legacy approach is to
一种传统的方法是使用嵌入的 ID ，

1288
00:34:00,065 --> 00:34:02,675
0,195 195,450 450,1205 1495,1895 2305,2610
use embedded IDs,| where with
|其中每个值都有一些唯一的 tuple 标识符，

1289
00:34:02,675 --> 00:34:04,415
0,255 255,570 570,935 1255,1530 1530,1740
every single value you have

1290
00:34:04,415 --> 00:34:06,430
0,210 210,450 450,795 795,1295 1615,2015
some unique tuple identifier,| like,
|比如，有点像日志结构，

1291
00:34:07,150 --> 00:34:07,830
0,230 230,365 365,515 515,590 590,680
you know, sort of like

1292
00:34:07,830 --> 00:34:08,880
0,120 120,285 285,540 540,795 795,1050
the {log-structure -} stuff,| like
|比如一些计数器加 1 ，

1293
00:34:08,880 --> 00:34:10,725
0,255 255,560 1120,1440 1440,1695 1695,1845
some counter being increment by

1294
00:34:10,725 --> 00:34:13,010
0,275 1195,1485 1485,1695 1695,1995 1995,2285
one,| and then there's some
|然后有一些索引结构，我在这里没有展示，

1295
00:34:13,180 --> 00:34:14,460
0,400 420,815 815,1055 1055,1175 1175,1280
index structure, that I'm not

1296
00:34:14,460 --> 00:34:15,810
0,210 210,525 525,920 1030,1260 1260,1350
showing here,| where for a
|对于给定的记录 ID ，给定的列，

1297
00:34:15,810 --> 00:34:16,875
0,210 210,480 480,780 780,990 990,1065
given record ID, for a

1298
00:34:16,875 --> 00:34:18,885
0,165 165,485 1255,1545 1545,1740 1740,2010
given column,| it tells you
|它告诉你跳到哪里。

1299
00:34:18,885 --> 00:34:19,760
0,225 225,345 345,495 495,630 630,875
where to jump to this.|
|

1300
00:34:20,500 --> 00:34:22,580
0,400 660,935 935,1100 1100,1390 1680,2080
{} This is rare, {}|
这很少见，|

1301
00:34:23,650 --> 00:34:24,510
0,275 275,425 425,590 590,680 680,860
you probably shouldn't even mention
你可能根本不应该提它，

1302
00:34:24,510 --> 00:34:25,800
0,180 180,285 285,530 910,1155 1155,1290
it,| but like, it is
|但是，这是一种方法，

1303
00:34:25,800 --> 00:34:26,535
0,165 165,285 285,390 390,510 510,735
one way to do it,|
|

1304
00:34:26,535 --> 00:34:27,600
0,255 255,465 465,660 660,840 840,1065
there was some system I
在过去，我忘记了，一些系统确实做了这个，

1305
00:34:27,600 --> 00:34:28,800
0,320 520,795 795,915 915,1035 1035,1200
forget in the old days

1306
00:34:28,800 --> 00:34:29,535
0,165 165,315 315,450 450,600 600,735
that did do this,| because
|因为它们有点像是[扭曲]行存储，使其成为列存储，

1307
00:34:29,535 --> 00:34:29,985
0,90 90,195 195,300 300,375 375,450
they were kind of like

1308
00:34:29,985 --> 00:34:30,930
0,420 420,525 525,690 690,855 855,945
contorting a row store to

1309
00:34:30,930 --> 00:34:31,700
0,75 75,150 150,240 240,435 435,770
make it a column store,|
|

1310
00:34:32,860 --> 00:34:34,260
0,400 450,755 755,1010 1010,1250 1250,1400
but everyone uses {fixed-length -}
但每个都用固定长度集合，

1311
00:34:34,260 --> 00:34:35,070
0,150 150,390 390,585 585,690 690,810
[] sets,| of course, the
|当然，你现在要再次处理的问题是，

1312
00:34:35,070 --> 00:34:35,625
0,135 135,255 255,315 315,405 405,555
problem you got to deal

1313
00:34:35,625 --> 00:34:37,350
0,150 150,405 405,675 675,965 1465,1725
with now again is,| how
|如何将可变长度值转换为固定长度值，

1314
00:34:37,350 --> 00:34:38,870
0,165 165,435 435,765 765,1125 1125,1520
to convert variable length values

1315
00:34:38,950 --> 00:34:40,160
0,400
into

1316
00:34:40,160 --> 00:34:41,660
0,180 180,360 360,650
{fixed-length -} values.|
|

1317
00:34:41,790 --> 00:34:42,395
0,260 260,365 365,440 440,500 500,605
Let me think, I guess,
让我想想，你如何做到这个。

1318
00:34:42,395 --> 00:34:44,100
0,135 135,240 240,330 330,575
how you do that.|
|

1319
00:34:45,450 --> 00:34:47,080
0,400
Yes.|
是的。|

1320
00:34:47,170 --> 00:34:48,615
0,245 245,395 395,850 960,1310 1310,1445
He says pointers, pointers to
他说指针，指向什么？

1321
00:34:48,615 --> 00:34:52,980
0,275
what?|
|

1322
00:34:56,030 --> 00:34:58,080
0,245 245,490 840,1190 1190,1540 1650,2050
For every, {every,data} is {less,continuous},|
对于每个不连续的数据。|

1323
00:35:00,270 --> 00:35:02,795
0,400 1650,1910 1910,2075 2075,2285 2285,2525
Yeah, that would, yeah, that
是的，这可能会奏效，

1324
00:35:02,795 --> 00:35:03,815
0,180 180,330 330,540 540,780 780,1020
actually would, would potentially work,|
|

1325
00:35:03,815 --> 00:35:04,430
0,150 150,285 285,420 420,525 525,615
the problem with that one
这个版本的问题是，

1326
00:35:04,430 --> 00:35:05,045
0,90 90,225 225,390 390,510 510,615
is like,| you to do
|你做就地更新，

1327
00:35:05,045 --> 00:35:07,760
0,275 775,1065 1065,1335 1335,1715 2425,2715
like in place updates, right,|
|

1328
00:35:07,760 --> 00:35:08,600
0,135 135,285 285,375 375,690 690,840
if you're just packing all
如果你只是把所有的数据打包，

1329
00:35:08,600 --> 00:35:11,075
0,135 135,300 300,620 1270,1670 2200,2475
the data in,| if it's
|如果它是不变的，你就不会有这个问题，

1330
00:35:11,075 --> 00:35:11,630
0,300 300,360 360,450 450,480 480,555
immutable, you don't have this

1331
00:35:11,630 --> 00:35:12,790
0,210 210,510 510,720 720,870 870,1160
problem,| but if it is
|但如果它是可变的，那么你就有了碎片化。

1332
00:35:12,840 --> 00:35:15,610
0,580 780,1180 1470,1760 1760,2050 2130,2770
mutable, then you have fragmentation.|
|

1333
00:35:17,800 --> 00:35:20,440
0,105 105,240 240,465 465,770
He says slot arrays,|
他说是 slot array ，|

1334
00:35:20,630 --> 00:35:22,140
0,400 630,920 920,1025 1025,1205 1205,1510
but what it pointing to.|
但是它指向什么。|

1335
00:35:23,070 --> 00:35:24,695
0,275 275,550 660,1040 1040,1355 1355,1625

1336
00:35:24,695 --> 00:35:26,390
0,255 255,510 510,875 1195,1500 1500,1695

1337
00:35:26,390 --> 00:35:27,860
0,195 195,360 360,585 585,950 1150,1470

1338
00:35:27,860 --> 00:35:29,740
0,210 210,500 670,1070 1120,1500 1500,1880

1339
00:35:29,790 --> 00:35:32,230
0,395 395,790 840,1240 1320,1720 2040,2440

1340
00:35:35,120 --> 00:35:38,120
0,400 810,1210
Yeah, yeah.|
是的，是的。|

1341
00:35:38,400 --> 00:35:39,365
0,425 425,590 590,695 695,830 830,965
That sort of similar what
这与他所说的有点类似，有可能奏效，

1342
00:35:39,365 --> 00:35:40,265
0,90 90,180 180,420 420,705 705,900
he was saying, that potentially

1343
00:35:40,265 --> 00:35:41,600
0,150 150,395
would work,|
|

1344
00:35:45,640 --> 00:35:47,540
0,490
compression,
压缩。

1345
00:35:47,910 --> 00:35:52,085
0,400 810,1210 3180,3580 3720,3995 3995,4175
right.| So the the point
|所以，这个方法将会奏效，

1346
00:35:52,085 --> 00:35:53,120
0,195 195,420 420,615 615,840 840,1035
approach that would work,| I
|我不认为有人这么做，

1347
00:35:53,120 --> 00:35:53,860
0,105 105,195 195,345 345,480 480,740
don't think anybody does that,|
|

1348
00:35:54,990 --> 00:35:55,895
0,275 275,410 410,560 560,740 740,905
you could just pad things
你可以把东西填满，

1349
00:35:55,895 --> 00:35:56,495
0,195 195,360 360,525 525,570 570,600
out,| but that's going to
|但就像我们之前说的那样，那将是浪费的，

1350
00:35:56,495 --> 00:35:57,170
0,60 60,345 345,450 450,555 555,675
be wasteful as we said

1351
00:35:57,170 --> 00:35:59,080
0,260 880,1230 1230,1455 1455,1620 1620,1910
before,| but this is basically
|但这基本上就是[字典压缩]的工作方式，

1352
00:35:59,160 --> 00:36:01,385
0,305 305,725 725,1025 1025,1360 1710,2225
how dictionary compression works,| dictionary
|字典压缩是用整型代码来替换一些可变长度值，

1353
00:36:01,385 --> 00:36:02,975
0,300 300,525 525,765 765,1275 1275,1590
compression is is replacing some,

1354
00:36:02,975 --> 00:36:05,465
0,395 775,1080 1080,1290 1290,1595 2215,2490
some variable length value with,

1355
00:36:05,465 --> 00:36:07,060
0,180 180,345 345,605 745,1290 1290,1595
{} with the integer code,|
|

1356
00:36:07,350 --> 00:36:08,345
0,400 540,785 785,890 890,965 965,995
which which is going to
它是固定长度的，通常是 32 位，

1357
00:36:08,345 --> 00:36:09,200
0,75 75,240 240,435 435,660 660,855
be {fixed-length -} and usually

1358
00:36:09,200 --> 00:36:12,065
0,390 390,650 1090,1490 2200,2595 2595,2865
32 bits,| {} that we
|我们可以在字典代码上做一些[谓词]，

1359
00:36:12,065 --> 00:36:14,580
0,165 165,450 450,845 1705,2105
can use to, to,

1360
00:36:14,580 --> 00:36:16,245
0,150 150,410 760,1065 1065,1260 1260,1665
to then do some predicates

1361
00:36:16,245 --> 00:36:17,685
0,225 225,345 345,690 690,995 1195,1440
on the dictionary code| and
|如果有必要，如果它匹配我们寻找的东西，

1362
00:36:17,685 --> 00:36:19,005
0,245 325,705 705,930 930,1050 1050,1320
if necessary, if it matches

1363
00:36:19,005 --> 00:36:20,400
0,315 315,510 510,660 660,995 1105,1395
something we're looking for,| go
|去查找，找出实际的值是什么，

1364
00:36:20,400 --> 00:36:21,320
0,135 135,240 240,480 480,630 630,920
do a lookup and find,

1365
00:36:21,490 --> 00:36:22,410
0,290 290,425 425,560 560,710 710,920
find what the actual value

1366
00:36:22,410 --> 00:36:24,230
0,350 910,1155 1155,1335 1335,1410 1410,1820
is,| and that's a typo,|
|这是一个打字错误，|

1367
00:36:24,250 --> 00:36:25,200
0,380 380,560 560,665 665,785 785,950
it's {not,more} in this next
它不是更多在下周，

1368
00:36:25,200 --> 00:36:31,155
0,165 165,500 500,1090 1090,1350 1350,5865 5865,5955
week,| it's more this {hour\,,like,we,will,discuss,this,now}.| {So\,,that's,how}
|它更多在这个小时，我们现在就会讨论。|这就是我们如何能够解决这个问题，

1369
00:36:31,155 --> 00:36:31,575
0,150 150,195 195,270 270,345 345,420
we're going to be able

1370
00:36:31,575 --> 00:36:32,840
0,240 240,510 510,645 645,885 885,1265
to solve this problem,| and
|以及几乎每个人在现代系统中解决问题的方式。

1371
00:36:32,920 --> 00:36:33,885
0,260 260,425 425,560 560,740 740,965
pretty much the way everyone

1372
00:36:33,885 --> 00:36:35,265
0,150 150,425 865,1110 1110,1200 1200,1380
does it, in a modern

1373
00:36:35,265 --> 00:36:36,140
0,335
system.|
|

1374
00:36:38,130 --> 00:36:40,100
0,400 630,1025 1025,1595 1595,1805 1805,1970
So this [] idea is
这种[]的想法并不是新的，

1375
00:36:40,100 --> 00:36:42,995
0,270 270,650 1000,1400 2380,2715 2715,2895
not new,| {} according to
|根据文献记载，

1376
00:36:42,995 --> 00:36:44,225
0,105 105,365 595,855 855,1020 1020,1230
the literature,| the very first
|最早的版本可以追溯到 1970 年代，

1377
00:36:44,225 --> 00:36:45,920
0,225 225,405 405,665 1285,1560 1560,1695
version of this goes back

1378
00:36:45,920 --> 00:36:47,540
0,105 105,285 285,830 1150,1440 1440,1620
to {1970s -},| there is
|瑞典国防部有一个名为 Cantor 的项目，

1379
00:36:47,540 --> 00:36:48,910
0,290 340,720 720,975 975,1110 1110,1370
this project out of the

1380
00:36:48,990 --> 00:36:50,870
0,335 335,695 695,905 905,1450 1560,1880
the Swedish Defense Ministry called

1381
00:36:50,870 --> 00:36:52,265
0,530 670,915 915,1065 1065,1260 1260,1395
Cantor,| it was more of
|与其说它是一个数据库系统，不如说它是一个文件系统，

1382
00:36:52,265 --> 00:36:53,620
0,165 165,405 405,720 720,1035 1035,1355
a file system than a

1383
00:36:53,700 --> 00:36:55,460
0,260 260,515 515,845 845,1180 1500,1760
than a database system,| but
|但这被认为是第一个记录在案的关于列存储系统的类似提案，

1384
00:36:55,460 --> 00:36:56,270
0,135 135,390 390,630 630,720 720,810
this is considered to be

1385
00:36:56,270 --> 00:36:58,750
0,180 180,500 610,1155 1155,1490 2080,2480
the first documented like proposal

1386
00:36:58,770 --> 00:37:00,070
0,275 275,485 485,770 770,1010 1010,1300
for a column store system,|
|

1387
00:37:00,300 --> 00:37:01,040
0,245 245,365 365,515 515,680 680,740
and I I don't know
我不知道它今天是否存在，

1388
00:37:01,040 --> 00:37:02,105
0,150 150,345 345,555 555,810 810,1065
whether it, it, it, it

1389
00:37:02,105 --> 00:37:04,310
0,225 225,515 1525,1800 1800,1965 1965,2205
exists today,| in the {1980s
|在 1980 年代，有一篇论文实际描绘了

1390
00:37:04,310 --> 00:37:05,410
0,465 465,615 615,705 705,825 825,1100
-}, there was a paper

1391
00:37:05,520 --> 00:37:06,905
0,335 335,670 780,1025 1025,1145 1145,1385
that actually sort of mapped

1392
00:37:06,905 --> 00:37:08,510
0,120 120,270 270,825 825,1175 1285,1605
out| the theoretical properties of
|分解存储模型的理论性质，

1393
00:37:08,510 --> 00:37:10,505
0,240 240,560 760,1440 1440,1725 1725,1995
what the decomposition storage model

1394
00:37:10,505 --> 00:37:12,605
0,210 210,485 1585,1845 1845,1980 1980,2100
looked like,| but again it
|但是，它在很大程度上仍然只是在学术界，

1395
00:37:12,605 --> 00:37:14,060
0,120 120,345 345,695 775,1155 1155,1455
was still mostly only only

1396
00:37:14,060 --> 00:37:15,480
0,240 240,830
in academia,|
|

1397
00:37:16,060 --> 00:37:17,700
0,400 630,965 965,1280 1280,1475 1475,1640
the roughly what considered the
被认为是列存储系统的第一个商业实现

1398
00:37:17,700 --> 00:37:19,770
0,290 670,1070 1120,1520 1720,1965 1965,2070
first commercial implementation of a

1399
00:37:19,770 --> 00:37:21,300
0,180 180,390 390,680 1090,1365 1365,1530
column store system| was this
|是一个被称为 SybaseIQ 的东西，

1400
00:37:21,300 --> 00:37:23,235
0,195 195,420 420,780 780,1310 1690,1935
thing called {SybaseIQ -},| but
|但它并不是一个真正成熟的数据库系统，

1401
00:37:23,235 --> 00:37:25,200
0,120 120,480 480,780 780,1175 1645,1965
it wasn't really a {full-fledged

1402
00:37:25,200 --> 00:37:27,285
0,285 285,555 555,950 1720,1965 1965,2085
-} database system,| it was
|它更像是一个查询加速器，

1403
00:37:27,285 --> 00:37:28,125
0,150 150,270 270,435 435,615 615,840
more like a like a

1404
00:37:28,125 --> 00:37:30,720
0,375 375,965 1345,1635 1635,1925 2245,2595
query accelerator,| and so similar
|与我之前提到的 Oracle 类似，

1405
00:37:30,720 --> 00:37:31,275
0,195 195,270 270,330 330,420 420,555
to what I was saying

1406
00:37:31,275 --> 00:37:32,415
0,210 210,450 450,900 900,1050 1050,1140
before about Oracle,| they make
|它们将行存储的副本复制到内存中列存储中，

1407
00:37:32,415 --> 00:37:33,330
0,135 135,375 375,600 600,735 735,915
a copy of your row

1408
00:37:33,330 --> 00:37:34,575
0,195 195,390 390,710 760,1035 1035,1245
store into a {in-memory -}

1409
00:37:34,575 --> 00:37:35,985
0,285 285,635 805,1065 1065,1200 1200,1410
column store,| this is basically
|这基本上就是 Sybase 在 1990 年代做的事情，

1410
00:37:35,985 --> 00:37:37,020
0,210 210,540 540,690 690,870 870,1035
what Sybase was doing back

1411
00:37:37,020 --> 00:37:38,355
0,105 105,180 180,330 330,830 1090,1335
in the {1990s -},| so
|所以，你的查询将会出现，

1412
00:37:38,355 --> 00:37:39,380
0,120 120,330 330,540 540,735 735,1025
your query would show up|
|

1413
00:37:39,520 --> 00:37:40,635
0,260 260,425 425,815 815,965 965,1115
and then Sybase would figure
然后 Sybase 会计算出，

1414
00:37:40,635 --> 00:37:41,810
0,195 195,360 360,480 480,755 775,1175
out,| should I go to
|我应该去行存储，并可能在那里做一些事情，

1415
00:37:41,920 --> 00:37:43,460
0,400 690,1025 1025,1220 1220,1310 1310,1540
the row store and maybe

1416
00:37:43,480 --> 00:37:44,685
0,260 260,425 425,730 810,1085 1085,1205
do something there| or should
|或者我应该只在内存中列存储上运行查询。

1417
00:37:44,685 --> 00:37:45,780
0,165 165,360 360,480 480,755 775,1095
I run the query only

1418
00:37:45,780 --> 00:37:47,160
0,210 210,500 580,870 870,1140 1140,1380
on the, on the {in-memory

1419
00:37:47,160 --> 00:37:48,420
0,180 180,435 435,770
-} column store.|
|

1420
00:37:49,610 --> 00:37:51,040
0,275 275,410 410,545 545,820 1140,1430
In the {2000s -}, is
在 2000 年，是列存储真正起飞的时候，

1421
00:37:51,040 --> 00:37:52,150
0,290 310,585 585,780 780,960 960,1110
when the column store stuff

1422
00:37:52,150 --> 00:37:53,095
0,195 195,360 360,570 570,780 780,945
really took off,| and the
|这个领域的三个关键系统，

1423
00:37:53,095 --> 00:37:54,460
0,305 385,690 690,975 975,1215 1215,1365
three key systems in this

1424
00:37:54,460 --> 00:37:57,310
0,240 240,480 480,1010 1180,1580 2560,2850
space,| where Vertica, which found
|由 [] 创建， Mike Stonebraker ，

1425
00:37:57,310 --> 00:38:00,205
0,290 790,1125 1125,1610 1720,2120 2620,2895
by {[] -}, stands, Mike

1426
00:38:00,205 --> 00:38:02,820
0,135 135,545 1405,1770 1770,2075 2215,2615
{Stonebraker -} ,| {Vectorwise -} was
|Vectorwise 是一个 [] 数据库，它是 CWI 的，

1427
00:38:04,460 --> 00:38:06,100
0,275 275,680 680,1070 1070,1325 1325,1640
a [] DB, but that

1428
00:38:06,100 --> 00:38:06,820
0,225 225,330 330,450 450,555 555,720
was at a {CWI -

1429
00:38:06,820 --> 00:38:09,270
0,320 1210,1485 1485,1785 1785,2055 2055,2450
-}| and MonetDB was was
|MonetDB 也是 CWI 的一个重要学术项目，

1430
00:38:09,680 --> 00:38:11,320
0,400 720,980 980,1190 1190,1445 1445,1640
was a major academic project

1431
00:38:11,320 --> 00:38:13,440
0,150 150,405 405,675 675,950
at CWI as well,|
|

1432
00:38:13,540 --> 00:38:14,910
0,680 680,875 875,1055 1055,1220 1220,1370
DuckDB is from {CWI -
DuckDB 来自 CWI ，

1433
00:38:14,910 --> 00:38:18,105
0,290 610,1010 1750,2150 2680,2970 2970,3195
-},| so the the first
|DuckDB 的第一个版本实际上被称为 MonetDBLite ，

1434
00:38:18,105 --> 00:38:19,350
0,225 225,360 360,840 840,1065 1065,1245
version of DuckDB was actually

1435
00:38:19,350 --> 00:38:20,270
0,150 150,300 300,420 420,645 645,920
called {MonetDBLite - - -},|
|

1436
00:38:20,830 --> 00:38:21,840
0,320 320,545 545,725 725,845 845,1010
they threw all the code
他们扔掉了所有的代码，

1437
00:38:21,840 --> 00:38:22,905
0,270 270,480 480,660 660,870 870,1065
away| and then started {DuckDB
|然后从头开始 DuckDB ，在了解了 MonetDBLite 之后，

1438
00:38:22,905 --> 00:38:23,940
0,135 135,285 285,540 540,825 825,1035
-} from scratch, after learning

1439
00:38:23,940 --> 00:38:25,160
0,135 135,380 580,840 840,960 960,1220
{MonetDBLite - - - -},|
|

1440
00:38:25,700 --> 00:38:27,030
0,365 365,590 590,800 800,1010 1010,1330
{Vectorwise -} was started by
Vectorwise 是由一些在 MonetDB 工作的人创办的，

1441
00:38:27,500 --> 00:38:28,315
0,230 230,335 335,470 470,635 635,815
some people that worked on

1442
00:38:28,315 --> 00:38:30,820
0,135 135,255 255,635 1975,2265 2265,2505
{MonetDB - -}| and then
|然后 Vectorwise 的两个主要人员，

1443
00:38:30,820 --> 00:38:32,605
0,350 1030,1320 1320,1455 1455,1590 1590,1785
the the two main people

1444
00:38:32,605 --> 00:38:33,445
0,165 165,345 345,555 555,735 735,840
at {Vectorwise -},| one of
|其中一个离开了，是 Snowflake 的联合创始人，

1445
00:38:33,445 --> 00:38:35,425
0,245 445,840 840,1235 1615,1875 1875,1980
them left and was a

1446
00:38:35,425 --> 00:38:37,105
0,120 120,360 360,465 465,935 1465,1680
{co-founder -} of Snowflake,| so
|所以， Vectorwise 提出的许多早期想法都在 Snowflake ，

1447
00:38:37,105 --> 00:38:37,600
0,45 45,135 135,240 240,315 315,495
a lot of the early

1448
00:38:37,600 --> 00:38:38,740
0,255 255,420 420,735 735,960 960,1140
ideas that Vectorwise developed is

1449
00:38:38,740 --> 00:38:40,810
0,180 180,680 880,1170 1170,1460 1840,2070
in Snowflake| and then the
|然后另一个人， Peter Boncz ，

1450
00:38:40,810 --> 00:38:41,830
0,120 120,285 285,450 450,855 855,1020
other guy, Peter Boncz,| he
|他回到了 CWI ，

1451
00:38:41,830 --> 00:38:42,760
0,135 135,285 285,405 405,765 765,930
went back to CWI| and
|然后，他帮助建议 DuckDB 项目。

1452
00:38:42,760 --> 00:38:44,065
0,165 165,470 670,900 900,1080 1080,1305
then he, you know, helped

1453
00:38:44,065 --> 00:38:45,070
0,135 135,225 225,465 465,810 810,1005
{ -} advise the the

1454
00:38:45,070 --> 00:38:46,240
0,105 105,330 330,590
{DuckDB -} project.|
|

1455
00:38:46,950 --> 00:38:48,110
0,400 720,950 950,1025 1025,1085 1085,1160
So there was a bunch
所以当时有很多其他的系统，

1456
00:38:48,110 --> 00:38:48,725
0,75 75,180 180,360 360,510 510,615
of other systems at the

1457
00:38:48,725 --> 00:38:49,925
0,165 165,435 435,705 705,915 915,1200
time,| but I consider these
|但我认为这三个主要的系统是这个领域的先驱者。

1458
00:38:49,925 --> 00:38:51,560
0,285 285,480 480,785 1075,1335 1335,1635
three major ones, the pioneers

1459
00:38:51,560 --> 00:38:53,560
0,120 120,240 240,530
in this space.|
|

1460
00:38:53,920 --> 00:38:54,945
0,335 335,530 530,695 695,860 860,1025
And actually how this all
实际上，这一切出来，

1461
00:38:54,945 --> 00:38:56,205
0,150 150,395 445,705 705,965 1015,1260
sort of came out,| the
|Mike 说的，或者 Stonebraker 说的方法，

1462
00:38:56,205 --> 00:38:57,290
0,135 135,330 330,525 525,750 750,1085
way Mike tells it was,

1463
00:38:57,970 --> 00:38:59,480
0,400 480,755 755,1085 1085,1220 1220,1510
{} or Stonebraker tells it,|
|

1464
00:38:59,680 --> 00:39:01,200
0,305 305,575 575,1025 1025,1175 1175,1520
he was consulting for Walmart
他是沃尔玛实验室的顾问，在 2000 年代早期，

1465
00:39:01,200 --> 00:39:03,150
0,590 880,1280 1390,1665 1665,1785 1785,1950
Labs, {} in the early

1466
00:39:03,150 --> 00:39:04,335
0,180 180,440 670,930 930,1050 1050,1185
{2000s -},| and they were
|他们努力扩大他们的 TB 数据库，

1467
00:39:04,335 --> 00:39:05,690
0,240 240,465 465,630 630,935 955,1355
struggling try to scale their

1468
00:39:06,430 --> 00:39:07,815
0,365 365,530 530,850 1020,1265 1265,1385
tera data database,| at the
|当时是行存储，

1469
00:39:07,815 --> 00:39:08,720
0,150 150,270 270,390 390,585 585,905
time was a row store,|
|

1470
00:39:09,010 --> 00:39:10,755
0,245 245,380 380,695 695,970 1500,1745
I think Walmart was, it
我认为沃尔玛是多个 PB ，

1471
00:39:10,755 --> 00:39:13,485
0,245 1315,1665 1665,2315 2425,2655 2655,2730
was multiple petabytes,| it was
|它是每一笔交易的数据库，

1472
00:39:13,485 --> 00:39:14,325
0,75 75,225 225,420 420,615 615,840
a database of every single

1473
00:39:14,325 --> 00:39:15,945
0,300 300,855 855,1170 1170,1410 1410,1620
transaction,| anytime somebody bought something
|任何时候，当有人在商店购买东西，

1474
00:39:15,945 --> 00:39:17,310
0,150 150,285 285,575 685,1230 1230,1365
at a store,| like {[]
|比如[]，它就在那个数据库中，

1475
00:39:17,310 --> 00:39:18,525
0,225 225,680 700,930 930,1050 1050,1215
- -}, it was in

1476
00:39:18,525 --> 00:39:20,160
0,165 165,455 895,1260 1260,1485 1485,1635
that database| and they were
|他们努力让 TB 数据运行更快，

1477
00:39:20,160 --> 00:39:20,970
0,195 195,345 345,465 465,675 675,810
struggling to get tera data

1478
00:39:20,970 --> 00:39:22,260
0,135 135,270 270,560 940,1185 1185,1290
to run fast,| and then
|然后迈克想，

1479
00:39:22,260 --> 00:39:23,190
0,120 120,225 225,330 330,590 640,930
Mike was like,| oh, we
|哦，我们应该把这个做成列存储，

1480
00:39:23,190 --> 00:39:23,910
0,195 195,375 375,495 495,600 600,720
should make just make this

1481
00:39:23,910 --> 00:39:25,140
0,120 120,315 315,650 820,1080 1080,1230
the column store| and then
|然后他创立了 C-store 项目，后来变成了 Vectica ，

1482
00:39:25,140 --> 00:39:27,810
0,290 490,890 1930,2175 2175,2370 2370,2670
he, {} and then he

1483
00:39:27,810 --> 00:39:28,710
0,240 240,450 450,630 630,765 765,900
he founded the {C-store -}

1484
00:39:28,710 --> 00:39:30,135
0,180 180,390 390,585 585,1100 1180,1425
project, that became Vectica| and
|然后，这是一个非常著名的项目。

1485
00:39:30,135 --> 00:39:31,280
0,245
then,

1486
00:39:31,820 --> 00:39:33,010
0,260 260,520 630,875 875,995 995,1190
it was a pretty famous

1487
00:39:33,010 --> 00:39:35,125
0,320 1240,1530 1530,1665 1665,1875 1875,2115
project.| Now pretty much everybody
|现在几乎每个人都这么做了，

1488
00:39:35,125 --> 00:39:38,275
0,165 165,455 715,1115 1795,2195 2875,3150
does this,| {} so this
|这只是一些被认为是列存储的数据库系统中的一个示例，

1489
00:39:38,275 --> 00:39:39,540
0,120 120,330 330,600 600,885 885,1265
is just a sample of

1490
00:39:39,740 --> 00:39:40,675
0,245 245,365 365,530 530,725 725,935
a bunch of database systems

1491
00:39:40,675 --> 00:39:41,275
0,120 120,165 165,255 255,435 435,600
that are out there, that

1492
00:39:41,275 --> 00:39:43,705
0,245 295,600 600,855 855,1205 2185,2430
are considered column stores,| but
|但是 2010 年还有两件很有趣的事情，

1493
00:39:43,705 --> 00:39:44,515
0,135 135,330 330,510 510,675 675,810
the two key things that

1494
00:39:44,515 --> 00:39:45,775
0,135 135,425 775,1035 1035,1155 1155,1260
are also interesting about the

1495
00:39:45,775 --> 00:39:47,695
0,540 540,845 1015,1350 1350,1595 1615,1920
2010 is,| there's these open
|那就是有这些开源的文件格式， Parquet 和 ORC ，

1496
00:39:47,695 --> 00:39:50,065
0,305 1195,1530 1530,1890 1890,2235 2235,2370
source file formats, Parquet and

1497
00:39:50,065 --> 00:39:51,520
0,455 565,1065 1065,1230 1230,1320 1320,1455
ORC,| parquet came out of
|Parquet 来自 Dremio 和另一个我忘记的人，，

1498
00:39:51,520 --> 00:39:53,740
0,540 540,920
Dremio and

1499
00:39:53,840 --> 00:39:55,510
0,290 290,440 440,635 635,1030 1350,1670
somebody else I'm forgetting| and
|ORC 来自 Facebook ，

1500
00:39:55,510 --> 00:39:56,400
0,240 240,420 420,525 525,630 630,890
ORC came out of Facebook,|
|

1501
00:39:56,930 --> 00:39:58,510
0,260 260,440 440,620 620,880 1260,1580
these are open source file
这些都是基于列的开源文件格式，

1502
00:39:58,510 --> 00:40:01,020
0,440 880,1215 1215,1550 1660,2235 2235,2510
formats that are columnar based,|
|

1503
00:40:01,970 --> 00:40:02,830
0,260 260,440 440,605 605,710 710,860
and now you can build
现在你可以构建读写 Parquet ORC 文件的数据库系统。

1504
00:40:02,830 --> 00:40:03,760
0,210 210,465 465,675 675,810 810,930
database systems that can read

1505
00:40:03,760 --> 00:40:06,630
0,120 120,380 2050,2385 2385,2595 2595,2870
and write Parquet ORC files.|
|

1506
00:40:09,810 --> 00:40:11,410
0,260 260,520 810,1160 1160,1355 1355,1600
All right, so the advantages
好的，列或分解存储模型的优势在于，

1507
00:40:11,550 --> 00:40:13,385
0,395 395,790 900,1145 1145,1520 1520,1835
for the, the columnar or

1508
00:40:13,385 --> 00:40:14,890
0,645 645,855 855,1065 1065,1245 1245,1505
decomposition storage model is that,|
|

1509
00:40:15,150 --> 00:40:16,115
0,275 275,320 320,440 440,710 710,965
we're going to greatly reduce
我们将极大地减少 I/O 浪费的数量，

1510
00:40:16,115 --> 00:40:17,050
0,120 120,210 210,300 300,465 465,935
the amount of waste I/O,|
|

1511
00:40:17,130 --> 00:40:17,915
0,260 260,380 380,485 485,620 620,785
we have to do for
我们进行分析查询所需的，

1512
00:40:17,915 --> 00:40:19,780
0,465 465,825 825,1145 1285,1620 1620,1865
analytical queries,| because we're only
|因为我们只读取所需的数据，

1513
00:40:19,890 --> 00:40:21,665
0,400 720,1040 1040,1295 1295,1565 1565,1775
reading the exact data that

1514
00:40:21,665 --> 00:40:23,520
0,165 165,455
we need,|
|

1515
00:40:23,520 --> 00:40:24,405
0,380 460,705 705,825 825,855 855,885
{} and we're going to
我们将获得更好的缓存使用

1516
00:40:24,405 --> 00:40:25,395
0,90 90,315 315,585 585,765 765,990
get better cache for use|
|

1517
00:40:25,395 --> 00:40:27,210
0,225 225,485 505,1245 1245,1515 1515,1815
and better locality for our
和更好的访问模式位置，

1518
00:40:27,210 --> 00:40:28,905
0,225 225,500 520,840 840,1160 1360,1695
access patterns,| because again, we're
|因为，我们实际上只需要一个接一个地[撕裂]列，

1519
00:40:28,905 --> 00:40:29,850
0,165 165,330 330,420 420,630 630,945
literally just going to rip

1520
00:40:29,850 --> 00:40:31,310
0,300 300,780 780,945 945,1140 1140,1460
through columns one after another|
|

1521
00:40:31,540 --> 00:40:32,505
0,275 275,455 455,620 620,755 755,965
and not have to jump
而不必在内存中跳跃，

1522
00:40:32,505 --> 00:40:35,235
0,335 1075,1475 1495,1845 1845,2195 2485,2730
around within, within memory,| which
|这对 CPU 更好，

1523
00:40:35,235 --> 00:40:36,765
0,105 105,255 255,405 405,845 1255,1530
is better for CPUs,| and
|同样，我们将获得更好的压缩，

1524
00:40:36,765 --> 00:40:37,940
0,275 295,570 570,660 660,810 810,1175
again, we'll get better compression,|
|

1525
00:40:38,260 --> 00:40:39,200
0,245 245,380 380,485 485,650 650,940
which we're coming up to.|
这是我们要讲到的。|

1526
00:40:39,940 --> 00:40:40,860
0,260 260,365 365,710 710,830 830,920
Because the downside is going
这是因为缺点是，

1527
00:40:40,860 --> 00:40:41,265
0,60 60,150 150,330 330,375 375,405
to be,| it's going to
|点查询的速度会很慢，

1528
00:40:41,265 --> 00:40:42,510
0,120 120,390 390,720 720,975 975,1245
be slow for point query,|
|

1529
00:40:42,510 --> 00:40:44,060
0,210 210,315 315,645 645,1185 1185,1550
slow for insert {update,delete},| because
插入，更新，删除的速度会很慢，|因为我们将不得不拆分数据，

1530
00:40:44,320 --> 00:40:44,895
0,275 275,320 320,365 365,440 440,575
we're going to have to

1531
00:40:44,895 --> 00:40:46,395
0,150 150,315 315,605 1075,1350 1350,1500
split things up| and write
|并将多个数据写到多个位置，

1532
00:40:46,395 --> 00:40:47,430
0,150 150,425 505,750 750,870 870,1035
out multiple, you know, data

1533
00:40:47,430 --> 00:40:48,420
0,135 135,330 330,645 645,855 855,990
to multiple locations| and then
|然后再带回它，

1534
00:40:48,420 --> 00:40:49,020
0,150 150,255 255,375 375,510 510,600
bring it back in| if
|如果我们想把它放在一起。

1535
00:40:49,020 --> 00:40:49,500
0,90 90,180 180,255 255,345 345,480
we want to put it,

1536
00:40:49,500 --> 00:40:50,580
0,135 135,210 210,345 345,650
put it back together.|
|

1537
00:40:52,230 --> 00:40:58,100
0,400 4290,4610 4610,4930 5040,5440 5610,5870
Yes.| Question is, [] build
是的。|问题是，[]是否建立了自己的数据库，没有，

1538
00:40:58,100 --> 00:40:59,940
0,105 105,195 195,440 440,840
their own database, no,|
|

1539
00:41:00,030 --> 00:41:01,445
0,430 840,1100 1100,1205 1205,1280 1280,1415
it consider that an each
它认为每个[]，

1540
00:41:01,445 --> 00:41:04,445
0,305 1285,1685 2095,2595 2595,2865 2865,3000
[],| but [] DB is
|但[]数据库是真实的，是一个真正的系统。

1541
00:41:04,445 --> 00:41:06,190
0,275 1045,1335 1335,1395 1395,1485 1485,1745
real, that's a real system.|
|

1542
00:41:08,560 --> 00:41:09,860
0,400
Okay.|
好的。|

1543
00:41:10,870 --> 00:41:12,900
0,400 1470,1730 1730,1835 1835,1925 1925,2030
So one thing to point
所以，有一点需要指出的是，

1544
00:41:12,900 --> 00:41:15,080
0,135 135,410 460,860 880,1280
out, though, is that,|
|

1545
00:41:15,370 --> 00:41:16,725
0,275 275,470 470,680 680,965 965,1355
in my, my earlier example,|
在我前面的例子中，|

1546
00:41:16,725 --> 00:41:17,790
0,240 240,390 390,615 615,870 870,1065
the way I showed I
我展示了我运行一个查询，

1547
00:41:17,790 --> 00:41:19,515
0,135 135,410 430,735 735,1070 1360,1725
ran that one query,| I
|我在 hostname 列上进行了扫描，

1548
00:41:19,515 --> 00:41:20,870
0,255 255,480 480,780 780,1050 1050,1355
did the scan on the,

1549
00:41:21,520 --> 00:41:23,460
0,320 320,635 635,1030
on the, {}

1550
00:41:23,770 --> 00:41:24,930
0,290 290,425 425,545 545,820 900,1160
on the, on the the

1551
00:41:24,930 --> 00:41:28,260
0,150 150,440 1570,1970 2050,2450 3040,3330
{hostname -} the column,| then
|然后，我在 login 上运行了查询的扫描部分，

1552
00:41:28,260 --> 00:41:29,985
0,180 180,345 345,510 510,800 1420,1725
I ran the scan portion

1553
00:41:29,985 --> 00:41:30,980
0,135 135,210 210,405 405,660 660,995
of the query on the

1554
00:41:32,710 --> 00:41:34,610
0,275 275,395 395,725 725,1000 1500,1900
on the login one| and
|你可以想象一下，

1555
00:41:34,840 --> 00:41:35,505
0,290 290,425 425,500 500,575 575,665
you sort of think of

1556
00:41:35,505 --> 00:41:36,540
0,150 150,345 345,495 495,755 775,1035
that,| like it was I
|就像我做了一个，然后它又移动到另一个，

1557
00:41:36,540 --> 00:41:37,275
0,165 165,375 375,540 540,645 645,735
did one and then it

1558
00:41:37,275 --> 00:41:38,520
0,105 105,365 385,785 865,1110 1110,1245
moved on another,| a lot
|但是，在很多情况下的查询，

1559
00:41:38,520 --> 00:41:39,630
0,135 135,300 300,510 510,885 885,1110
of cases though, queries,| you
|你希望同时查看多个列，

1560
00:41:39,630 --> 00:41:40,740
0,180 180,315 315,590 640,915 915,1110
actually want to look at

1561
00:41:40,740 --> 00:41:41,955
0,315 315,720 720,840 840,975 975,1215
multiple columns at the same

1562
00:41:41,955 --> 00:41:43,000
0,365
time,

1563
00:41:43,000 --> 00:41:44,140
0,195 195,345 345,510 510,810 810,1140
right,| my WHERE clause had
|我的 WHERE 子句只引用了一个属性，

1564
00:41:44,140 --> 00:41:45,510
0,225 225,390 390,705 705,915 915,1370
was only referenced one attribute,|
|

1565
00:41:45,710 --> 00:41:46,990
0,230 230,455 455,800 800,1040 1040,1280
but as you've seen in
但像你在为家庭作业一编写的查询中看到的那样，

1566
00:41:46,990 --> 00:41:47,665
0,120 120,345 345,465 465,555 555,675
the queries you've written for

1567
00:41:47,665 --> 00:41:49,090
0,165 165,485 745,1080 1080,1305 1305,1425
homework one,| often times you
|通常，你在 WHERE 子句中经常引用了多个列或多个属性，

1568
00:41:49,090 --> 00:41:50,620
0,90 90,350 850,1245 1245,1320 1320,1530
have multiple columns or multiple

1569
00:41:50,620 --> 00:41:51,700
0,300 300,705 705,825 825,930 930,1080
attributes referenced in your WHERE

1570
00:41:51,700 --> 00:41:52,740
0,320
clause,|
|

1571
00:41:52,750 --> 00:41:54,225
0,290 290,580 960,1205 1205,1310 1310,1475
and so it would be
所以，现在维护会有点昂贵或繁琐，

1572
00:41:54,225 --> 00:41:57,030
0,195 195,485 685,945 945,1205 2485,2805
kind of kind of expensive

1573
00:41:57,030 --> 00:41:57,915
0,180 180,585 585,705 705,795 795,885
or cumbersome to sort of

1574
00:41:57,915 --> 00:42:00,645
0,135 135,405 405,785 2185,2490 2490,2730
now {} maintaining,| as I'm
|因为我沿着一列扫描，同时获取另一列，

1575
00:42:00,645 --> 00:42:02,565
0,270 270,450 450,645 645,935 1495,1920
scanning along one column, fetching

1576
00:42:02,565 --> 00:42:03,315
0,135 135,330 330,525 525,660 660,750
in another column at the

1577
00:42:03,315 --> 00:42:04,310
0,165 165,375 375,555 555,720 720,995
same time| and trying to
|并试图将东西拼凑在一起，

1578
00:42:04,660 --> 00:42:06,740
0,290 290,500 500,820 1500,1790 1790,2080
patch things together,| and so
|所以我们仍然希望有数据，

1579
00:42:07,390 --> 00:42:08,715
0,320 320,545 545,800 800,1040 1040,1325
we still want we still,

1580
00:42:08,715 --> 00:42:09,510
0,270 270,390 390,555 555,705 705,795
we want to be able

1581
00:42:09,510 --> 00:42:11,130
0,180 180,495 495,890 1120,1440 1440,1620
to have data| or we
|我们想要一种方式，

1582
00:42:11,130 --> 00:42:11,685
0,135 135,285 285,390 390,465 465,555
want, we want a way|
|

1583
00:42:11,685 --> 00:42:12,585
0,90 90,225 225,480 480,780 780,900
to have the attributes that
让在一起使用的属性，

1584
00:42:12,585 --> 00:42:13,660
0,225 225,605
are somewhat

1585
00:42:13,700 --> 00:42:15,490
0,395 395,790 1140,1385 1385,1520 1520,1790
that are going to use

1586
00:42:15,490 --> 00:42:17,320
0,380 850,1230 1230,1545 1545,1710 1710,1830
together| somewhat close to each
|在我们的文件中彼此靠近的磁盘上，

1587
00:42:17,320 --> 00:42:18,775
0,240 240,510 510,1035 1035,1275 1275,1455
other on disk in our

1588
00:42:18,775 --> 00:42:20,455
0,305 835,1155 1155,1380 1380,1545 1545,1680
files,| but still get all
|但仍然可以获得列存储布局的所有好处。

1589
00:42:20,455 --> 00:42:21,910
0,150 150,425 475,875 925,1215 1215,1455
the benefit of a column

1590
00:42:21,910 --> 00:42:23,260
0,240 240,650
store layout,

1591
00:42:26,520 --> 00:42:27,560
0,400
right.|
|

1592
00:42:27,930 --> 00:42:28,685
0,275 275,410 410,545 545,665 665,755
And so this is what
这就是PS模型的模型。正如我所说的，在大多数系统中，他们说他们是一个列存储。他们真的在这么做。帕奎特和兽人真的真的在做这件事。

1593
00:42:28,685 --> 00:42:29,950
0,135 135,450 450,675 675,945 945,1265
the PS model model is,

1594
00:42:31,560 --> 00:42:32,800
0,290 290,580 600,845 845,965 965,1240
again. And as I said,

1595
00:42:33,180 --> 00:42:34,445
0,305 305,545 545,830 830,1070 1070,1265
in most systems they say

1596
00:42:34,445 --> 00:42:35,825
0,210 210,285 285,510 510,875 1045,1380
they're a column store. They're

1597
00:42:35,825 --> 00:42:37,550
0,210 210,540 540,905 1105,1605 1605,1725
really doing this. Parquet and

1598
00:42:37,550 --> 00:42:38,795
0,270 270,405 405,680 700,1020 1020,1245
orc are really, really doing

1599
00:42:38,795 --> 00:42:39,820
0,305
this.|
|

1600
00:42:39,820 --> 00:42:40,510
0,75 75,210 210,345 345,480 480,690
And the idea is not
这个想法不像，你知道，基本上只是说，不是每个单独的列或属性都有一个单独的文件，我会，呃，我把它们分成块，分成行组，让同一个学生里的数据彼此接近。

1601
00:42:40,510 --> 00:42:42,190
0,320 490,720 720,930 930,1245 1245,1680
like, you know, mind blowing

1602
00:42:42,190 --> 00:42:44,050
0,255 255,420 420,705 705,1100 1600,1860
it just basically saying, instead

1603
00:42:44,050 --> 00:42:45,660
0,120 120,380 490,890 910,1260 1260,1610
of having a separate file

1604
00:42:46,130 --> 00:42:47,545
0,275 275,515 515,880 900,1205 1205,1415
for every single column or

1605
00:42:47,545 --> 00:42:49,380
0,150 150,330 330,665 1165,1575 1575,1835
attrib by itself, I'll have,

1606
00:42:50,090 --> 00:42:51,520
0,400 660,1025 1025,1190 1190,1325 1325,1430
uh, I'll break them up

1607
00:42:51,520 --> 00:42:53,940
0,210 210,770 1510,1860 1860,2115 2115,2420
into chunks, into row groups

1608
00:42:54,080 --> 00:42:55,650
0,305 305,610 690,1070 1070,1310 1310,1570
and have data that are

1609
00:42:55,940 --> 00:42:57,445
0,275 275,395 395,545 545,1000 1170,1505
within the same pupil close

1610
00:42:57,445 --> 00:42:58,720
0,165 165,255 255,515
to each other.|
|

1611
00:42:59,680 --> 00:43:01,110
0,275 275,410 410,590 590,910 1170,1430
In the same file, just
在同一个文件中，只是在不同的页面中隔开了一些。

1612
00:43:01,110 --> 00:43:02,130
0,120 120,270 270,495 495,750 750,1020
sort of spaced out in

1613
00:43:02,130 --> 00:43:03,580
0,255 255,590
separate pages.|
|

1614
00:43:04,630 --> 00:43:05,940
0,400 780,1025 1025,1115 1115,1205 1205,1310
Right. So if we go
正确的。因此，如果我们回到我们这里的模拟示例，我们要做的就是将表水平分区到行组中，然后在行组中，我们将根据列对其进行分区。

1615
00:43:05,940 --> 00:43:06,930
0,165 165,375 375,600 600,765 765,990
back to our sort of

1616
00:43:06,930 --> 00:43:08,565
0,390 390,630 630,950 1150,1455 1455,1635
mock example here, all we're

1617
00:43:08,565 --> 00:43:09,045
0,45 45,120 120,240 240,360 360,480
going to do is just

1618
00:43:09,045 --> 00:43:10,965
0,465 465,780 780,975 975,1235 1585,1920
horizontally partition the table, eh,

1619
00:43:10,965 --> 00:43:13,905
0,335 1345,1740 1740,2040 2040,2345 2665,2940
into to row groups, and

1620
00:43:13,905 --> 00:43:15,135
0,150 150,425 475,810 810,1050 1050,1230
then within that row group

1621
00:43:15,135 --> 00:43:15,915
0,180 180,225 225,315 315,615 615,780
we're going to partition it

1622
00:43:15,915 --> 00:43:17,340
0,165 165,360 360,815
based on columns.|
|

1623
00:43:18,250 --> 00:43:19,125
0,320 320,515 515,650 650,770 770,875
Right. So you think of
正确的。你想想，这里的前三行，我将在我的巨大文件中有一些部分，呃，定义行组。我有那个行组的标题，然后我把列a的所有属性都放在一起。然后是列a的所有值的所有属性、列b的所有值、以及列c的所有值。

1624
00:43:19,125 --> 00:43:20,400
0,245 385,645 645,825 825,1020 1020,1275
this, the first three rows

1625
00:43:20,400 --> 00:43:22,370
0,260 700,1065 1065,1275 1275,1605 1605,1970
here I'll have some portion

1626
00:43:22,720 --> 00:43:24,320
0,245 245,365 365,590 590,940 1200,1600
in my giant file, eh,

1627
00:43:25,390 --> 00:43:26,625
0,290 290,440 440,590 590,880 990,1235
define the row group. I

1628
00:43:26,625 --> 00:43:27,270
0,75 75,165 165,420 420,510 510,645
have a header for that

1629
00:43:27,270 --> 00:43:28,530
0,195 195,500 700,975 975,1125 1125,1260
row group and then I

1630
00:43:28,530 --> 00:43:29,760
0,260 490,795 795,1005 1005,1140 1140,1230
have all the attrib of

1631
00:43:29,760 --> 00:43:31,050
0,165 165,390 390,710 850,1125 1125,1290
column a together. Then all

1632
00:43:31,050 --> 00:43:32,625
0,240 240,510 510,770 1150,1440 1440,1575
the attributes for all the

1633
00:43:32,625 --> 00:43:33,465
0,165 165,330 330,465 465,675 675,840
values for column a, all

1634
00:43:33,465 --> 00:43:34,395
0,90 90,270 270,525 525,735 735,930
the values, column b, followed

1635
00:43:34,395 --> 00:43:35,325
0,210 210,390 390,510 510,675 675,930
by all the values column

1636
00:43:35,325 --> 00:43:36,100
0,335
c.|
|

1637
00:43:37,940 --> 00:43:39,625
0,400 750,1010 1010,1220 1220,1490 1490,1685
Right. So now again, if
正确的。所以现在再一次，如果我有一个WHERE调用需要访问，你知道的，列a和列c，当我去获取这个行组的这些页面时。我，你知道，我我有我需要的所有数据。但我也得到了Funch IO的好处，因为这个行组将以几十兆字节的形式存在，而不是像你知道的那样，4千字节或8千字节的页面。

1638
00:43:39,625 --> 00:43:40,555
0,165 165,315 315,435 435,630 630,930
I have a where calls

1639
00:43:40,555 --> 00:43:41,830
0,240 240,405 405,675 675,1050 1050,1275
that needs to access, you

1640
00:43:41,830 --> 00:43:42,790
0,90 90,300 300,570 570,780 780,960
know, both column a and

1641
00:43:42,790 --> 00:43:44,380
0,255 255,620 1060,1305 1305,1425 1425,1590
column c, when I go

1642
00:43:44,380 --> 00:43:45,820
0,320 400,705 705,1010 1060,1305 1305,1440
fetch these pages for this

1643
00:43:45,820 --> 00:43:47,350
0,210 210,530 940,1260 1260,1425 1425,1530
row group. I, you know,

1644
00:43:47,350 --> 00:43:48,340
0,210 210,465 465,675 675,855 855,990
I I have all the

1645
00:43:48,340 --> 00:43:49,780
0,260 610,960 960,1155 1155,1260 1260,1440
data for that I need

1646
00:43:49,780 --> 00:43:50,770
0,195 195,300 300,375 375,620 760,990
close to each other. But

1647
00:43:50,770 --> 00:43:51,505
0,180 180,315 315,450 450,585 585,735
I'm also getting the benefit

1648
00:43:51,505 --> 00:43:52,510
0,345 345,510 510,705 705,870 870,1005
ofunch I O because this

1649
00:43:52,510 --> 00:43:53,460
0,210 210,405 405,525 525,660 660,950
row group is gonna be,

1650
00:43:54,080 --> 00:43:54,895
0,245 245,365 365,530 530,680 680,815
you know, in in the

1651
00:43:54,895 --> 00:43:56,575
0,165 165,455 625,1365 1365,1560 1560,1680
tens of megabytes instead of

1652
00:43:56,575 --> 00:43:57,580
0,165 165,300 300,480 480,705 705,1005
like, you know, four kilobyte

1653
00:43:57,580 --> 00:43:59,040
0,60 60,165 165,480 480,740
or eight kilobyte pages.|
|

1654
00:44:02,300 --> 00:44:03,415
0,400 480,770 770,920 920,1025 1025,1115
Right, same thing with the
对，下一个人也是这样，诸如此类。

1655
00:44:03,415 --> 00:44:04,200
0,120 120,270 270,390 390,510 510,785
next guy, and so forth

1656
00:44:04,340 --> 00:44:05,620
0,275 275,550
and so.|
|

1657
00:44:06,050 --> 00:44:07,470
0,290 290,470 470,710 710,935 935,1420
This is roughly how parquet
这大概就是镶木地板的工作原理。有很多关于镶木地板或看起来是什么样子的图表或演示。再说一次，他们基本上使用了我们在这里使用的所有相同的语言。这里他们说，页面的默认大小是1兆字节，因为他们想要，你知道，把东西组合在一起，并尽可能多地伸缩IO。然后一行Groupp将是128兆字节。

1658
00:44:07,520 --> 00:44:09,010
0,400 930,1220 1220,1280 1280,1370 1370,1490
work. There's a lot of

1659
00:44:09,010 --> 00:44:12,730
0,690 690,1070 2710,3345 3345,3585 3585,3720
diagrams or presentations of what

1660
00:44:12,730 --> 00:44:13,770
0,315 315,480 480,645 645,780 780,1040
parquet or look look like.

1661
00:44:14,360 --> 00:44:16,285
0,400 450,850 1200,1520 1520,1685 1685,1925
And again, they're basically using

1662
00:44:16,285 --> 00:44:17,320
0,180 180,315 315,465 465,735 735,1035
all the same language that

1663
00:44:17,320 --> 00:44:19,360
0,180 180,330 330,495 495,830 1780,2040
that we're using here. And

1664
00:44:19,360 --> 00:44:20,440
0,135 135,285 285,495 495,780 780,1080
here they say the, the

1665
00:44:20,440 --> 00:44:21,295
0,255 255,465 465,585 585,675 675,855
default size of a page

1666
00:44:21,295 --> 00:44:22,555
0,165 165,300 300,945 945,1170 1170,1260
is one megabyte because they

1667
00:44:22,555 --> 00:44:23,370
0,90 90,195 195,405 405,585 585,815
want to have, you know,

1668
00:44:23,390 --> 00:44:24,565
0,290 290,500 500,755 755,935 935,1175
group things together and have,

1669
00:44:24,565 --> 00:44:25,720
0,225 225,455 505,780 780,960 960,1155
you know, as much stretch

1670
00:44:25,720 --> 00:44:26,890
0,255 255,345 345,450 450,710 910,1170
io as they can. And

1671
00:44:26,890 --> 00:44:27,565
0,105 105,225 225,405 405,585 585,675
then a row groupp is

1672
00:44:27,565 --> 00:44:29,700
0,75 75,135 135,365 810,1635 1635,2135
going to be 128 megabytes.|
|

1673
00:44:32,190 --> 00:44:34,900
0,400 1470,1820 1820,2120 2120,2345 2345,2710
Yes, same problem where you're
是的，你做的事也有同样的问题。

1674
00:44:35,280 --> 00:44:35,680
0,350
doing.|
|

1675
00:44:36,380 --> 00:44:37,460
0,350
I.|
我。|

1676
00:44:38,630 --> 00:44:40,105
0,275 275,455 455,760 990,1325 1325,1475
The statement is couldn't this
声明是，这难道不能让你在做全表扫描时仍然有一堆iOS的问题吗？

1677
00:44:40,105 --> 00:44:41,170
0,180 180,425 535,795 795,945 945,1065
also have you still have

1678
00:44:41,170 --> 00:44:41,650
0,90 90,240 240,360 360,420 420,480
the problem where you have

1679
00:44:41,650 --> 00:44:43,630
0,60 60,135 135,345 345,860 1750,1980
a bunch of ios if

1680
00:44:43,630 --> 00:44:44,320
0,135 135,210 210,330 330,480 480,690
you're doing a full table

1681
00:44:44,320 --> 00:44:46,220
0,320
scan?|
|

1682
00:44:46,220 --> 00:44:47,450
0,255 255,630 630,855 855,1035 1035,1230
The header tells you where
头球告诉你哪里是正确的，因为它是如此之大，我可以带来，我在这里带来了第一个头球。实际上，我显示的是页眉，但就像在真实系统或parking org中一样，它实际上位于页脚，因为假设文件是不可变的。所以我不知道会是什么样子，我不知道一切会是什么样子，直到我写完它。所以它在页脚。但这是一个次要问题。所以他的声明是，如果我在做这个包的事情，就不会有和这里的行存储一样的问题，因为现在如果我把整个行组都放进来。

1683
00:44:47,450 --> 00:44:50,180
0,225 225,530 1180,1580 2020,2420 2440,2730
things are right and because

1684
00:44:50,180 --> 00:44:51,155
0,195 195,360 360,615 615,825 825,975
it's so huge like I

1685
00:44:51,155 --> 00:44:51,935
0,150 150,300 300,495 495,675 675,780
could bring in, I bring

1686
00:44:51,935 --> 00:44:52,870
0,90 90,210 210,405 405,675 675,935
in this first header here.

1687
00:44:53,070 --> 00:44:55,250
0,400 1260,1595 1595,1745 1745,1895 1895,2180
Actually, I'm showing the header,

1688
00:44:55,250 --> 00:44:56,285
0,180 180,330 330,525 525,765 765,1035
but like in in real

1689
00:44:56,285 --> 00:44:57,200
0,285 285,450 450,525 525,705 705,915
systems or in parking org,

1690
00:44:57,200 --> 00:44:58,180
0,225 225,345 345,435 435,555 555,980
it's actually at the footer

1691
00:44:58,350 --> 00:44:59,255
0,335 335,560 560,695 695,800 800,905
because assuming the file is

1692
00:44:59,255 --> 00:45:00,530
0,545 565,795 795,885 885,1110 1110,1275
immutable. So I don't know

1693
00:45:00,530 --> 00:45:01,640
0,195 195,470 550,810 810,1005 1005,1110
what like, I don't know

1694
00:45:01,640 --> 00:45:02,855
0,260 280,600 600,840 840,975 975,1215
what where everything's gonna be

1695
00:45:02,855 --> 00:45:03,910
0,180 180,300 300,495 495,735 735,1055
until I finish writing it.

1696
00:45:04,080 --> 00:45:05,290
0,305 305,545 545,650 650,800 800,1210
So it's in the footer.

1697
00:45:05,340 --> 00:45:07,630
0,305 305,1055 1055,1355 1355,1660 1890,2290
But that's an aside. So

1698
00:45:07,710 --> 00:45:09,065
0,290 290,485 485,790 960,1265 1265,1355
his statement is don't have

1699
00:45:09,065 --> 00:45:09,635
0,75 75,195 195,360 360,480 480,570
the same problem as a

1700
00:45:09,635 --> 00:45:10,460
0,150 150,345 345,540 540,675 675,825
row store here if I'm

1701
00:45:10,460 --> 00:45:11,680
0,135 135,345 345,660 660,870 870,1220
doing this packs thing because

1702
00:45:12,750 --> 00:45:13,835
0,380 380,605 605,740 740,905 905,1085
now if I bring this

1703
00:45:13,835 --> 00:45:15,400
0,240 240,510 510,720 720,995
entire row group in.|
|

1704
00:45:15,400 --> 00:45:15,895
0,120 120,240 240,330 330,405 405,495
Am I going to read
我是不是要读一大堆我不需要的东西？所以你不会把整排的人都带进来？你把头放进来，说这是我的属性所在位置的偏移量，然后继续去取那些。

1705
00:45:15,895 --> 00:45:16,345
0,75 75,165 165,270 270,360 360,450
a bunch of stuff I

1706
00:45:16,345 --> 00:45:18,235
0,165 165,395 655,1055 1375,1620 1620,1890
don't need? So you don't

1707
00:45:18,235 --> 00:45:19,075
0,180 180,315 315,465 465,660 660,840
bring the whole row group

1708
00:45:19,075 --> 00:45:19,960
0,180 180,330 330,465 465,630 630,885
in? You bring the header

1709
00:45:19,960 --> 00:45:21,505
0,260 490,735 735,840 840,1100 1150,1545
in and you say here's

1710
00:45:21,505 --> 00:45:22,825
0,105 105,555 555,855 855,1125 1125,1320
the offsets now of where

1711
00:45:22,825 --> 00:45:24,600
0,240 240,525 525,815 1255,1515 1515,1775
my attributes are and then

1712
00:45:24,890 --> 00:45:25,800
0,260 260,350 350,410 410,590 590,910
go ahead and fetch those.|
|

1713
00:45:33,230 --> 00:45:34,290
0,245 245,365 365,500 500,710 710,1060
Actually, here you can see.|
实际上，你可以在这里看到。|

1714
00:45:36,660 --> 00:45:38,225
0,335 335,790 990,1280 1280,1430 1430,1565
Here, here's you see the
这里，您看到的是页脚，而不是页眉、元数据、这里的内容、文件和列元数据。偏移量代替了页眉，只是在页脚，等等都是一样的。

1715
00:45:38,225 --> 00:45:39,545
0,225 225,455 895,1140 1140,1230 1230,1320
footer here instead of the

1716
00:45:39,545 --> 00:45:40,625
0,330 330,540 540,885 885,1005 1005,1080
header, the metadata, what's in

1717
00:45:40,625 --> 00:45:41,990
0,180 180,375 375,635 925,1200 1200,1365
here, the file and column

1718
00:45:41,990 --> 00:45:44,255
0,620 1060,1305 1305,1590 1590,1850 2020,2265
metadata. The offsets are instead

1719
00:45:44,255 --> 00:45:45,125
0,75 75,150 150,390 390,795 795,870
of the header, it's just

1720
00:45:45,125 --> 00:45:47,360
0,90 90,210 210,2025 2025,2130 2130,2235
in the footerquetc is the

1721
00:45:47,360 --> 00:45:48,180
0,105 105,380
same way.|
|

1722
00:45:50,350 --> 00:45:52,100
0,260 260,515 515,910
All right, so.|
好吧，那么。|

1723
00:45:52,840 --> 00:45:53,840
0,245 245,350 350,485 485,680 680,1000
As you say multiple times,
正如您多次提到的，io一直是我们的主要瓶颈，尤其是在分析查询和。

1724
00:45:54,070 --> 00:45:54,960
0,440 440,575 575,710 710,815 815,890
io has always been the

1725
00:45:54,960 --> 00:45:57,075
0,120 120,525 525,630 630,890 1810,2115
main bottleneck we have, especially

1726
00:45:57,075 --> 00:45:59,880
0,150 150,510 510,935 1345,1745
for analytical queries and.|
|

1727
00:46:00,010 --> 00:46:01,350
0,320 320,640 660,950 950,1100 1100,1340
If we assume the data
如果我们假设媒体上的数据，那就意味着。

1728
00:46:01,350 --> 00:46:02,430
0,270 270,420 420,645 645,885 885,1080
on the press, that means

1729
00:46:02,430 --> 00:46:04,600
0,320 730,1130
like the.|
|

1730
00:46:04,600 --> 00:46:05,800
0,210 210,440 550,810 810,960 960,1200
You know, whatever the exact
您知道，无论表中两位数的确切大小是多少，每个页面都会带来确切的数据，因此，减少查询速度的最明显方法是什么？你可以的，你可以的。

1731
00:46:05,800 --> 00:46:07,410
0,285 285,465 465,570 570,980 1210,1610
size of a twople for

1732
00:46:07,430 --> 00:46:10,680
0,400 870,1130 1130,1390 2580,2915 2915,3250
in a table, every page

1733
00:46:10,820 --> 00:46:12,070
0,275 275,395 395,640 660,995 995,1250
is going to bring exactly

1734
00:46:12,070 --> 00:46:14,785
0,320 430,735 735,1040 2320,2595 2595,2715
that data in, and so

1735
00:46:14,785 --> 00:46:15,775
0,75 75,255 255,480 480,705 705,990
the most obvious way to

1736
00:46:15,775 --> 00:46:18,505
0,315 315,695 2095,2430 2430,2610 2610,2730
reduce the to speed up

1737
00:46:18,505 --> 00:46:19,920
0,425 565,840 840,1020 1020,1170 1170,1415
queries? You can, you can.|
|

1738
00:46:20,680 --> 00:46:22,010
0,230 230,350 350,640 720,1040 1040,1330
You can basically skip data
你基本上可以跳过数据，或者你可以让你提取的数据，把更多的东西放入内存。因此，跳过数据是comm存储的帮助，因为您不必读取不需要的属性。压缩是另一种说法，好吧，对于我获取的每个页面，我得到的比未压缩的页面多两个。

1739
00:46:22,390 --> 00:46:23,925
0,400 450,710 710,970 1080,1385 1385,1535
or you can make the

1740
00:46:23,925 --> 00:46:25,200
0,135 135,270 270,405 405,725 955,1275
data you do fetch, bring

1741
00:46:25,200 --> 00:46:27,195
0,315 315,600 600,795 795,1100 1690,1995
more things into memory. So

1742
00:46:27,195 --> 00:46:28,485
0,315 315,600 600,960 960,1185 1185,1290
skipping data is what the

1743
00:46:28,485 --> 00:46:29,325
0,165 165,360 360,495 495,645 645,840
comm store stuff helps with

1744
00:46:29,325 --> 00:46:30,660
0,165 165,330 330,635 895,1185 1185,1335
because you avoid having to

1745
00:46:30,660 --> 00:46:32,210
0,260 730,1035 1035,1125 1125,1305 1305,1550
read attributes you don't need.

1746
00:46:32,710 --> 00:46:33,780
0,440 440,650 650,830 830,965 965,1070
Compression is another way to

1747
00:46:33,780 --> 00:46:34,710
0,195 195,405 405,510 510,690 690,930
say, okay, for every page

1748
00:46:34,710 --> 00:46:36,105
0,165 165,470 640,900 900,1095 1095,1395
I fetch, I get more

1749
00:46:36,105 --> 00:46:37,320
0,375 375,465 465,585 585,875 955,1215
twoils than I would if

1750
00:46:37,320 --> 00:46:38,940
0,105 105,210 210,770
it was uncompressed.|
|

1751
00:46:38,980 --> 00:46:39,525
0,275 275,380 380,455 455,515 515,545
Now this is going to
这将是速度和撞车率之间的权衡。显然，磁盘可能会比C/U慢，尤其是在云环境中。因此，我愿意支付必须解压缩和压缩数据的额外成本，因为现在这又一次减少了我在I操作上浪费的取东西的时间。

1752
00:46:39,525 --> 00:46:40,460
0,60 60,210 210,390 390,600 600,935
be this trade off between

1753
00:46:40,930 --> 00:46:42,510
0,400 720,980 980,1205 1205,1445 1445,1580
eh speed up and the

1754
00:46:42,510 --> 00:46:45,195
0,180 180,500 1180,1580 1960,2445 2445,2685
crash ratio. Obviously disk is

1755
00:46:45,195 --> 00:46:46,755
0,120 120,195 195,425 835,1200 1200,1560
going to be potentially slower

1756
00:46:46,755 --> 00:46:48,075
0,365 475,735 735,825 825,1005 1005,1320
than C P U, especially

1757
00:46:48,075 --> 00:46:49,560
0,225 225,360 360,540 540,845 1195,1485
in the cloud setting. And

1758
00:46:49,560 --> 00:46:50,870
0,240 240,555 555,750 750,1005 1005,1310
so I'm willing to pay

1759
00:46:50,980 --> 00:46:52,065
0,245 245,455 455,740 740,935 935,1085
the extra cost of having

1760
00:46:52,065 --> 00:46:53,270
0,150 150,540 540,660 660,885 885,1205
to decompress and compress data

1761
00:46:53,860 --> 00:46:55,455
0,275 275,515 515,800 800,1210 1260,1595
because now again it reduce

1762
00:46:55,455 --> 00:46:56,750
0,335 445,705 705,795 795,900 900,1295
my amount of I ops

1763
00:46:56,980 --> 00:46:57,840
0,245 245,350 350,470 470,620 620,860
amount of time I'm wasting

1764
00:46:57,840 --> 00:46:59,085
0,120 120,255 255,680 760,1005 1005,1245
on I ops to bring

1765
00:46:59,085 --> 00:47:00,520
0,225 225,420 420,615 615,905
to fetch things in.|
|

1766
00:47:01,970 --> 00:47:05,695
0,290 290,545 545,905 905,1300 3360,3725
Things are slightly getting the
事情正在略微得到争议和CPU速度之间的区别。

1767
00:47:05,695 --> 00:47:06,670
0,210 210,375 375,555 555,735 735,975
sort of the difference between

1768
00:47:06,670 --> 00:47:07,860
0,390 390,510 510,795 795,930 930,1190
dispute and cpu speed is

1769
00:47:08,180 --> 00:47:10,120
0,400
getting.|
|

1770
00:47:10,450 --> 00:47:11,550
0,230 230,350 350,500 500,740 740,1100
The distance is getting smaller,
距离变得越来越小，在某些情况下，磁盘最近实际上变得如此之快，而您可能不希望事情被压缩。

1771
00:47:11,550 --> 00:47:12,660
0,270 270,450 450,600 600,810 810,1110
where in some cases disk

1772
00:47:12,660 --> 00:47:13,560
0,150 150,315 315,465 465,660 660,900
is actually getting so fast

1773
00:47:13,560 --> 00:47:15,045
0,350 640,915 915,1080 1080,1245 1245,1485
lately, where maybe you don't

1774
00:47:15,045 --> 00:47:16,010
0,135 135,315 315,450 450,555 555,965
want things to be compressed.|
|

1775
00:47:16,820 --> 00:47:17,615
0,195 195,255 255,345 345,510 510,795
There'll be some other benefits
我们很快就会看到一些其他的好处，在那里我们确实保持了压缩。当数据系统实际处理内存中的数据时，它实际上可以运行得更快，我们将在几周内讨论这一点，但总的来说，对于大多数系统来说，压缩磁盘上的数据总是一件好事。

1776
00:47:17,615 --> 00:47:18,320
0,285 285,345 345,390 390,480 480,705
we'll see in a second

1777
00:47:18,320 --> 00:47:19,265
0,225 225,360 360,555 555,765 765,945
where we do keep things

1778
00:47:19,265 --> 00:47:20,390
0,345 345,480 480,615 615,885 885,1125
compressed. The data system actually

1779
00:47:20,390 --> 00:47:22,010
0,150 150,330 330,620 1240,1485 1485,1620
can run faster when it

1780
00:47:22,010 --> 00:47:23,260
0,150 150,410 520,810 810,975 975,1250
actually processes things in memory,

1781
00:47:23,460 --> 00:47:25,430
0,245 245,395 395,560 560,880 1710,1970
and we'll cover that in

1782
00:47:25,430 --> 00:47:26,825
0,120 120,240 240,465 465,830 1090,1395
a few weeks, but in

1783
00:47:26,825 --> 00:47:29,255
0,305 1015,1275 1275,1440 1440,1745 1915,2430
general, for most systems, compressing

1784
00:47:29,255 --> 00:47:30,125
0,135 135,270 270,525 525,660 660,870
things on disk is, is

1785
00:47:30,125 --> 00:47:30,560
0,165 165,255 255,300 300,345 345,435
always going to be a

1786
00:47:30,560 --> 00:47:31,360
0,260
win.|
|

1787
00:47:33,230 --> 00:47:34,540
0,350 350,620 620,980 980,1190 1190,1310
So any compression scheme we
因此，我们需要使用的任何压缩方案都必须产生固定的长度值。正如我们前面所说的，因为我们希望将其存储在列存储中，所以我们希望确保所有集合的长度始终固定。

1788
00:47:34,540 --> 00:47:36,010
0,105 105,210 210,470 940,1260 1260,1470
need to use has to

1789
00:47:36,010 --> 00:47:37,945
0,210 210,420 420,630 630,950 1660,1935
produce fixed length values. As

1790
00:47:37,945 --> 00:47:38,845
0,135 135,255 255,480 480,750 750,900
we said before, because we

1791
00:47:38,845 --> 00:47:39,460
0,90 90,180 180,285 285,450 450,615
want to store this in

1792
00:47:39,460 --> 00:47:41,185
0,135 135,375 375,740 1330,1605 1605,1725
a column store, we want

1793
00:47:41,185 --> 00:47:42,205
0,75 75,210 210,420 420,725 745,1020
to make sure that we

1794
00:47:42,205 --> 00:47:43,015
0,135 135,270 270,435 435,615 615,810
always have fixed length all

1795
00:47:43,015 --> 00:47:44,900
0,305
sets.|
|

1796
00:47:45,500 --> 00:47:47,095
0,365 365,635 635,935 935,1325 1325,1595
In some cases, too, we
在某些情况下，我们也希望在实际解压缩时尽可能长时间地延迟，为什么我们执行查询，然后我们会再次看到这一点。我们将在讨论查询执行时更多地讨论这一点，但这里的想法是，如果我有一堆1兆字节的字符串。

1797
00:47:47,095 --> 00:47:49,285
0,135 135,395 1195,1595 1735,2010 2010,2190
want to delay when we

1798
00:47:49,285 --> 00:47:50,200
0,165 165,495 495,690 690,825 825,915
actually decompress things for as

1799
00:47:50,200 --> 00:47:51,520
0,150 150,315 315,590 790,1095 1095,1320
long as possible, why we

1800
00:47:51,520 --> 00:47:52,885
0,195 195,650 910,1140 1140,1290 1290,1365
execute queries and we'll see

1801
00:47:52,885 --> 00:47:53,755
0,180 180,465 465,705 705,780 780,870
this again. We'll talk about

1802
00:47:53,755 --> 00:47:54,460
0,105 105,300 300,495 495,615 615,705
this more when we talk

1803
00:47:54,460 --> 00:47:55,840
0,90 90,300 300,620 910,1170 1170,1380
about query execution, but the

1804
00:47:55,840 --> 00:47:57,055
0,255 255,405 405,510 510,770 970,1215
idea here is that if

1805
00:47:57,055 --> 00:47:57,750
0,105 105,195 195,285 285,420 420,695
I have a bunch of

1806
00:47:57,890 --> 00:48:00,440
0,400 450,770 770,1310 1310,1660
these one megabyte strings.|
|

1807
00:48:00,440 --> 00:48:01,550
0,260 430,765 765,945 945,1035 1035,1110
Uh, that that are in
呃，那在我的表格里，但是我可以，我可以把它们转换成32位整数。我希望尽可能长地处理32位整数，因为我必须将数据从一个运算符复制到下一个运算符。只要我退出查询，或者如果它是通过网络复制的分布式系统，我希望尽可能长时间地保持压缩的内容，并且只有在我实际上必须显示需要它的内容时才将其解压缩，以证明某些内容需要DBD压缩或用户需要输出。

1808
00:48:01,550 --> 00:48:03,110
0,135 135,440 1030,1290 1290,1425 1425,1560
my table, but I can

1809
00:48:03,110 --> 00:48:04,025
0,135 135,345 345,570 570,750 750,915
I can convert them to

1810
00:48:04,025 --> 00:48:05,600
0,315 315,405 405,905 1075,1395 1395,1575
32 bit integers. I want

1811
00:48:05,600 --> 00:48:07,670
0,260 460,860 1270,1680 1680,1740 1740,2070
to process 32 bit integers

1812
00:48:07,670 --> 00:48:08,620
0,120 120,225 225,420 420,645 645,950
for as long as possible

1813
00:48:09,240 --> 00:48:10,025
0,245 245,350 350,440 440,545 545,785
because I have to copy

1814
00:48:10,025 --> 00:48:10,970
0,285 285,465 465,675 675,870 870,945
data from one operator to

1815
00:48:10,970 --> 00:48:11,780
0,75 75,255 255,495 495,645 645,810
the next. As as I

1816
00:48:11,780 --> 00:48:13,475
0,180 180,270 270,530 910,1310 1390,1695
exit the query I or

1817
00:48:13,475 --> 00:48:14,470
0,165 165,300 300,435 435,675 675,995
if it's a distributed system

1818
00:48:14,550 --> 00:48:15,830
0,365 365,485 485,590 590,820 1020,1280
copied over the network, I

1819
00:48:15,830 --> 00:48:16,460
0,90 90,180 180,330 330,510 510,630
want to keep things that

1820
00:48:16,460 --> 00:48:17,300
0,225 225,360 360,495 495,645 645,840
compress as long as possible

1821
00:48:17,300 --> 00:48:18,710
0,225 225,530 550,1095 1095,1260 1260,1410
and only decompress it when

1822
00:48:18,710 --> 00:48:19,370
0,165 165,315 315,405 405,510 510,660
I actually have to show

1823
00:48:19,370 --> 00:48:21,020
0,210 210,480 480,830 1210,1455 1455,1650
something back to that something

1824
00:48:21,020 --> 00:48:22,835
0,270 270,525 525,885 885,1280 1510,1815
needs it dbd compressed or

1825
00:48:22,835 --> 00:48:23,950
0,165 165,345 345,555 555,780 780,1115
the user needs the output.|
|

1826
00:48:24,530 --> 00:48:25,705
0,440 440,575 575,800 800,1025 1025,1175
Joins makes that makes that
Joins使这一点变得更加困难，但我们稍后将讨论这一点。

1827
00:48:25,705 --> 00:48:27,310
0,275 685,930 930,1080 1080,1325 1345,1605
harder, but we'll cover that

1828
00:48:27,310 --> 00:48:28,460
0,135 135,240 240,315 315,560
later in a second.|
|

1829
00:48:28,720 --> 00:48:29,760
0,260 260,380 380,620 620,875 875,1040
And then the most important
然后，对于我们的数据系统中的任何压缩方案，我们需要的最重要的是我们需要确保我们使用的是无损方案。

1830
00:48:29,760 --> 00:48:30,345
0,150 150,240 240,360 360,480 480,585
thing we need for any

1831
00:48:30,345 --> 00:48:31,155
0,315 315,510 510,570 570,645 645,810
compression scheme in our data

1832
00:48:31,155 --> 00:48:32,595
0,305 685,975 975,1125 1125,1260 1260,1440
system is we need to

1833
00:48:32,595 --> 00:48:33,450
0,225 225,405 405,570 570,690 690,855
ensure that we're using a

1834
00:48:33,450 --> 00:48:34,920
0,465 465,800
lossless scheme.|
|

1835
00:48:35,650 --> 00:48:36,270
0,230 230,320 320,410 410,485 485,620
And I know what that
我知道这意味着什么。

1836
00:48:36,270 --> 00:48:37,540
0,290
means.|
|

1837
00:48:37,610 --> 00:48:41,060
0,425 425,590 590,1090
Lawsuit versus lossless.|
官司VS无损。|

1838
00:48:41,060 --> 00:48:42,245
0,270 270,585 585,765 765,990 990,1185
Right. There's no information loss
正确的。当你正确地压缩或解压时，信息不会丢失，对吗？因此，一个诉讼方案可能是MP、3 MP、4 jpeg，他们在做一些关于人类如何感知音频数据或视频数据的把戏，以将东西压缩到更小的尺寸。

1839
00:48:42,245 --> 00:48:43,450
0,165 165,300 300,570 570,840 840,1205
when you compress things right

1840
00:48:43,470 --> 00:48:45,970
0,260 260,605 605,815 815,1150 2100,2500
or decompress them, right? So

1841
00:48:46,530 --> 00:48:47,705
0,290 290,725 725,905 905,1040 1040,1175
a lawsuit scheme would be

1842
00:48:47,705 --> 00:48:49,085
0,165 165,495 495,720 720,1095 1095,1380
like mp, three mp, four

1843
00:48:49,085 --> 00:48:51,665
0,815 1345,1740 1740,2115 2115,2325 2325,2580
jpeg, where they're doing some

1844
00:48:51,665 --> 00:48:53,195
0,485 505,795 795,1080 1080,1350 1350,1530
tricks about how the human

1845
00:48:53,195 --> 00:48:54,650
0,515 685,915 915,990 990,1200 1200,1455
perceives, you know, audio data

1846
00:48:54,650 --> 00:48:56,075
0,135 135,315 315,650 940,1185 1185,1425
or visual data to compress

1847
00:48:56,075 --> 00:48:57,365
0,210 210,465 465,815 835,1110 1110,1290
things down to a much

1848
00:48:57,365 --> 00:48:58,720
0,255 255,605
smaller size.|
|

1849
00:48:58,720 --> 00:48:59,680
0,195 195,285 285,560 610,855 855,960
So that means if you
这意味着如果你有你拍摄的原始图像和原始声音文件，当你压缩它的时候，你不会得到相同的，相同的值，如果你愿意，当你解压缩它的时候。

1850
00:48:59,680 --> 00:49:00,595
0,165 165,330 330,480 480,705 705,915
have the raw image you

1851
00:49:00,595 --> 00:49:01,405
0,165 165,300 300,390 390,555 555,810
took and the raw sound

1852
00:49:01,405 --> 00:49:02,515
0,240 240,405 405,665 745,1005 1005,1110
file you took when you

1853
00:49:02,515 --> 00:49:03,640
0,240 240,390 390,585 585,815 865,1125
compress it, you're not going

1854
00:49:03,640 --> 00:49:04,500
0,90 90,210 210,420 420,600 600,860
to get back the same,

1855
00:49:04,880 --> 00:49:06,460
0,260 260,520 720,1120 1200,1460 1460,1580
the same values if you

1856
00:49:06,460 --> 00:49:08,040
0,260 520,780 780,900 900,1290 1290,1580
will, when you decompress it.|
|

1857
00:49:09,095 --> 00:49:09,575
0,105 105,210 210,300 300,390 390,480
We don't want to do
我们不想在数据库系统中这样做，因为。

1858
00:49:09,575 --> 00:49:10,420
0,75 75,135 135,225 225,465 465,845
that in a database system

1859
00:49:10,470 --> 00:49:11,900
0,400
because.|
|

1860
00:49:12,250 --> 00:49:13,230
0,320 320,500 500,620 620,740 740,980
But as you said before,
但就像你之前说的，人们不会丢失数据，对吗？如果，你知道，如果你的银行账户中有100美元，然后他们压缩数据，当数据被解压缩时，现在你有90美元，你会注意到，你会抱怨，对吗？因此，通常情况下，你知道，大多数系统不会仅仅因为你知道自己有问题，就使用有损计划，你可以做法律。

1861
00:49:13,230 --> 00:49:15,080
0,255 255,510 510,735 735,1070 1450,1850
people don't losing data, right?

1862
00:49:15,280 --> 00:49:16,770
0,400 990,1235 1235,1310 1310,1385 1385,1490
If, you know, if you

1863
00:49:16,770 --> 00:49:17,430
0,105 105,300 300,465 465,570 570,660
have 100 dollars in your

1864
00:49:17,430 --> 00:49:18,435
0,180 180,495 495,735 735,855 855,1005
bank account and then they

1865
00:49:18,435 --> 00:49:19,290
0,285 285,435 435,615 615,780 780,855
compress the data and when

1866
00:49:19,290 --> 00:49:20,055
0,60 60,150 150,510 510,645 645,765
it gets decompress and now

1867
00:49:20,055 --> 00:49:21,015
0,120 120,365 445,675 675,765 765,960
you have, you know, ninety

1868
00:49:21,015 --> 00:49:22,860
0,335 895,1230 1230,1335 1335,1590 1590,1845
dollars, you're gonna notice, you're

1869
00:49:22,860 --> 00:49:25,520
0,150 150,435 435,800 1360,1760 2260,2660
gonna complain, right? So typically,

1870
00:49:25,900 --> 00:49:27,405
0,230 230,460 780,1085 1085,1310 1310,1505
you know, most systems will

1871
00:49:27,405 --> 00:49:28,875
0,210 210,540 540,825 825,1185 1185,1470
not use a lossy scheme

1872
00:49:28,875 --> 00:49:31,965
0,315 315,635 1495,1725 1725,1955 2725,3090
just because you know you

1873
00:49:31,965 --> 00:49:34,140
0,135 135,425 1375,1695 1695,1950 1950,2175
have problems, you can do

1874
00:49:34,140 --> 00:49:35,260
0,290
laws.|
|

1875
00:49:35,260 --> 00:49:37,120
0,375 375,770 1240,1545 1545,1725 1725,1860
Compression yourself, right. So think
给自己加压，对。所以想一想，我的意思是，就像应用程序可以做到这一点。就像如果我有这个，每秒都在记录这个房间的温度，对吗？我这样做了十年，我真的需要知道每一秒的确切温度是多少吗？你知道，一年后？不，我可以把它压缩到，这是每分钟的平均温度。

1876
00:49:37,120 --> 00:49:39,220
0,120 120,380 1600,1860 1860,1980 1980,2100
of like, I mean like

1877
00:49:39,220 --> 00:49:40,285
0,210 210,480 480,675 675,825 825,1065
the application could do this.

1878
00:49:40,285 --> 00:49:42,240
0,365 805,1095 1095,1260 1260,1535 1555,1955
Like if I have um,

1879
00:49:42,830 --> 00:49:43,705
0,320 320,500 500,590 590,680 680,875
keeping track of the temperature

1880
00:49:43,705 --> 00:49:45,210
0,165 165,285 285,575 805,1155 1155,1505
of this room every second,

1881
00:49:45,680 --> 00:49:46,480
0,305 305,440 440,545 545,680 680,800
right? And I do this

1882
00:49:46,480 --> 00:49:48,370
0,210 210,555 555,840 840,1130 1660,1890
for for ten years, do

1883
00:49:48,370 --> 00:49:49,260
0,120 120,330 330,510 510,630 630,890
I really need to know

1884
00:49:49,640 --> 00:49:50,800
0,260 260,410 410,605 605,875 875,1160
what the exact temperature was

1885
00:49:50,800 --> 00:49:52,090
0,320 520,765 765,885 885,1080 1080,1290
at at a one second

1886
00:49:52,090 --> 00:49:53,485
0,470 700,945 945,1080 1080,1245 1245,1395
interval? You know, a year

1887
00:49:53,485 --> 00:49:55,165
0,120 120,365 955,1350 1350,1590 1590,1680
from now? No, I could

1888
00:49:55,165 --> 00:49:56,095
0,135 135,405 405,525 525,705 705,930
maybe compress it down to,

1889
00:49:56,095 --> 00:49:57,175
0,210 210,270 270,450 450,785 805,1080
here's the average temperature per

1890
00:49:57,175 --> 00:49:58,020
0,275
minute.|
|

1891
00:49:58,330 --> 00:49:59,595
0,400 510,740 740,845 845,1115 1115,1265
Right. So I can't get
正确的。因此，我无法恢复原始数据，因为它已被压缩或聚合，这可能没有问题。但同样，作为应用程序中的用户，这是美国人知道这是否可以做的事情。数据系统做到了这一点。因此，数据库系统将始终使用无损方案。

1892
00:49:59,595 --> 00:50:01,200
0,210 210,360 360,540 540,875 1285,1605
back the original data because

1893
00:50:01,200 --> 00:50:03,170
0,195 195,345 345,740 1180,1440 1440,1970
it been compressed or aggregated

1894
00:50:03,640 --> 00:50:04,730
0,275 275,425 425,575 575,770 770,1090
and that might be okay.

1895
00:50:05,260 --> 00:50:06,440
0,260 260,395 395,635 635,830 830,1180
But again, that's something you

1896
00:50:06,520 --> 00:50:07,470
0,275 275,410 410,605 605,785 785,950
as a user in the

1897
00:50:07,470 --> 00:50:08,400
0,210 210,375 525,675 675,810 810,930
application a US to know

1898
00:50:08,400 --> 00:50:09,150
0,135 135,300 300,435 435,615 615,750
whether that's an okay thing

1899
00:50:09,150 --> 00:50:10,545
0,120 120,380 490,750 750,1010 1060,1395
to do. The data system

1900
00:50:10,545 --> 00:50:11,475
0,210 210,435 435,645 645,750 750,930
does it. Therefore, the database

1901
00:50:11,475 --> 00:50:12,195
0,210 210,405 405,585 585,675 675,720
system is always going to

1902
00:50:12,195 --> 00:50:13,430
0,45 45,275 295,570 570,930 930,1235
be using a lossless scheme.|
|

1903
00:50:15,490 --> 00:50:16,400
0,245 245,365 365,485 485,620 620,910
So now the question is,
所以现在的问题是，我们实际上想要压缩什么？有，有几个不同的选择。其中之一是我们可以压缩单个页面或一块数据。

1904
00:50:17,170 --> 00:50:17,910
0,245 245,335 335,500 500,665 665,740
what do we actually want

1905
00:50:17,910 --> 00:50:20,010
0,75 75,470 1120,1410 1410,1790 1810,2100
to compress? And there's, there's

1906
00:50:20,010 --> 00:50:21,690
0,60 60,165 165,330 330,620 1420,1680
a couple different choices. One

1907
00:50:21,690 --> 00:50:22,710
0,120 120,240 240,345 345,740 760,1020
is we can compress a

1908
00:50:22,710 --> 00:50:23,700
0,210 210,495 495,675 675,810 810,990
single page or a block

1909
00:50:23,700 --> 00:50:24,880
0,150 150,410
of data.|
|

1910
00:50:24,880 --> 00:50:25,870
0,260 280,525 525,675 675,825 825,990
Uh, so that's all the
呃，这就是同一张桌子上的所有两个螺栓。我们可以单独压缩一个工具。如果它是排仓制，我们可以做更细的颗粒。我们可以说我压缩在一个、两个、一个单一属性中，然后压缩它。

1911
00:50:25,870 --> 00:50:27,010
0,120 120,285 285,530 730,990 990,1140
two bolts within the same

1912
00:50:27,010 --> 00:50:29,050
0,290 1000,1260 1260,1380 1380,1730 1780,2040
table. We can compress a

1913
00:50:29,050 --> 00:50:30,235
0,165 165,360 360,585 585,915 915,1185
single tool by itself. If

1914
00:50:30,235 --> 00:50:31,590
0,335 415,675 675,840 840,1050 1050,1355
it's a row store system,

1915
00:50:33,290 --> 00:50:34,105
0,245 245,350 350,470 470,620 620,815
we can go even more

1916
00:50:34,105 --> 00:50:34,840
0,210 210,375 375,480 480,615 615,735
fine grain than that. We

1917
00:50:34,840 --> 00:50:36,430
0,90 90,285 285,510 510,920 1210,1590
can say I compress within

1918
00:50:36,430 --> 00:50:38,280
0,270 270,540 540,870 870,1220 1330,1850
one, two, one single attribute

1919
00:50:38,660 --> 00:50:40,360
0,275 275,560 560,880
and compress that.|
|

1920
00:50:40,360 --> 00:50:41,850
0,260 670,930 930,1050 1050,1200 1200,1490
EM, so think of like
嗯，就像溢出表一样。我们之前说过，如果你在存储巨大的文本属性或在维基百科中，修订可能是大量的文本。我忘记了维基百科上最大的文章是什么，它是星球大战的东西，所以，你知道，可能是千字节的文本数据。我可以为这一点进行压缩。你知道，就是那个词条。

1921
00:50:41,930 --> 00:50:43,210
0,260 260,620 620,905 905,1160 1160,1280
the overflow tables. We said

1922
00:50:43,210 --> 00:50:45,720
0,260 640,885 885,1080 1080,1370 2110,2510
before, if you're storing huge

1923
00:50:46,640 --> 00:50:49,090
0,400 720,1210 1380,1700 1700,1880 1880,2450
text attributes or in Wikipedia,

1924
00:50:49,090 --> 00:50:52,110
0,135 135,500 2230,2475 2475,2670 2670,3020
the revisions could be a

1925
00:50:52,340 --> 00:50:54,970
0,275 275,425 425,700 2190,2495 2495,2630
lot of text. I forget

1926
00:50:54,970 --> 00:50:56,100
0,75 75,180 180,420 420,885 885,1130
what the largest Wikipedia article

1927
00:50:56,330 --> 00:50:57,940
0,305 305,545 545,970 990,1355 1355,1610
is and it's something star

1928
00:50:57,940 --> 00:51:00,295
0,290 700,1100 1510,1905 1905,2145 2145,2355
wars so that, you know,

1929
00:51:00,295 --> 00:51:01,480
0,195 195,315 315,795 795,960 960,1185
could be kilobytes of text

1930
00:51:01,480 --> 00:51:02,785
0,320 520,750 750,825 825,930 930,1305
data. And I could compress

1931
00:51:02,785 --> 00:51:04,390
0,270 270,435 435,695 1165,1410 1410,1605
just for that. You know,

1932
00:51:04,390 --> 00:51:05,860
0,270 270,590 610,1010
that one entry.|
|

1933
00:51:05,860 --> 00:51:07,540
0,290 820,1095 1095,1410 1410,1545 1545,1680
EM and postgres to this
EM和Postgres这样做，还有一堆其他系统这样做。或者，如果是列存储系统，我也可以按下单列。

1934
00:51:07,540 --> 00:51:08,050
0,135 135,255 255,345 345,405 405,510
and a bunch of other

1935
00:51:08,050 --> 00:51:10,555
0,210 210,390 390,650 1360,1760 2110,2505
systems do this. Or alternatively,

1936
00:51:10,555 --> 00:51:12,025
0,105 105,270 270,575 715,1115 1165,1470
I could press for a

1937
00:51:12,025 --> 00:51:13,990
0,255 255,605 1465,1725 1725,1890 1890,1965
single column if it's a

1938
00:51:13,990 --> 00:51:15,580
0,195 195,420 420,710
column store system.|
|

1939
00:51:16,280 --> 00:51:17,110
0,245 245,410 410,515 515,680 680,830
So let's talk about how
所以让我们讨论一下如何在块级别上做到这一点，然后我们将花大部分时间来讨论如何在列级别上做到这一点，因为这对于专栏系统来说是最重要的。

1940
00:51:17,110 --> 00:51:17,710
0,90 90,180 180,270 270,420 420,600
you can do this at

1941
00:51:17,710 --> 00:51:20,245
0,135 135,315 315,620 2110,2370 2370,2535
the block level, and then

1942
00:51:20,245 --> 00:51:21,010
0,225 225,360 360,480 480,600 600,765
we'll spend most our time

1943
00:51:21,010 --> 00:51:21,535
0,180 180,300 300,345 345,405 405,525
talking how to do this

1944
00:51:21,535 --> 00:51:22,450
0,120 120,240 240,450 450,720 720,915
at the column level, because

1945
00:51:22,450 --> 00:51:24,270
0,260 790,1125 1125,1305 1305,1485 1485,1820
that matters the most for

1946
00:51:24,470 --> 00:51:26,140
0,245 245,350 350,695 695,970
in a columnar system.|
|

1947
00:51:27,590 --> 00:51:28,210
0,275 275,395 395,485 485,560 560,620
So to do it at
因此，要在数据块级别上做到这一点，我们基本上需要使用简单的压缩方案。我说的天真，我的意思是，它是，它是数据库系统正在调用类似于GZIP的第三方库。您不会想要使用它，因为它很慢，但它是一个第三方库，它将获取页面，然后将其压缩成某种二进制形式，在这种形式下，数据库系统无法解释或自省到块的压缩版本。

1948
00:51:28,210 --> 00:51:29,215
0,105 105,315 315,570 570,810 810,1005
a block level, we, we

1949
00:51:29,215 --> 00:51:30,055
0,195 195,375 375,480 480,645 645,840
essentially need to use a

1950
00:51:30,055 --> 00:51:32,155
0,360 360,735 735,1115 1525,1860 1860,2100
naive compression scheme. And by

1951
00:51:32,155 --> 00:51:34,230
0,435 435,630 630,840 840,1175 1675,2075
naive I mean that the,

1952
00:51:34,730 --> 00:51:36,355
0,395 395,785 785,1055 1055,1310 1310,1625
it's, it's the database system

1953
00:51:36,355 --> 00:51:37,675
0,225 225,435 435,660 660,945 945,1320
is making a call to

1954
00:51:37,675 --> 00:51:38,880
0,255 255,405 405,615 615,870 870,1205
like a third party library

1955
00:51:39,290 --> 00:51:41,125
0,305 305,790 1320,1565 1565,1745 1745,1835
like gzip. You wouldn't want

1956
00:51:41,125 --> 00:51:41,770
0,75 75,165 165,315 315,450 450,645
to use that because it's

1957
00:51:41,770 --> 00:51:42,895
0,165 165,470 550,870 870,960 960,1125
slow, but it's a third

1958
00:51:42,895 --> 00:51:44,110
0,240 240,575 655,1020 1020,1095 1095,1215
party library that's going to

1959
00:51:44,110 --> 00:51:45,730
0,290 520,825 825,1130 1180,1440 1440,1620
take the page and then

1960
00:51:45,730 --> 00:51:46,870
0,345 345,480 480,690 690,945 945,1140
compress it down to some

1961
00:51:46,870 --> 00:51:48,715
0,375 375,710 1060,1380 1380,1575 1575,1845
binary form where the database

1962
00:51:48,715 --> 00:51:50,125
0,375 375,690 690,930 930,1140 1140,1410
system has no way to

1963
00:51:50,125 --> 00:51:51,655
0,365 445,845 1015,1275 1275,1380 1380,1530
interpret or can do any

1964
00:51:51,655 --> 00:51:53,940
0,845 985,1385 1435,1680 1680,1950 1950,2285
introspection into the compressed version

1965
00:51:53,960 --> 00:51:55,400
0,350 350,575 575,725 725,1000
of, of the block.|
|

1966
00:51:55,870 --> 00:51:57,080
0,350 350,605 605,755 755,905 905,1210
Right again. So I call,
又对了。所以我打电话给，你知道的，在一个文件上调用g压缩。数据中心不知道如何读取压缩文件中的内容，对吗？它必须对其进行解压缩，才能恢复其原始版本。

1967
00:51:57,370 --> 00:51:58,800
0,245 245,490 690,1025 1025,1250 1250,1430
you know, call g zip

1968
00:51:58,800 --> 00:52:00,915
0,105 105,210 210,330 330,590 1870,2115
on a, on a, on

1969
00:52:00,915 --> 00:52:02,370
0,120 120,395 835,1095 1095,1275 1275,1455
a file. The data center

1970
00:52:02,370 --> 00:52:03,090
0,225 225,375 375,480 480,555 555,720
doesn't know how to go

1971
00:52:03,090 --> 00:52:04,520
0,285 285,555 555,765 765,1110 1110,1430
read inside that compress file,

1972
00:52:04,930 --> 00:52:06,000
0,275 275,410 410,545 545,680 680,1070
right? It has to decompress

1973
00:52:06,000 --> 00:52:07,320
0,120 120,380 850,1110 1110,1215 1215,1320
it in order to get

1974
00:52:07,320 --> 00:52:08,220
0,150 150,300 300,495 495,735 735,900
back the original version of

1975
00:52:08,220 --> 00:52:08,880
0,260
it.|
|

1976
00:52:08,880 --> 00:52:10,080
0,380
Right.|
正确的。|

1977
00:52:10,150 --> 00:52:11,085
0,350 350,575 575,695 695,860 860,935
So again, you wouldn't want
因此，同样，您不会想要使用GAP。有一堆这样更快的替代方案，L在20世纪90年代推出的这类方案是一个巨大的伟大突破，z标准被认为是最先进的压缩方案。现在来自Facebook的他们实际上正在开发一个新版本。它还没有公开。

1978
00:52:11,085 --> 00:52:11,940
0,75 75,210 210,600 600,810 810,855
to use gap. There's a

1979
00:52:11,940 --> 00:52:13,100
0,90 90,180 180,285 285,560 580,1160
bunch of these faster alternatives

1980
00:52:14,620 --> 00:52:15,645
0,275 275,470 470,635 635,800 800,1025
and that sort of all

1981
00:52:15,645 --> 00:52:17,370
0,165 165,315 315,605 715,1115 1375,1725
came out with l was

1982
00:52:17,370 --> 00:52:18,960
0,225 225,500 610,900 900,1185 1185,1590
was a big great breakthrough

1983
00:52:18,960 --> 00:52:20,480
0,195 195,555 555,810 810,1005 1005,1520
in the in nineteen nineties,

1984
00:52:20,980 --> 00:52:22,650
0,335 335,665 665,1060 1080,1415 1415,1670
z standard is considered the

1985
00:52:22,650 --> 00:52:23,400
0,180 180,270 270,330 330,435 435,750
state of the art compression

1986
00:52:23,400 --> 00:52:25,785
0,225 225,500 1060,1335 1335,1610 2050,2385
scheme. Now from Facebook, they're

1987
00:52:25,785 --> 00:52:26,475
0,120 120,255 255,375 375,480 480,690
actually working on a new

1988
00:52:26,475 --> 00:52:27,740
0,300 300,585 585,705 705,930 930,1265
version. It's not public yet.|
|

1989
00:52:29,630 --> 00:52:31,930
0,400 1380,1700 1700,1820 1820,2075 2075,2300
EM, it's even faster and
嗯，它更快更好，但这还没有出来，但标准是什么，你应该使用吗？

1990
00:52:31,930 --> 00:52:32,935
0,260 430,660 660,780 780,870 870,1005
better, but that's not out

1991
00:52:32,935 --> 00:52:35,980
0,275 1315,1715 2095,2495 2635,2910 2910,3045
yet, but standards what you

1992
00:52:35,980 --> 00:52:37,140
0,105 105,180 180,410
should be using?|
|

1993
00:52:37,610 --> 00:52:38,150
0,60 60,150 150,255 255,375 375,540
So let's see how my
让我们来看看我的SQL是如何做到这一点的。

1994
00:52:38,150 --> 00:52:39,620
0,270 270,405 405,680
sql does this.|
|

1995
00:52:40,110 --> 00:52:41,120
0,245 245,380 380,620 620,740 740,1010
So by sql act, you
所以通过SQL操作，就可以支持表压缩。您在每个表的基础上声明它。我不认为它是默认拥有的。它的工作方式是，当你的所有页面被写入时，一个磁盘，它们将被压缩成某个页面大小，是它的几倍。

1996
00:52:41,120 --> 00:52:43,685
0,330 330,680 1270,1575 1575,2000 2290,2565
can support table compression. You

1997
00:52:43,685 --> 00:52:44,525
0,300 300,420 420,525 525,660 660,840
declare it on a per

1998
00:52:44,525 --> 00:52:45,860
0,225 225,545 895,1140 1140,1290 1290,1335
table basis. I don't think

1999
00:52:45,860 --> 00:52:47,195
0,105 105,180 180,360 360,680 1090,1335
it's owned by default. And

2000
00:52:47,195 --> 00:52:47,795
0,90 90,195 195,315 315,465 465,600
the way it works is

2001
00:52:47,795 --> 00:52:49,835
0,245 895,1230 1230,1500 1500,1755 1755,2040
that all your your pages

2002
00:52:49,835 --> 00:52:50,780
0,210 210,345 345,450 450,600 600,945
when they're written, a disk,

2003
00:52:50,780 --> 00:52:51,580
0,180 180,225 225,270 270,360 360,800
they're going to be compressed

2004
00:52:52,110 --> 00:52:56,660
0,400 1860,2260 2790,3190 3960,4280 4280,4550
into into some page size

2005
00:52:56,660 --> 00:52:58,800
0,315 315,570 570,860 1000,1400
that some multiple of.|
|

2006
00:52:58,800 --> 00:53:01,280
0,320 340,740 1390,1790 1900,2190 2190,2480
Of of four or two,
四个或两个字节，最大可达8千字节。在每个页面中，他们将有一个称为mod日志的标题部分，这有点像我之前提到的Robot事情，在那里我可以进行一系列写入和对页面进行更改，而不必先解压缩它。

2007
00:53:01,690 --> 00:53:04,590
0,335 335,635 635,905 905,1480 2640,2900
up to eight kilobytes. And

2008
00:53:04,590 --> 00:53:05,640
0,135 135,360 360,705 705,990 990,1050
in each page they're going

2009
00:53:05,640 --> 00:53:06,405
0,60 60,135 135,255 255,540 540,765
to have a header portion

2010
00:53:06,405 --> 00:53:08,180
0,210 210,345 345,570 570,935 1375,1775
called the mod log, where

2011
00:53:08,710 --> 00:53:09,795
0,335 335,410 410,485 485,730 810,1085
it's sort of like the

2012
00:53:09,795 --> 00:53:10,950
0,360 360,480 480,660 660,885 885,1155
rowart thing I mentioned before,

2013
00:53:10,950 --> 00:53:11,925
0,380 460,705 705,810 810,900 900,975
where I can do a

2014
00:53:11,925 --> 00:53:13,620
0,105 105,255 255,545 1255,1515 1515,1695
bunch of writes and make

2015
00:53:13,620 --> 00:53:15,210
0,270 270,465 465,585 585,860 1240,1590
changes to the page without

2016
00:53:15,210 --> 00:53:16,400
0,225 225,360 360,735 735,900 900,1190
having to decompress it first.|
|

2017
00:53:17,260 --> 00:53:18,360
0,400
Right.|
正确的。|

2018
00:53:18,630 --> 00:53:18,990
0,45 45,90 90,150 150,225 225,360
So it's like a little
所以这就像是开始的时候有一点额外的空间。

2019
00:53:18,990 --> 00:53:20,000
0,225 225,465 465,600 600,720 720,1010
extra space in the beginning.|
|

2020
00:53:23,290 --> 00:53:23,940
0,245 245,305 305,365 365,500 500,650
And I would say also
我也会说，比如说，如果你的页面在压缩6千字节时，他们会将其填充到1，2，4，8中的下一个最高值，这确保了你在磁盘上的布局中没有任何碎片。

2021
00:53:23,940 --> 00:53:25,350
0,260 370,690 690,930 930,1200 1200,1410
too, say like say if

2022
00:53:25,350 --> 00:53:27,110
0,165 165,390 390,710 970,1365 1365,1760
your page is like when

2023
00:53:27,160 --> 00:53:28,980
0,425 425,650 650,815 815,1450 1470,1820
compressed it six kilobytes, they'll

2024
00:53:28,980 --> 00:53:30,420
0,180 180,315 315,510 510,860 1150,1440
pad it up to the

2025
00:53:30,420 --> 00:53:32,130
0,195 195,435 435,720 720,1070 1420,1710
next highest value within one,

2026
00:53:32,130 --> 00:53:33,480
0,165 165,330 330,620 970,1230 1230,1350
two, four, eight, and this

2027
00:53:33,480 --> 00:53:35,565
0,345 345,585 585,795 795,1070 1840,2085
ensures that you have, you

2028
00:53:35,565 --> 00:53:36,930
0,135 135,210 210,375 375,995 1045,1365
don't have any fragmentation in,

2029
00:53:36,930 --> 00:53:38,030
0,165 165,285 285,540 540,660 660,1100
in your layout on disk.|
|

2030
00:53:39,180 --> 00:53:39,965
0,320 320,485 485,575 575,665 665,785
And, and when you bring
然后，当你把事情带入记忆。假设我运行了一个查询，想要读到第0页中的内容，对吗？如果我正在执行像插入、删除甚至更新这样的盲写操作，假设我有这些值，我就不需要解压缩页面。我只是将更改写入mod日志，而且它也是一个日志结构，就像我们之前谈到的那样。我说我们会在这学期剩下的时间里看到这个想法。您可以认为mod日志就是我们前面谈到的日志结构存储。

2031
00:53:39,965 --> 00:53:41,435
0,120 120,240 240,515 1015,1275 1275,1470
things into memory. So say

2032
00:53:41,435 --> 00:53:43,550
0,335 955,1290 1290,1560 1560,1860 1860,2115
I A query runs and

2033
00:53:43,550 --> 00:53:44,300
0,120 120,240 240,405 405,600 600,750
want to read something in

2034
00:53:44,300 --> 00:53:46,715
0,165 165,470 850,1250 1840,2145 2145,2415
page zero, right? If I'm

2035
00:53:46,715 --> 00:53:48,395
0,135 135,330 330,585 585,935 1435,1680
doing a blind write like

2036
00:53:48,395 --> 00:53:49,960
0,105 105,635 835,1095 1095,1260 1260,1565
an insert or a delete

2037
00:53:50,880 --> 00:53:52,070
0,260 260,515 515,830 830,1040 1040,1190
or even update, assuming I

2038
00:53:52,070 --> 00:53:54,050
0,150 150,300 300,560 1510,1785 1785,1980
have the values, I don't

2039
00:53:54,050 --> 00:53:55,240
0,120 120,330 330,765 765,915 915,1190
need to decompress the page.

2040
00:53:55,470 --> 00:53:56,620
0,260 260,425 425,620 620,830 830,1150
I just write that change

2041
00:53:56,700 --> 00:53:58,235
0,260 260,365 365,515 515,820 1260,1535
to the mod log and

2042
00:53:58,235 --> 00:53:59,105
0,180 180,435 435,570 570,690 690,870
again it's just a log

2043
00:53:59,105 --> 00:53:59,915
0,255 255,420 420,525 525,675 675,810
structure like we talked about

2044
00:53:59,915 --> 00:54:00,980
0,245 295,570 570,780 780,975 975,1065
before. I said we going

2045
00:54:00,980 --> 00:54:02,330
0,90 90,210 210,405 405,740 1060,1350
to see this idea throughout

2046
00:54:02,330 --> 00:54:03,160
0,180 180,345 345,450 450,525 525,830
the rest of the semester.

2047
00:54:03,870 --> 00:54:04,625
0,245 245,350 350,485 485,605 605,755
You can think the mod

2048
00:54:04,625 --> 00:54:05,390
0,180 180,315 315,450 450,585 585,765
log is just the log

2049
00:54:05,390 --> 00:54:06,290
0,255 255,480 480,630 630,765 765,900
structure storage we talked about

2050
00:54:06,290 --> 00:54:07,060
0,260
before.|
|

2051
00:54:08,120 --> 00:54:09,420
0,260 260,380 380,560 560,880 900,1300
And in some cases too,
在某些情况下，我也可以对mod日志进行读取，因为如果我需要的数据只是插入到mod日志中，我就不必解压缩页面的其余部分。

2052
00:54:09,470 --> 00:54:10,465
0,275 275,395 395,530 530,860 860,995
I can do reads on

2053
00:54:10,465 --> 00:54:11,860
0,105 105,255 255,575 1015,1275 1275,1395
the mod log, because if

2054
00:54:11,860 --> 00:54:13,290
0,135 135,360 360,630 630,950 1030,1430
the data I need was

2055
00:54:13,730 --> 00:54:15,175
0,275 275,845 845,1115 1115,1340 1340,1445
just inserted and within the

2056
00:54:15,175 --> 00:54:16,675
0,165 165,485 715,1050 1050,1380 1380,1500
mod log, I don't have

2057
00:54:16,675 --> 00:54:17,545
0,120 120,480 480,630 630,750 750,870
to decompress the rest of

2058
00:54:17,545 --> 00:54:19,160
0,240 240,635
the page.|
|

2059
00:54:20,170 --> 00:54:20,895
0,245 245,335 335,410 410,530 530,725
But then if I do
但如果我确实需要读取页面，他们会将其解压缩，将其作为常规的16千字节页面存储在缓冲池的内存中，因为这是我的SQL的默认大小，然后我可以对其执行任何读取操作。

2060
00:54:20,895 --> 00:54:21,645
0,165 165,270 270,375 375,495 495,750
need to read the page,

2061
00:54:21,645 --> 00:54:23,805
0,405 405,645 645,1080 1080,1385 1885,2160
they'll, they'll decompress it, store

2062
00:54:23,805 --> 00:54:26,250
0,120 120,345 345,600 600,875 2095,2445
it as a regular sixteen

2063
00:54:26,250 --> 00:54:27,525
0,390 390,645 645,930 930,1095 1095,1275
kilobyte page in in memory

2064
00:54:27,525 --> 00:54:28,275
0,150 150,240 240,480 480,615 615,750
in the buffer pool because

2065
00:54:28,275 --> 00:54:29,475
0,135 135,270 270,465 465,755 895,1200
that's the default size for

2066
00:54:29,475 --> 00:54:30,885
0,165 165,575 925,1185 1185,1305 1305,1410
my sql, and then I

2067
00:54:30,885 --> 00:54:31,770
0,90 90,210 210,390 390,705 705,885
can do whatever reads I

2068
00:54:31,770 --> 00:54:33,100
0,195 195,405 405,710
want on that.|
|

2069
00:54:33,100 --> 00:54:34,140
0,320
Right.|
正确的。|

2070
00:54:34,150 --> 00:54:35,175
0,230 230,380 380,650 650,890 890,1025
But I still keep the
但我仍然保留压缩版本，我也认为，当它被解压缩时，他们会将对mod日志的更改应用到那里的页面。

2071
00:54:35,175 --> 00:54:36,945
0,285 285,570 570,935 1405,1665 1665,1770
compressed version around and I

2072
00:54:36,945 --> 00:54:37,935
0,210 210,465 465,675 675,870 870,990
think also too, when it

2073
00:54:37,935 --> 00:54:39,150
0,120 120,600 600,840 840,1050 1050,1215
gets decompressed they apply the

2074
00:54:39,150 --> 00:54:40,130
0,225 225,435 435,525 525,675 675,980
changes to the mod log

2075
00:54:40,390 --> 00:54:41,390
0,305 305,455 455,545 545,695 695,1000
to to the page there.|
|

2076
00:54:42,200 --> 00:54:43,260
0,400
Right.|
正确的。|

2077
00:54:45,980 --> 00:54:46,720
0,245 245,335 335,410 410,560 560,740
This is a good idea
这是一个好主意，还是一个坏主意。

2078
00:54:46,720 --> 00:54:48,340
0,90 90,150 150,315 315,650
or a bad idea.|
|

2079
00:54:50,140 --> 00:54:51,200
0,290 290,455 455,680 680,800 800,1060
Post code doesn't do this.|
邮政编码不会这样做。|

2080
00:54:56,770 --> 00:54:58,800
0,400
Yes.|
是。|

2081
00:55:00,530 --> 00:55:01,345
0,260 260,380 380,515 515,665 665,815
He said, so reading it's
他说，所以读这本书并不是很棒。为什么每次都是？

2082
00:55:01,345 --> 00:55:03,220
0,75 75,225 225,435 435,755 1555,1875
not super great. Why every

2083
00:55:03,220 --> 00:55:04,200
0,225 225,530
single time?|
|

2084
00:55:05,860 --> 00:55:07,885
0,210 210,345 345,650 1390,1905 1905,2025
You'll have to decompress a
你得解压缩一堆东西。

2085
00:55:07,885 --> 00:55:08,900
0,120 120,270 270,545
bunch of stuff.|
|

2086
00:55:09,120 --> 00:55:11,460
0,380 380,710 710,1060
Not necessarily like.|
不一定是喜欢。|

2087
00:55:11,460 --> 00:55:13,440
0,290 520,795 795,945 945,1220
Like going back here.|
就像回到这里。|

2088
00:55:14,480 --> 00:55:15,510
0,260 260,410 410,530 530,605 605,1030
If I do an insert.|
如果我做插入的话。|

2089
00:55:16,280 --> 00:55:16,925
0,195 195,285 285,435 435,570 570,645
And it lands in the
然后它落在黑帮日志里，对吧？我不需要像簿记一样解压我的索引，比如，我现在更新了索引，所以记录ID指向这个页面，然后你可以查看模型日志。哦，对于那个槽号，那个记录ID，它真的在模型中。记录整个页面，这样你就不必解压缩了。

2090
00:55:16,925 --> 00:55:18,845
0,150 150,455 505,905 1525,1770 1770,1920
mob log, right? I don't

2091
00:55:18,845 --> 00:55:20,240
0,45 45,120 120,420 420,695 1015,1395
have to decompress it my

2092
00:55:20,240 --> 00:55:22,085
0,380 910,1185 1185,1380 1380,1485 1485,1845
index like there's some bookkeeping

2093
00:55:22,085 --> 00:55:23,615
0,165 165,360 360,665 1015,1335 1335,1530
doing saying, OK, I updated

2094
00:55:23,615 --> 00:55:24,620
0,180 180,375 375,660 660,900 900,1005
the index now, so the

2095
00:55:24,620 --> 00:55:25,610
0,150 150,420 420,705 705,855 855,990
record ID points to this

2096
00:55:25,610 --> 00:55:27,005
0,290 400,660 660,765 765,1010 1120,1395
page and then you look

2097
00:55:27,005 --> 00:55:27,730
0,105 105,165 165,285 285,450 450,725
in the model log. Oh,

2098
00:55:27,930 --> 00:55:29,105
0,245 245,410 410,650 650,905 905,1175
for that slot number that

2099
00:55:29,105 --> 00:55:30,140
0,255 255,495 495,705 705,930 930,1035
that record ID, it's really

2100
00:55:30,140 --> 00:55:30,890
0,105 105,180 180,300 300,540 540,750
in the model. Log the

2101
00:55:30,890 --> 00:55:32,135
0,135 135,410 880,1110 1110,1155 1155,1245
full page so you don't

2102
00:55:32,135 --> 00:55:33,420
0,30 30,90 90,360 360,635
have to decompress it.|
|

2103
00:55:36,150 --> 00:55:36,810
0,75 75,195 195,420 420,600 600,660
I'll say I actually think
我会说我真的觉得这是个不错的主意。

2104
00:55:36,855 --> 00:55:38,200
0,45 45,105 105,285 285,635
it's a decent idea.|
|

2105
00:55:38,200 --> 00:55:39,340
0,330 330,540 540,690 690,855 855,1140
And, and I say, postres
而且，我要说，帖子不能做到这一点。不是因为，哦，像波斯特格雷这样的波斯特格雷不是福音，对吗？波斯格雷斯没有做某事，并不意味着你不应该做这件事。波斯格雷斯实际上很令人惊叹。前端。后端实际上相当糟糕。

2106
00:55:39,340 --> 00:55:40,470
0,255 255,390 390,540 540,780 780,1130
doesn't do it. Not because

2107
00:55:40,730 --> 00:55:42,640
0,320 320,640 690,1240 1290,1580 1580,1910
like, oh, postgres like postgres

2108
00:55:42,640 --> 00:55:43,770
0,120 120,300 300,480 480,840 840,1130
is not the gospel, right?

2109
00:55:43,850 --> 00:55:45,505
0,550 780,1115 1115,1235 1235,1400 1400,1655
Postgres doesn't do something, doesn't

2110
00:55:45,505 --> 00:55:46,780
0,180 180,515 715,990 990,1185 1185,1275
mean like you shouldn't be

2111
00:55:46,780 --> 00:55:48,685
0,165 165,470 910,1395 1395,1620 1620,1905
doing it. Postgres is actually

2112
00:55:48,685 --> 00:55:50,035
0,345 345,585 585,845 925,1185 1185,1350
amazing. Front end. The back

2113
00:55:50,035 --> 00:55:50,940
0,150 150,300 300,450 450,600 600,905
end is actually pretty terrible.|
|

2114
00:55:51,790 --> 00:55:54,300
0,400 1530,1930 2040,2285 2285,2405 2405,2510
Right, because a lot of
是的，因为很多设计都是20世纪80年代的残余物，这不是你今天建造现代系统的方式。

2115
00:55:54,300 --> 00:55:55,485
0,105 105,315 315,525 525,945 945,1185
the design is remnants from

2116
00:55:55,485 --> 00:55:56,850
0,90 90,240 240,695 955,1200 1200,1365
the nineteen eighties, and it's

2117
00:55:56,850 --> 00:55:57,375
0,120 120,255 255,330 330,420 420,525
not how you would build

2118
00:55:57,375 --> 00:55:59,000
0,90 90,270 270,525 525,845
a modern system today.|
|

2119
00:55:59,040 --> 00:56:00,470
0,400 690,950 950,1070 1070,1295 1295,1430
So, and they don't support
所以，他们不支持压缩，对于像这样的常规数据页面，只支持Toast表，溢出页面。因此，这实际上是一个不错的想法。

2120
00:56:00,470 --> 00:56:03,290
0,315 315,680 700,1100 2320,2625 2625,2820
compression for, for regular data

2121
00:56:03,290 --> 00:56:04,220
0,195 195,375 375,555 555,765 765,930
pages like this, only for

2122
00:56:04,220 --> 00:56:05,650
0,180 180,440 640,870 870,1185 1185,1430
toast tables, the overflow pages.

2123
00:56:06,180 --> 00:56:06,845
0,230 230,320 320,485 485,605 605,665
So this is actually a

2124
00:56:06,845 --> 00:56:07,980
0,180 180,515
decent idea.|
|

2125
00:56:08,970 --> 00:56:10,340
0,400 690,935 935,1055 1055,1205 1205,1370
Right. It does have some
正确的。不过，它确实有一些挑战，对吗？

2126
00:56:10,340 --> 00:56:13,840
0,270 270,525 525,800
challenges, though, right?|
|

2127
00:56:14,760 --> 00:56:15,695
0,305 305,500 500,740 740,815 815,935
Because my sql is a
因为我的SQL是行存储，这就是为什么你必须使用简单的压缩方案，因为你不能做任何奇妙的事情，因为你存储在这两个值本身或页面本身中的值来自所有不同的属性，你不能进行所有的本机压缩。我们一会儿就会看到。

2128
00:56:15,695 --> 00:56:18,230
0,225 225,575 1045,1445 2005,2385 2385,2535
row store, the that's why

2129
00:56:18,230 --> 00:56:19,160
0,135 135,240 240,315 315,530 580,930
you have to use naive

2130
00:56:19,160 --> 00:56:20,315
0,315 315,585 585,750 750,900 900,1155
compression scheme because you can't

2131
00:56:20,315 --> 00:56:22,025
0,165 165,375 375,665 775,1175 1375,1710
do anything fancy because the,

2132
00:56:22,025 --> 00:56:23,675
0,225 225,495 495,765 765,1055 1285,1650
the values you're storing in

2133
00:56:23,675 --> 00:56:25,205
0,255 255,600 600,935 1045,1305 1305,1530
the twoils themselves or so

2134
00:56:25,205 --> 00:56:26,315
0,210 210,315 315,495 495,815 835,1110
in the page itself from

2135
00:56:26,315 --> 00:56:27,305
0,165 165,285 285,495 495,840 840,990
all the different attributes and

2136
00:56:27,305 --> 00:56:27,860
0,150 150,255 255,390 390,480 480,555
you're not going to be

2137
00:56:27,860 --> 00:56:29,435
0,90 90,210 210,470 970,1335 1335,1575
able to do all the

2138
00:56:29,435 --> 00:56:30,650
0,275 385,780 780,975 975,1155 1155,1215
native compression. C we'll see

2139
00:56:30,650 --> 00:56:31,640
0,60 60,150 150,410
in a second.|
|

2140
00:56:31,640 --> 00:56:34,430
0,350 1150,1455 1455,1760 2290,2595 2595,2790
Right. And again, because we're
正确的。再说一次，因为我们只是使用，我认为他们使用Snappy或z标准，因为我们使用的是通用压缩算法。数据系统不知道如何解释这些压缩版本压缩字节的实际含义。

2141
00:56:34,430 --> 00:56:35,810
0,135 135,440 760,1050 1050,1230 1230,1380
just using, I think they

2142
00:56:35,810 --> 00:56:37,660
0,165 165,680 760,1160 1270,1560 1560,1850
use snappy or z standard

2143
00:56:38,010 --> 00:56:39,380
0,290 290,500 500,755 755,1100 1100,1370
because we're using a general

2144
00:56:39,380 --> 00:56:41,225
0,255 255,680 730,1220 1360,1635 1635,1845
purpose compression algorithm. The data

2145
00:56:41,225 --> 00:56:42,185
0,210 210,435 435,570 570,705 705,960
system doesn't know how to

2146
00:56:42,185 --> 00:56:44,290
0,395 805,1095 1095,1380 1380,1800 1800,2105
interpret what those compressed version

2147
00:56:44,490 --> 00:56:46,280
0,395 395,740 740,935 935,1210
compressed bytes actually mean.|
|

2148
00:56:46,710 --> 00:56:47,795
0,245 245,365 365,665 665,830 830,1085
And the spoiler is all
搅局的是我之前谈到的所有压缩算法，它们基本上是做字典压缩的一些变体。

2149
00:56:47,795 --> 00:56:48,755
0,210 210,525 525,735 735,855 855,960
those compression algorithms I've talked

2150
00:56:48,755 --> 00:56:50,195
0,150 150,425 505,840 840,1085 1105,1440
about before, they're basically doing

2151
00:56:50,195 --> 00:56:52,775
0,240 240,690 690,995 1645,1995 1995,2580
some variant of of dictionary

2152
00:56:52,775 --> 00:56:53,960
0,485
compression.|
|

2153
00:56:54,180 --> 00:56:54,875
0,320 320,380 380,470 470,590 590,695
It's going to build its
它将为重复的字节字节序列构建自己的字典，但同样，我的SQL不知道如何读取该字典，所以它必须解压缩整个字典。

2154
00:56:54,875 --> 00:56:56,780
0,120 120,570 570,875 895,1295 1435,1905
own dictionary of repeated byte

2155
00:56:56,780 --> 00:56:58,865
0,330 330,830 1270,1545 1545,1800 1800,2085
byte sequences, but again, my

2156
00:56:58,865 --> 00:56:59,690
0,270 270,465 465,570 570,690 690,825
sql doesn't know how to

2157
00:56:59,690 --> 00:57:01,805
0,195 195,500 670,1340 1810,2040 2040,2115
read that dictionary, so it

2158
00:57:01,805 --> 00:57:02,690
0,120 120,270 270,630 630,750 750,885
has to decompress the whole

2159
00:57:02,690 --> 00:57:04,260
0,290
thing.|
|

2160
00:57:04,950 --> 00:57:05,930
0,275 275,395 395,515 515,875 875,980
So for some workloads, I
因此，对于一些工作负载，我认为这实际上是一个好主意，我希望POST代码确实做了一些压缩。

2161
00:57:05,930 --> 00:57:08,210
0,240 240,525 525,830 1840,2145 2145,2280
think this, this is actually

2162
00:57:08,210 --> 00:57:09,035
0,75 75,210 210,465 465,675 675,825
a good idea and I

2163
00:57:09,035 --> 00:57:09,850
0,150 150,225 225,360 360,540 540,815
kind of wish post code

2164
00:57:09,900 --> 00:57:11,620
0,290 290,470 470,635 635,1000
did do some compression.|
|

2165
00:57:12,920 --> 00:57:14,360
0,350 350,700
Right, so.|
对，所以。|

2166
00:57:15,555 --> 00:57:17,260
0,120 120,180 180,300 300,725
If we're doing olap.|
如果我们在做olap。|

2167
00:57:17,450 --> 00:57:18,580
0,650 650,830 830,980 980,1070 1070,1130
Ideally, we want to be
理想情况下，我们希望能够直接在压缩数据中运行查询，而不必先将其解压缩。

2168
00:57:18,580 --> 00:57:19,890
0,210 210,585 585,855 855,1005 1005,1310
able to run our query

2169
00:57:20,300 --> 00:57:21,330
0,305 305,455 455,530 530,725 725,1030
directly in the compressed data

2170
00:57:21,650 --> 00:57:22,645
0,320 320,500 500,590 590,875 875,995
without having to decompress it

2171
00:57:22,645 --> 00:57:23,580
0,245
first.|
|

2172
00:57:23,580 --> 00:57:24,555
0,150 150,300 300,450 450,660 660,975
Right. So say something like
正确的。所以这样说吧。我有我的DJ两P L的工资。假设我有按压的话。我不是说它是什么，然后我就有了数据库的压缩形式。

2173
00:57:24,555 --> 00:57:26,210
0,330 330,510 510,615 615,1185 1185,1655
this. I have myary DJ

2174
00:57:26,290 --> 00:57:28,125
0,245 245,320 320,440 440,940 1530,1835
two P L salary. Assuming

2175
00:57:28,125 --> 00:57:29,385
0,165 165,330 330,495 495,845 955,1260
I have some compression. I'm

2176
00:57:29,385 --> 00:57:30,080
0,90 90,240 240,360 360,450 450,695
not saying what it is

2177
00:57:30,400 --> 00:57:31,500
0,260 260,365 365,485 485,760 780,1100
and then I have a

2178
00:57:31,500 --> 00:57:33,600
0,345 345,630 630,980 1390,1790 1840,2100
compressed form of of the

2179
00:57:33,600 --> 00:57:34,780
0,260
database.|
|

2180
00:57:34,780 --> 00:57:35,815
0,300 300,480 480,615 615,855 855,1035
Well, if my query shows
好吧，如果我的问题出现了，我想拿到我的工资。我使用了某种魔术将查询转换为常量字符串并转换为压缩形式，现在我可以进行直接查找了。

2181
00:57:35,815 --> 00:57:36,700
0,275 415,675 675,765 765,810 810,885
up, I want to get

2182
00:57:36,700 --> 00:57:38,230
0,180 180,710 1000,1275 1275,1410 1410,1530
my salary. I do some

2183
00:57:38,230 --> 00:57:40,285
0,105 105,210 210,470 940,1340 1660,2055
kind of magic that converts

2184
00:57:40,285 --> 00:57:43,120
0,165 165,485 1615,2015 2305,2610 2610,2835
the query to convert this

2185
00:57:43,120 --> 00:57:45,235
0,320 850,1215 1215,1575 1575,1920 1920,2115
constant string and into the

2186
00:57:45,235 --> 00:57:46,930
0,225 225,545 925,1230 1230,1485 1485,1695
compressed form, and now I

2187
00:57:46,930 --> 00:57:48,060
0,90 90,165 165,315 315,585 585,1130
can do a direct lookup.|
|

2188
00:57:48,600 --> 00:57:50,385
0,270 270,540 540,915 915,1220 1480,1785
On my compressed table using
在我的压缩表上使用我的压缩常量，而不必在我前进的过程中解压缩每一页。

2189
00:57:50,385 --> 00:57:52,050
0,180 180,495 495,815 1255,1515 1515,1665
my compressed constant and not

2190
00:57:52,050 --> 00:57:52,950
0,150 150,255 255,570 570,720 720,900
have to decompress every single

2191
00:57:52,950 --> 00:57:54,050
0,240 240,435 435,615 615,780 780,1100
page as I'm going along.|
|

2192
00:57:56,490 --> 00:57:57,950
0,395 395,740 740,970 1110,1400 1400,1460
Now I'm getting, I'm going
现在我得到了，我要减少我必须做的io的数量，因为我正在获取和压缩页面。我不需要解压缩它们来查找它们。

2193
00:57:57,950 --> 00:57:58,670
0,60 60,195 195,360 360,450 450,720
to reduce amount of io

2194
00:57:58,670 --> 00:57:59,470
0,90 90,180 180,285 285,465 465,800
I have to do because

2195
00:57:59,610 --> 00:58:01,030
0,380 380,695 695,815 815,1115 1115,1420
I'm fetching and compress pages.

2196
00:58:01,350 --> 00:58:02,855
0,290 290,560 560,740 740,1040 1040,1505
I don't have to decompress

2197
00:58:02,855 --> 00:58:03,455
0,135 135,225 225,345 345,480 480,600
them in order to do

2198
00:58:03,455 --> 00:58:05,280
0,300 300,465 465,785
lookups into them.|
|

2199
00:58:08,390 --> 00:58:09,490
0,230 230,320 320,440 440,875 875,1100
So this is ideally what
理想情况下，这就是我们想要的，而实现这一点的最简单方法是在柱状系统中。

2200
00:58:09,490 --> 00:58:11,110
0,120 120,380 640,1040 1090,1335 1335,1620
we want, and the easiest

2201
00:58:11,110 --> 00:58:11,875
0,120 120,240 240,390 390,570 570,765
way to do this is

2202
00:58:11,875 --> 00:58:12,610
0,150 150,255 255,420 420,585 585,735
going to be in a

2203
00:58:12,610 --> 00:58:14,140
0,390 390,680
columnar system.|
|

2204
00:58:16,300 --> 00:58:17,835
0,400 510,785 785,920 920,1180 1290,1535
So this is just sort
所以这只是你可能有的一系列不同压缩算法的简单概述。

2205
00:58:17,835 --> 00:58:18,645
0,60 60,150 150,315 315,720 720,810
of a quick overview of

2206
00:58:18,645 --> 00:58:19,380
0,105 105,225 225,300 300,405 405,735
a bunch of different compression

2207
00:58:19,380 --> 00:58:20,690
0,360 360,585 585,780 780,975 975,1310
algorithms you could possibly have.|
|

2208
00:58:21,780 --> 00:58:23,945
0,400 930,1235 1235,1540 1680,2015 2015,2165
EM again, the spoil is
再说一次，这将是字典压缩。字典编码是大多数系统的默认选择，但您可以做的是，您可能不想使用这些其他方案压缩单个列。我们将看到一些它确实有意义的例子。但是在您进行字典编码之后，您可以将所有这些其他压缩方案应用于字典本身，或者您仍然是您的字典编码值并获得进一步的压缩。

2209
00:58:23,945 --> 00:58:24,920
0,75 75,135 135,285 285,705 705,975
going to be dictionary compression.

2210
00:58:24,920 --> 00:58:26,300
0,330 330,675 675,840 840,1095 1095,1380
Dictionary encoding is the default

2211
00:58:26,300 --> 00:58:28,550
0,255 255,480 480,690 690,1010 1990,2250
choice for most systems, but

2212
00:58:28,550 --> 00:58:29,800
0,135 135,300 300,525 525,855 855,1250
what you can do, you

2213
00:58:30,390 --> 00:58:31,780
0,305 305,500 500,650 650,845 845,1390
may not want to compress

2214
00:58:33,120 --> 00:58:34,970
0,305 305,545 545,880 1230,1595 1595,1850
a single column using these

2215
00:58:34,970 --> 00:58:36,500
0,225 225,675 675,1110 1110,1365 1365,1530
other schemes. We'll see some

2216
00:58:36,500 --> 00:58:37,175
0,210 210,345 345,390 390,510 510,675
examples where it does make

2217
00:58:37,175 --> 00:58:39,395
0,275 475,875 1285,1605 1605,1925 1975,2220
sense. But after you do

2218
00:58:39,395 --> 00:58:41,705
0,345 345,935 1285,1575 1575,1865 1975,2310
dictionary encoding, you can apply

2219
00:58:41,705 --> 00:58:43,145
0,300 300,540 540,720 720,1050 1050,1440
all these other compression schemes

2220
00:58:43,145 --> 00:58:44,600
0,195 195,315 315,735 735,1085 1165,1455
on the dictionary itself, or

2221
00:58:44,600 --> 00:58:45,740
0,225 225,390 390,570 570,855 855,1140
you're still your dictionary encoded

2222
00:58:45,740 --> 00:58:47,165
0,260 640,900 900,1005 1005,1185 1185,1425
values and get even further

2223
00:58:47,165 --> 00:58:48,060
0,425
compression.|
|

2224
00:58:48,070 --> 00:58:48,600
0,230 230,290 290,350 350,440 440,530
So you can get sort
所以你可以得到一种乘法效果，你以一种方式进行压缩，然后对压缩的数据运行另一种压缩算法，得到更好的压缩，而且它仍然是以数据库系统可以本机解释的方式完成的。

2225
00:58:48,600 --> 00:58:49,635
0,60 60,150 150,735 735,900 900,1035
of a multiplicative effect where

2226
00:58:49,635 --> 00:58:50,870
0,90 90,210 210,575 655,945 945,1235
you do compression one way,

2227
00:58:51,160 --> 00:58:52,065
0,260 260,380 380,500 500,680 680,905
and then you run another

2228
00:58:52,065 --> 00:58:53,115
0,345 345,645 645,735 735,840 840,1050
compression algorithm on the compressed

2229
00:58:53,115 --> 00:58:53,925
0,225 225,390 390,495 495,630 630,810
data and get even better

2230
00:58:53,925 --> 00:58:55,590
0,425 715,975 975,1200 1200,1425 1425,1665
compression, and it's still done

2231
00:58:55,590 --> 00:58:56,445
0,135 135,270 270,510 510,735 735,855
in a way where the

2232
00:58:56,445 --> 00:58:58,130
0,180 180,465 465,795 795,1365 1365,1685
database system can natively interpret.|
|

2233
00:58:58,840 --> 00:58:59,920
0,135 135,315 315,675 675,885 885,1080
What those bytes actually mean
这些字节在压缩形式中的实际含义，而不必先将其解压缩。

2234
00:58:59,920 --> 00:59:01,315
0,165 165,255 255,525 525,860 1060,1395
in the compressed form, without

2235
00:59:01,315 --> 00:59:02,370
0,210 210,330 330,630 630,780 780,1055
having to decompress it first.|
|

2236
00:59:03,790 --> 00:59:04,845
0,275 275,500 500,740 740,905 905,1055
And again, this is why
同样，这就是为什么你希望数据做任何事情，做所有事情，而不希望操作系统做任何事情或任何其他人做任何事情。

2237
00:59:04,845 --> 00:59:05,565
0,120 120,225 225,330 330,525 525,720
you want the data to

2238
00:59:05,565 --> 00:59:06,720
0,165 165,405 405,690 690,975 975,1155
do everything, do everything and

2239
00:59:06,720 --> 00:59:07,410
0,195 195,300 300,450 450,600 600,690
don't want the OS to

2240
00:59:07,410 --> 00:59:08,145
0,150 150,345 345,510 510,645 645,735
do anything or anybody else

2241
00:59:08,145 --> 00:59:09,320
0,75 75,195 195,485
to do anything.|
|

2242
00:59:09,570 --> 00:59:11,450
0,400 870,1235 1235,1505 1505,1685 1685,1880
Because, again, because we can
因为，再说一次，因为我们可以进行本机压缩。

2243
00:59:11,450 --> 00:59:13,860
0,320 910,1185 1185,1365 1365,1790
do this native compression.|
|

2244
00:59:16,270 --> 00:59:17,550
0,230 230,590 590,785 785,1055 1055,1280
So let's do some quick
所以让我们在这里做一些快速的例子。所以你要做的一种方法叫做游程编码。

2245
00:59:17,550 --> 00:59:20,235
0,255 255,590 1510,1910 2230,2520 2520,2685
examples here. So one approach

2246
00:59:20,235 --> 00:59:20,940
0,105 105,240 240,405 405,555 555,705
you do is called run

2247
00:59:20,940 --> 00:59:22,800
0,120 120,620 670,1070
length encoding e.|
|

2248
00:59:22,800 --> 00:59:23,805
0,120 120,240 240,495 495,750 750,1005
And this is the basic
这里的基本思想是，如果我们有一系列连续的价值是相同的。

2249
00:59:23,805 --> 00:59:24,705
0,300 300,465 465,600 600,750 750,900
idea here, is that if

2250
00:59:24,705 --> 00:59:28,820
0,180 180,485 1885,2705 3265,3665 3715,4115
we have contiguous runs of

2251
00:59:29,590 --> 00:59:31,275
0,400 900,1160 1160,1295 1295,1445 1445,1685
values that are the same

2252
00:59:31,275 --> 00:59:32,380
0,365
thing.|
|

2253
00:59:33,070 --> 00:59:34,530
0,305 305,470 470,620 620,910 1230,1460
Literally the same value. Instead
从字面上看是相同的价值。我不是每两个人一次又一次地存储那个值，而是存储一个压缩的摘要，对于这个值，在这个偏移量上，这里是它有多少，多少货币。

2254
00:59:34,530 --> 00:59:35,595
0,75 75,240 240,420 420,710 730,1065
of storing that value over

2255
00:59:35,595 --> 00:59:36,630
0,165 165,345 345,645 645,840 840,1035
and over again for every

2256
00:59:36,630 --> 00:59:39,195
0,285 285,770 1210,1650 1650,1970 2200,2565
single twople, I'll instead store

2257
00:59:39,195 --> 00:59:41,360
0,315 315,810 810,1175 1585,1875 1875,2165
a compressed summary that says

2258
00:59:41,950 --> 00:59:43,280
0,260 260,410 410,700 720,1025 1025,1330
for this value, at this

2259
00:59:43,360 --> 00:59:45,165
0,400 1020,1340 1340,1415 1415,1610 1610,1805
offset, here's how many, how

2260
00:59:45,165 --> 00:59:46,980
0,165 165,645 645,825 825,1085
many currenrences it has.|
|

2261
00:59:47,100 --> 00:59:48,340
0,400
Right.|
正确的。|

2262
00:59:48,500 --> 00:59:49,915
0,395 395,680 680,965 965,1265 1265,1415
Now, this works great if
现在，如果您的数据是根据您试图压缩的列进行排序的，那么这种方法非常有效。呃，你不能总是这样。但再说一次，如果你对东西进行排序，那么你就可以最大化数量，最大化重复运行。假设我，我有一个单独的表，其中有一个I‘d字段，然后有一个列，说某人是否死了，是或不是，对吗？是或不是，没有零，没有可能，对吗？这样我们就可以按压这个人了，对吗？

2263
00:59:49,915 --> 00:59:50,920
0,120 120,270 270,435 435,780 780,1005
your data is sorted based

2264
00:59:50,920 --> 00:59:52,435
0,320 760,1020 1020,1155 1155,1320 1320,1515
on whatever the column you're

2265
00:59:52,435 --> 00:59:55,075
0,75 75,180 180,545 1045,1445 2365,2640
trying to compress. Uh, you

2266
00:59:55,075 --> 00:59:56,700
0,240 240,390 390,525 525,785 1225,1625
can't always do this. But

2267
00:59:57,380 --> 00:59:58,255
0,260 260,365 365,500 500,680 680,875
again, if you sort things,

2268
00:59:58,255 --> 00:59:59,155
0,240 240,435 435,570 570,720 720,900
then you can, you can

2269
00:59:59,155 --> 01:00:01,930
0,510 510,660 660,795 795,1085 2245,2775
maximize the amount of maximize

2270
01:00:01,930 --> 01:00:03,850
0,210 210,405 405,710 1510,1830 1830,1920
the repeated runs. Let's say

2271
01:00:03,850 --> 01:00:04,480
0,165 165,300 300,360 360,450 450,630
I I have a single

2272
01:00:04,480 --> 01:00:05,230
0,255 255,435 435,540 540,645 645,750
table where it has an

2273
01:00:05,365 --> 01:00:06,790
0,180 180,485 715,990 990,1200 1200,1425
I'd field and then has

2274
01:00:06,790 --> 01:00:07,975
0,180 180,405 405,630 630,840 840,1185
a column says whether somebody's

2275
01:00:07,975 --> 01:00:08,710
0,120 120,240 240,405 405,600 600,735
dead or not, yes or

2276
01:00:08,710 --> 01:00:10,860
0,260 550,950 1480,1755 1755,1890 1890,2150
no, right? Yes or no,

2277
01:00:10,940 --> 01:00:12,145
0,335 335,485 485,740 740,980 980,1205
there's no null, there's no

2278
01:00:12,145 --> 01:00:14,890
0,395 445,845 2035,2310 2310,2535 2535,2745
maybe, right? So we can

2279
01:00:14,890 --> 01:00:16,260
0,270 270,465 465,630 630,920 970,1370
compress this guy here, right?|
|

2280
01:00:17,250 --> 01:00:19,475
0,335 335,545 545,980 980,1360 1920,2225
So a compressed form would
所以一个压缩的形式，基本上只需要扫描列，找到具有相同值的katigu属性或两个值，然后将其转换为这个三元组，它说，这是值，我们在这个偏移量，这是运行的大小。

2281
01:00:19,475 --> 01:00:21,830
0,305 565,965 1405,1740 1740,1995 1995,2355
just take, essentially just scanning

2282
01:00:21,830 --> 01:00:23,620
0,105 105,225 225,500 1120,1455 1455,1790
through the column and finding

2283
01:00:23,700 --> 01:00:26,780
0,400 1410,2000 2000,2315 2315,2590 2700,3080
the katigu attributes or twoples

2284
01:00:26,780 --> 01:00:27,610
0,135 135,285 285,405 405,540 540,830
that have the same value

2285
01:00:28,050 --> 01:00:29,045
0,275 275,485 485,800 800,890 890,995
and then converting it into

2286
01:00:29,045 --> 01:00:30,545
0,180 180,525 525,660 660,935 1135,1500
this triplet that says, here's

2287
01:00:30,545 --> 01:00:31,600
0,105 105,365 385,690 690,780 780,1055
the value, we're at this

2288
01:00:31,620 --> 01:00:32,855
0,400 420,710 710,935 935,1055 1055,1235
offset, and here's the size

2289
01:00:32,855 --> 01:00:34,020
0,135 135,225 225,485
of the run.|
|

2290
01:00:34,450 --> 01:00:35,740
0,275 275,550
All right.|
好的。|

2291
01:00:36,890 --> 01:00:37,900
0,260 260,380 380,635 635,905 905,1010
And so now if have
现在，如果有一个问题出现，比如计算死亡人数与未死亡人数，对吗？我只需撕开已死的列，并通过对运行长度求和来计算我的聚合。

2292
01:00:37,900 --> 01:00:39,300
0,60 60,210 210,405 405,710 1000,1400
a query comes along, like

2293
01:00:41,000 --> 01:00:41,785
0,290 290,410 410,485 485,575 575,785
count the number of people

2294
01:00:41,785 --> 01:00:42,850
0,210 210,360 360,585 585,825 825,1065
that are dead versus not

2295
01:00:42,850 --> 01:00:45,150
0,320 670,1070 1420,1785 1785,2025 2025,2300
dead, right? I can just

2296
01:00:45,230 --> 01:00:47,320
0,365 365,700 960,1360 1590,1880 1880,2090
rip through that is dead

2297
01:00:47,320 --> 01:00:50,280
0,320 1690,1965 1965,2250 2250,2385 2385,2960
column and compute my aggregation

2298
01:00:50,300 --> 01:00:52,680
0,275 275,550 840,1265 1265,1540 1980,2380
by just summing up the

2299
01:00:53,150 --> 01:00:54,300
0,380 380,650 650,785 785,890 890,1150
the length of the run.|
|

2300
01:00:55,100 --> 01:00:55,880
0,105 105,240 240,390 390,570 570,780
You know, and then along
你知道，然后和那里的价值一起。

2301
01:00:55,880 --> 01:00:58,520
0,290 1150,1410 1410,1620 1620,1970
with the value there.|
|

2302
01:01:01,300 --> 01:01:02,100
0,305 305,455 455,545 545,650 650,800
I actually can do even
事实上，我可以做得更好。

2303
01:01:02,100 --> 01:01:03,460
0,290
better.|
|

2304
01:01:03,550 --> 01:01:04,760
0,400
Right.|
正确的。|

2305
01:01:05,590 --> 01:01:06,300
0,230 230,320 320,440 440,545 545,710
So I have this little,
所以我这里有一个小的，这个小的部分。我有一个人没有死，然后他们就死了又不死。所以我现在有三个三元组，这里的游程大小是1。

2306
01:01:06,300 --> 01:01:07,590
0,195 195,360 360,540 540,830 1030,1290
this little part here. I

2307
01:01:07,590 --> 01:01:09,015
0,255 255,660 660,795 795,1100 1180,1425
have somebody's not dead, and

2308
01:01:09,015 --> 01:01:09,795
0,90 90,255 255,375 375,570 570,780
then they're dead and not

2309
01:01:09,795 --> 01:01:12,740
0,305 745,1145 1435,1755 1755,2075 2545,2945
dead. So I have now

2310
01:01:13,180 --> 01:01:14,460
0,290 290,470 470,785 785,980 980,1280
these three triplets here where

2311
01:01:14,460 --> 01:01:15,650
0,240 240,420 420,660 660,885 885,1190
the run size is one.|
|

2312
01:01:16,660 --> 01:01:17,445
0,245 245,335 335,470 470,635 635,785
So in this case here,
所以在这个例子中，我实际上做得更糟，因为我存储的是一个三元组，而我本来可以只存储一个值。

2313
01:01:17,445 --> 01:01:18,720
0,225 225,435 435,690 690,1025 1045,1275
I'm actually doing worse because

2314
01:01:18,720 --> 01:01:20,300
0,240 240,645 645,945 945,1125 1125,1580
I'm, I'm storing a triplet

2315
01:01:20,770 --> 01:01:21,360
0,245 245,350 350,440 440,500 500,590
when I could have just

2316
01:01:21,360 --> 01:01:22,335
0,195 195,375 375,555 555,765 765,975
stored a single value by

2317
01:01:22,335 --> 01:01:23,360
0,305
itself.|
|

2318
01:01:23,930 --> 01:01:25,200
0,400
Right.|
正确的。|

2319
01:01:25,700 --> 01:01:26,530
0,230 230,305 305,470 470,680 680,830
So if I sort the
因此，如果我根据某人是否死亡来对数据进行排序。

2320
01:01:26,530 --> 01:01:28,060
0,260 700,990 990,1155 1155,1350 1350,1530
data based on whether somebody

2321
01:01:28,060 --> 01:01:29,440
0,120 120,240 240,345 345,590
is dead or not.|
|

2322
01:01:29,870 --> 01:01:32,010
0,335 335,670 1020,1510 1530,1835 1835,2140
Now my compression only has,
现在我的压缩只有，你知道，压缩列只有两个条目。

2323
01:01:32,060 --> 01:01:33,070
0,245 245,380 380,665 665,860 860,1010
you know, compressed column only

2324
01:01:33,070 --> 01:01:34,440
0,135 135,255 255,680
has two entries.|
|

2325
01:01:34,835 --> 01:01:35,450
0,45 45,150 150,270 270,420 420,615
Here's all the dead people
这里是所有的死人，这里是所有未死的人。

2326
01:01:35,450 --> 01:01:36,035
0,135 135,240 240,360 360,465 465,585
and here all the non

2327
01:01:36,035 --> 01:01:37,260
0,165 165,455
dead people.|
|

2328
01:01:37,690 --> 01:01:39,050
0,245 245,395 395,605 605,995 995,1360
And this greatly reduces the
这极大地减少了商店现在的数据量。

2329
01:01:40,660 --> 01:01:41,400
0,260 260,365 365,485 485,620 620,740
amount of data at the

2330
01:01:41,400 --> 01:01:42,400
0,135 135,410
store now.|
|

2331
01:01:42,570 --> 01:01:43,370
0,320 320,485 485,590 590,695 695,800
So it may be the
因此，情况可能再次如此，说我一直认为它是极端的。我的例子是，我必须把它们放在我的幻灯片上。我这里有十、八、八或九桶，如果我有十亿桶或十亿人。

2332
01:01:43,370 --> 01:01:44,530
0,240 240,570 570,765 765,885 885,1160
case again say I have

2333
01:01:44,640 --> 01:01:45,620
0,260 260,365 365,455 455,545 545,980
always think of it extremes.

2334
01:01:45,620 --> 01:01:46,775
0,165 165,390 390,710 880,1095 1095,1155
My example is I have

2335
01:01:46,775 --> 01:01:47,225
0,90 90,165 165,240 240,330 330,450
to fit them on the

2336
01:01:47,225 --> 01:01:48,920
0,275 715,1005 1005,1275 1275,1515 1515,1695
slides I having. I have

2337
01:01:48,920 --> 01:01:49,835
0,285 285,540 540,675 675,780 780,915
ten, eight, eight or nine

2338
01:01:49,835 --> 01:01:51,005
0,270 270,545 775,1020 1020,1095 1095,1170
tubils here if I have

2339
01:01:51,005 --> 01:01:51,935
0,150 150,420 420,765 765,840 840,930
a billion tubils or a

2340
01:01:51,935 --> 01:01:53,200
0,225 225,575
billion people.|
|

2341
01:01:53,680 --> 01:01:55,400
0,290 290,440 440,770 770,1090 1320,1720
I can compress now down,
我现在可以压缩，你知道10亿人中谁死了，谁没有死。

2342
01:01:55,450 --> 01:01:56,430
0,230 230,440 440,695 695,845 845,980
you know, keeping track of

2343
01:01:56,430 --> 01:01:57,870
0,260 490,735 735,885 885,1260 1260,1440
like, you know who's a

2344
01:01:57,870 --> 01:01:58,515
0,150 150,285 285,405 405,540 540,645
billion people was dead or

2345
01:01:58,515 --> 01:02:00,720
0,135 135,425 655,1055
not dead into.|
|

2346
01:02:00,720 --> 01:02:01,670
0,150 150,315 315,450 450,555 555,950
A small number of bytes.|
一小部分字节。|

2347
01:02:02,360 --> 01:02:02,960
0,165 165,270 270,390 390,495 495,600
And that will fit on
这将适合在一页上。

2348
01:02:02,960 --> 01:02:04,260
0,165 165,470
one page.|
|

2349
01:02:07,310 --> 01:02:09,010
0,260 260,410 410,590 590,880 1440,1700
You need the length in
你需要三元组中的长度，因为，再一次，假设我们总是有固定长度的小球，这可以让你计算出，好的，如果我需要找到一个两池的单一条目，如果他们喜欢或不喜欢，允许你做数学反转，并说，好的，如果我被解压缩，我会在这个偏移量上。

2350
01:02:09,010 --> 01:02:10,470
0,135 135,510 510,840 840,1140 1140,1460
the triplet because, because, again,

2351
01:02:10,550 --> 01:02:11,785
0,320 320,640 660,950 950,1100 1100,1235
assuming that we always have

2352
01:02:11,785 --> 01:02:13,435
0,150 150,315 315,815 1105,1425 1425,1650
fixed length allets, this allows

2353
01:02:13,435 --> 01:02:14,410
0,150 150,255 255,420 420,690 690,975
you to figure out, okay,

2354
01:02:14,410 --> 01:02:15,340
0,320 370,615 615,720 720,825 825,930
like if I need to

2355
01:02:15,340 --> 01:02:16,180
0,180 180,330 330,420 420,615 615,840
find for a single two

2356
01:02:16,180 --> 01:02:17,700
0,290 520,795 795,1035 1035,1260 1260,1520
pool, a single entry, if

2357
01:02:17,780 --> 01:02:19,140
0,260 260,365 365,470 470,730 960,1360
they did or not like

2358
01:02:19,160 --> 01:02:19,900
0,260 260,425 425,560 560,635 635,740
it allows you to do

2359
01:02:19,900 --> 01:02:21,610
0,120 120,380 520,920 1270,1560 1560,1710
the math to reverse it

2360
01:02:21,610 --> 01:02:22,315
0,150 150,285 285,420 420,570 570,705
back and say, okay, I

2361
01:02:22,315 --> 01:02:23,215
0,150 150,255 255,390 390,660 660,900
would be at this offset

2362
01:02:23,215 --> 01:02:24,780
0,135 135,270 270,420 420,965
if I was uncompressed.|
|

2363
01:02:25,380 --> 01:02:26,570
0,210 210,300 300,420 420,570 570,1190
And that's just simple arithmetic.|
这只是一个简单的算术。|

2364
01:02:30,350 --> 01:02:31,210
0,260 260,395 395,590 590,770 770,860
Now the expression scheme you
现在，您可以执行的表达式方案称为比特打包。

2365
01:02:31,210 --> 01:02:31,750
0,75 75,150 150,240 240,375 375,540
can do is called bit

2366
01:02:31,750 --> 01:02:32,940
0,470
packing.|
|

2367
01:02:32,940 --> 01:02:33,735
0,105 105,255 255,480 480,660 660,795
And the idea here is
这里的想法是。

2368
01:02:33,735 --> 01:02:34,880
0,275
that.|
|

2369
01:02:35,470 --> 01:02:38,030
0,350 350,695 695,1090 1230,1870 2070,2560
People often times declare attributes
人们经常会声明某种类型的属性或列，而这些属性或列比实际需要的要大。

2370
01:02:38,110 --> 01:02:39,825
0,400 420,860 860,1120 1230,1505 1505,1715
or columns in a certain

2371
01:02:39,825 --> 01:02:42,285
0,335 1045,1440 1440,1800 1800,2165 2185,2460
type that is larger than

2372
01:02:42,285 --> 01:02:43,820
0,240 240,495 495,785
they actually need.|
|

2373
01:02:44,390 --> 01:02:46,690
0,400 1680,1925 1925,2015 2015,2150 2150,2300
So idea would be like
假设我有一个列，跟踪某个数字，我将它声明为一个整数类型，在SQL中，这是一个32位的整数。

2374
01:02:46,690 --> 01:02:47,305
0,105 105,210 210,315 315,420 420,615
if I have a column

2375
01:02:47,305 --> 01:02:48,145
0,165 165,315 315,435 435,600 600,840
where I'm keeping track of

2376
01:02:48,145 --> 01:02:49,600
0,255 255,545 835,1110 1110,1230 1230,1455
some number, and I declare

2377
01:02:49,600 --> 01:02:51,420
0,90 90,320 970,1215 1215,1560 1560,1820
it as an integer type

2378
01:02:51,950 --> 01:02:53,845
0,550 570,875 875,1160 1160,1510 1590,1895
that's in sql, that's it's

2379
01:02:53,845 --> 01:02:55,460
0,90 90,420 420,525 525,965
a 32 bit integer.|
|

2380
01:02:55,610 --> 01:02:56,740
0,245 245,365 365,560 560,860 860,1130
So that means that even
这意味着，即使有一个很小的值，我仍然会分配32位来存储。所以对于这里的这些数字，它们都不是很大，但我总是会从某些位开始。所以在这种情况下。

2381
01:02:56,740 --> 01:02:58,510
0,285 285,525 525,770 1390,1635 1635,1770
if, no matter if there's

2382
01:02:58,510 --> 01:02:59,440
0,105 105,270 270,510 510,810 810,930
a small value, I'm still

2383
01:02:59,440 --> 01:03:00,610
0,90 90,150 150,540 540,960 960,1170
going to allocate 32 bits

2384
01:03:00,610 --> 01:03:02,200
0,240 240,530 1120,1365 1365,1455 1455,1590
to store. So for these

2385
01:03:02,200 --> 01:03:03,340
0,225 225,560 730,990 990,1080 1080,1140
numbers here, none of them

2386
01:03:03,340 --> 01:03:05,425
0,90 90,270 270,590 1660,1905 1905,2085
are very big, but I'm

2387
01:03:05,425 --> 01:03:06,085
0,135 135,225 225,330 330,495 495,660
always going to start as

2388
01:03:06,085 --> 01:03:07,075
0,225 225,540 540,765 765,870 870,990
certain bits. So in this

2389
01:03:07,075 --> 01:03:08,200
0,180 180,485
case here.|
|

2390
01:03:08,360 --> 01:03:09,700
0,275 275,455 455,680 680,1000 1080,1340
To store these these eight
为了存储这些8个或9个数字，8个数字，我存储了2，6位。但再说一次，唯一重要的是这里的下部，因为这是，这是实际情况。

2391
01:03:09,700 --> 01:03:11,455
0,105 105,225 225,500 1300,1590 1590,1755
or nine numbers, eight numbers,

2392
01:03:11,455 --> 01:03:12,750
0,195 195,465 465,750 750,990 990,1295
I store two, six bits.

2393
01:03:13,400 --> 01:03:14,860
0,275 275,550 960,1205 1205,1325 1325,1460
But again, the only thing

2394
01:03:14,860 --> 01:03:15,970
0,135 135,405 405,735 735,945 945,1110
that matters is actually these

2395
01:03:15,970 --> 01:03:16,720
0,210 210,420 420,540 540,615 615,750
lower portion of the bits

2396
01:03:16,720 --> 01:03:18,715
0,290 1150,1440 1440,1620 1620,1815 1815,1995
here, because this is, this

2397
01:03:18,715 --> 01:03:19,940
0,165 165,375 375,695
is the actual.|
|

2398
01:03:19,980 --> 01:03:20,885
0,260 260,380 380,560 560,740 740,905
This is the actual data
这就是我需要的实际数据，对吗？所有这些其他的东西，你知道，其他的，其他的24位都是浪费的空间。

2399
01:03:20,885 --> 01:03:22,835
0,150 150,270 270,545 925,1325 1645,1950
that I need, right? All

2400
01:03:22,835 --> 01:03:24,490
0,165 165,360 360,695 1195,1425 1425,1655
this other stuff, you know,

2401
01:03:24,720 --> 01:03:27,620
0,230 230,460 2130,2375 2375,2525 2525,2900
the other, the other 24

2402
01:03:27,620 --> 01:03:28,870
0,255 255,510 510,660 660,975 975,1250
bits is just wasted space.|
|

2403
01:03:30,320 --> 01:03:32,015
0,320 940,1260 1260,1470 1470,1605 1605,1695
Right. So instead what I
正确的。所以相反，我能做的是。

2404
01:03:32,015 --> 01:03:34,020
0,120 120,395 625,1025
can do is.|
|

2405
01:03:34,330 --> 01:03:35,340
0,320 320,530 530,725 725,905 905,1010
Even though you declared it
即使您将其声明为32位整数，我也会将其排序为8位整数。

2406
01:03:35,340 --> 01:03:36,530
0,90 90,225 225,570 570,675 675,1190
as a 32 bit integer,

2407
01:03:37,030 --> 01:03:37,680
0,320 320,380 380,470 470,575 575,650
I'm going to sort it

2408
01:03:37,680 --> 01:03:38,870
0,90 90,255 255,480 480,675 675,1190
as an eight bit integer.|
|

2409
01:03:40,170 --> 01:03:41,210
0,245 245,380 380,590 590,815 815,1040
And then now that greatly
现在，这极大地缩小了尺寸的四倍。

2410
01:03:41,210 --> 01:03:43,895
0,375 375,585 585,860 880,1280 2440,2685
reduces the size down by

2411
01:03:43,895 --> 01:03:45,720
0,120 120,300 300,465 465,725
a factor of four.|
|

2412
01:03:46,180 --> 01:03:46,785
0,230 230,290 290,365 365,485 485,605
So I was able to
所以我能够从206位再讲到64位，你可以用位移位运算符和Cy来做一系列的技巧，我们可以在本学期晚些时候讨论。

2413
01:03:46,785 --> 01:03:48,000
0,165 165,390 390,585 585,1005 1005,1215
go again from 206 bits

2414
01:03:48,000 --> 01:03:50,685
0,320 610,1080 1080,1340 2380,2610 2610,2685
to 64 bits, and you

2415
01:03:50,685 --> 01:03:51,150
0,90 90,165 165,225 225,315 315,465
can do a bunch of

2416
01:03:51,150 --> 01:03:52,920
0,285 285,435 435,615 615,1070 1180,1770
tricks with bit shifting operators

2417
01:03:52,920 --> 01:03:54,420
0,285 285,740 1030,1320 1320,1440 1440,1500
and cy, which we can

2418
01:03:54,420 --> 01:03:55,725
0,75 75,180 180,330 330,680 1000,1305
talk about later semester to

2419
01:03:55,725 --> 01:03:56,940
0,165 165,425
actually now.|
|

2420
01:03:57,190 --> 01:03:58,155
0,245 245,365 365,560 560,740 740,965
You know, as, as I'm
你知道，就像我扫描并说的那样，试图找到某个数字的匹配，因为这些现在是8位整数，我可以把它们放到一个单独的第三位整数中，我会在我的系统中跟踪。哦，它真的是在这个偏移量，这些不同的值。现在，使用一条CPU指令，我可以一次操作四个值。

2421
01:03:58,155 --> 01:03:59,145
0,270 270,465 465,675 675,855 855,990
scanning along and saying, trying

2422
01:03:59,145 --> 01:04:00,360
0,90 90,335 355,585 585,815 865,1215
to find, you know, matches

2423
01:04:00,360 --> 01:04:01,920
0,180 180,255 255,375 375,650 1270,1560
on a certain number, because

2424
01:04:01,920 --> 01:04:02,610
0,150 150,255 255,390 390,555 555,690
these are now eight bit

2425
01:04:02,610 --> 01:04:03,675
0,420 420,645 645,795 795,930 930,1065
integers, I could put them

2426
01:04:03,675 --> 01:04:06,105
0,275 325,690 690,1055 1945,2265 2265,2430
into a single third bit

2427
01:04:06,105 --> 01:04:07,710
0,485 805,1050 1050,1200 1200,1380 1380,1605
integer and I'm keeping track

2428
01:04:07,710 --> 01:04:08,780
0,195 195,360 360,495 495,720 720,1070
of inside my system. Oh,

2429
01:04:08,800 --> 01:04:10,040
0,350 350,500 500,650 650,875 875,1240
it's really at this offset,

2430
01:04:10,270 --> 01:04:12,090
0,290 290,580 600,1000 1380,1640 1640,1820
these different values. And then

2431
01:04:12,090 --> 01:04:13,140
0,195 195,375 375,540 540,735 735,1050
now with a single cpu

2432
01:04:13,140 --> 01:04:14,990
0,410 730,1020 1020,1290 1290,1560 1560,1850
instruction, I can operate on

2433
01:04:15,760 --> 01:04:18,000
0,305 305,605 605,890 890,1180
four values at once.|
|

2434
01:04:21,010 --> 01:04:21,750
0,305 305,365 365,470 470,575 575,740
What's the problem with this?
这有什么问题？是。如果添加32位英寸会发生什么情况？

2435
01:04:21,750 --> 01:04:23,625
0,320 880,1155 1155,1380 1380,1620 1620,1875
Yes. What happens if you

2436
01:04:23,625 --> 01:04:25,010
0,285 285,555 555,1020 1020,1125 1125,1385
add a 32 bit inch?|
|

2437
01:04:26,210 --> 01:04:27,600
0,400 420,755 755,965 965,1115 1115,1390
Boom. Okay, excellent. Thank you.
砰的一声。好的，太棒了。谢谢。所以他的陈述是，如果我有一个数字，不能存储在我试图将它们打包成的8位中，会发生什么，对吗？

2438
01:04:28,190 --> 01:04:29,665
0,245 245,395 395,590 590,880 1200,1475
So his statement is, well,

2439
01:04:29,665 --> 01:04:30,430
0,135 135,330 330,510 510,630 630,765
what happens if I have

2440
01:04:30,430 --> 01:04:32,350
0,120 120,360 360,740 1480,1830 1830,1920
a number that can't be

2441
01:04:32,350 --> 01:04:33,085
0,150 150,255 255,375 375,540 540,735
stored in those eight bits

2442
01:04:33,085 --> 01:04:33,655
0,135 135,270 270,360 360,450 450,570
that I'm trying to pack

2443
01:04:33,655 --> 01:04:35,260
0,120 120,365 565,965
them into, right?|
|

2444
01:04:35,270 --> 01:04:35,980
0,275 275,380 380,455 455,575 575,710
And so the way you
因此，解决这个问题的方法是亚马逊的红移技术。它被称为主要是编码，在那里你可以说。

2445
01:04:35,980 --> 01:04:36,820
0,120 120,285 285,525 525,720 720,840
get around this is a

2446
01:04:36,820 --> 01:04:38,155
0,225 225,585 585,870 870,1005 1005,1335
technique from Amazon for redshift.

2447
01:04:38,155 --> 01:04:40,015
0,165 165,285 285,510 510,1145 1525,1860
It's called mostly encoding, where

2448
01:04:40,015 --> 01:04:41,480
0,225 225,515
you say.|
|

2449
01:04:41,490 --> 01:04:42,470
0,335 335,560 560,695 695,785 785,980
The the idea is basically
这个想法基本上是说，我的专栏中的大多数数据都足够小，但在不够小的情况下，他们会跟踪这些数据，然后将其作为单独的数据存储在词典中，对吧。再一次，我有32，30个量子比特数，但是我有，我有这个，9，90和9。这真的很大。所以我仍然会存储它们是8位，但是我会有一个特殊的标记值。假设所有位都设置为1，然后我有一个单独的表，表示给定的偏移量。以下是原始值应该是什么。所以现在，当我沿着这一列扫描时，如果我看到我的特殊标记值，我知道我应该查看这个偏移表，找出实际值应该是什么。

2450
01:04:42,470 --> 01:04:43,685
0,300 300,645 645,885 885,990 990,1215
say most of the data

2451
01:04:43,685 --> 01:04:44,540
0,270 270,495 495,690 690,795 795,855
my column is going to

2452
01:04:44,540 --> 01:04:46,160
0,150 150,390 390,710 1150,1455 1455,1620
be small enough but in

2453
01:04:46,160 --> 01:04:47,320
0,165 165,450 450,675 675,885 885,1160
the cases where it's not

2454
01:04:47,730 --> 01:04:48,830
0,350 350,605 605,755 755,950 950,1100
they they'll keep track of

2455
01:04:48,830 --> 01:04:49,685
0,180 180,360 360,525 525,705 705,855
that and then store that

2456
01:04:49,685 --> 01:04:50,990
0,135 135,270 270,545 985,1230 1230,1305
as a separate in a

2457
01:04:50,990 --> 01:04:52,400
0,470 640,930 930,1065 1065,1230 1230,1410
dictionary, right. So again I

2458
01:04:52,400 --> 01:04:53,195
0,105 105,225 225,390 390,585 585,795
have these thirty two thirty

2459
01:04:53,195 --> 01:04:54,380
0,225 225,485 775,1005 1005,1065 1065,1185
qubit numbers but I have

2460
01:04:54,380 --> 01:04:55,280
0,150 150,285 285,435 435,660 660,900
I have this one nine,

2461
01:04:55,280 --> 01:04:56,180
0,135 135,255 255,465 465,690 690,900
ninety and nine here. That's

2462
01:04:56,180 --> 01:04:58,400
0,135 135,440 940,1340 1540,1950 1950,2220
really big. So I'll store

2463
01:04:58,400 --> 01:04:59,540
0,315 315,525 525,645 645,885 885,1140
still store them is is

2464
01:04:59,540 --> 01:05:01,610
0,195 195,530 1030,1320 1320,1610 1750,2070
eight bits but then I'll

2465
01:05:01,610 --> 01:05:03,190
0,90 90,255 255,560 850,1305 1305,1580
have a special marker value.

2466
01:05:03,810 --> 01:05:04,745
0,290 290,440 440,620 620,800 800,935
Think like all the bits

2467
01:05:04,745 --> 01:05:06,455
0,150 150,300 300,450 450,725 1435,1710
are set to one and

2468
01:05:06,455 --> 01:05:08,075
0,275 925,1200 1200,1320 1320,1425 1425,1620
then I have a separate

2469
01:05:08,075 --> 01:05:09,230
0,255 255,435 435,695 865,1095 1095,1155
table that says for a

2470
01:05:09,230 --> 01:05:11,225
0,230 400,800 1210,1650 1650,1920 1920,1995
given offset. Here's here's what

2471
01:05:11,225 --> 01:05:12,220
0,90 90,255 255,510 510,720 720,995
the original value should be.

2472
01:05:12,450 --> 01:05:13,745
0,245 245,380 380,670 810,1055 1055,1295
So now as as I'm

2473
01:05:13,745 --> 01:05:15,755
0,300 300,575 625,1025 1105,1505 1765,2010
scanning along this column, if

2474
01:05:15,755 --> 01:05:17,015
0,180 180,420 420,630 630,885 885,1260
I see my special marker

2475
01:05:17,015 --> 01:05:18,380
0,245 535,855 855,1095 1095,1260 1260,1365
value I know that I

2476
01:05:18,380 --> 01:05:19,780
0,260 280,570 570,720 720,980 1000,1400
should look in this offset

2477
01:05:19,920 --> 01:05:21,245
0,400 630,905 905,1055 1055,1205 1205,1325
table and find out what

2478
01:05:21,245 --> 01:05:21,905
0,90 90,210 210,405 405,570 570,660
the real value should have

2479
01:05:21,905 --> 01:05:22,500
0,245
been.|
|

2480
01:05:23,870 --> 01:05:25,345
0,400 570,905 905,1115 1115,1265 1265,1475
Yes, you also do something
是的，你也可以用做一些类似的事情。

2481
01:05:25,345 --> 01:05:26,240
0,285 285,635
similar with.|
|

2482
01:05:26,820 --> 01:05:28,160
0,290 290,515 515,740 740,1115 1115,1340
Like the the triplets where
就像三胞胎一样，你只是。

2483
01:05:28,160 --> 01:05:29,220
0,150 150,410
you just.|
|

2484
01:05:29,340 --> 01:05:30,390
0,225 225,450 450,585 585,765 765,1050
Like say the next couple
比方说接下来的几个数是4比特，那么。

2485
01:05:30,390 --> 01:05:31,680
0,270 270,495 495,705 705,1010 1030,1290
things are four bits, so

2486
01:05:31,680 --> 01:05:32,380
0,260
then.|
|

2487
01:05:32,380 --> 01:05:33,325
0,150 150,315 315,465 465,690 690,945
Next couple or eight or
下一对或者八对或者下一对或者第三对。

2488
01:05:33,325 --> 01:05:34,520
0,210 210,390 390,630 630,995
next couple or third.|
|

2489
01:05:34,790 --> 01:05:35,590
0,275 275,380 380,470 470,605 605,800
Yeah, so the statement is
是的，所以声明是，你不能做一些事情，比如三元组，而不是只说所有的东西都是八位的，你能说，你知道，我有一千个连续的值，你存储为四位，然后我可以把它们存储在十二位或其他什么地方。回到包的事情，因为它们将其分解为行组，每个行组可以有自己的压缩方案。

2490
01:05:35,590 --> 01:05:36,490
0,210 210,285 285,390 390,600 600,900
couldn't you do something with

2491
01:05:36,490 --> 01:05:38,785
0,255 255,450 450,840 840,1160 2050,2295
like the triplets where instead

2492
01:05:38,785 --> 01:05:39,625
0,90 90,195 195,420 420,735 735,840
of just saying everything's always

2493
01:05:39,625 --> 01:05:40,650
0,150 150,420 420,630 630,750 750,1025
eight bits, could you say,

2494
01:05:40,970 --> 01:05:43,465
0,230 230,460 1800,2075 2075,2285 2285,2495
you know, I have a

2495
01:05:43,465 --> 01:05:44,755
0,225 225,575 595,840 840,930 930,1290
thousand values that are contiguous

2496
01:05:44,755 --> 01:05:45,730
0,255 255,510 510,645 645,795 795,975
that you store as four

2497
01:05:45,730 --> 01:05:46,900
0,290 550,795 795,900 900,1020 1020,1170
bits then I can store

2498
01:05:46,900 --> 01:05:49,000
0,120 120,350 520,920 1660,1950 1950,2100
them in is twelve bits

2499
01:05:49,000 --> 01:05:50,470
0,135 135,410 700,945 945,1185 1185,1470
or whatever. So that going

2500
01:05:50,470 --> 01:05:51,480
0,165 165,270 270,390 390,735 735,1010
back to the packs thing,

2501
01:05:51,860 --> 01:05:52,675
0,275 275,440 440,605 605,725 725,815
because they break it up

2502
01:05:52,675 --> 01:05:54,280
0,165 165,420 420,755 985,1335 1335,1605
into row groups, each row

2503
01:05:54,280 --> 01:05:55,075
0,210 210,375 375,525 525,660 660,795
group could have its own

2504
01:05:55,075 --> 01:05:56,200
0,315 315,665
compression scheme.|
|

2505
01:05:56,600 --> 01:05:57,415
0,230 230,350 350,515 515,650 650,815
So you could do something
所以你可以做这样的事情。

2506
01:05:57,415 --> 01:05:58,420
0,165 165,425
like that.|
|

2507
01:06:00,000 --> 01:06:01,150
0,245 245,380 380,740 740,875 875,1150
I think parquet is more
我觉得实木地板更像是实木地板。比兽人的更猛烈，更复杂。也许围绕其中之一的另一种方式非常简单。其中一个确实有一堆你所说的各种把戏。

2508
01:06:01,260 --> 01:06:02,645
0,395 395,515 515,710 710,965 965,1385
parquet. Is more aggressive compression

2509
01:06:02,645 --> 01:06:05,465
0,270 270,1260 1260,1365 1365,1625 2515,2820
than orc's, more complicated. Maybe

2510
01:06:05,465 --> 01:06:06,125
0,135 135,240 240,375 375,525 525,660
the other way around one

2511
01:06:06,125 --> 01:06:07,325
0,75 75,305 775,1035 1035,1125 1125,1200
of them one of is

2512
01:06:07,325 --> 01:06:08,030
0,150 150,375 375,525 525,585 585,705
very simple. One of them

2513
01:06:08,030 --> 01:06:08,890
0,225 225,405 405,495 495,600 600,860
does has a bunch of

2514
01:06:08,970 --> 01:06:09,845
0,245 245,410 410,620 620,755 755,875
the various tricks you're talking

2515
01:06:09,845 --> 01:06:10,600
0,305
about.|
|

2516
01:06:12,340 --> 01:06:13,200
0,290 290,410 410,470 470,620 620,860
Right. So in this example
正确的。所以在这个例子中，原始大小是206位，但如果我进行主要的编码，我必须为主要的8列存储8乘8位，然后假设我只需要16位用于所有集合，32或2位用于这个查找表的值，这不是真的，因为显然分配更多的用于附加元数据，但假设你得到它，它是112位。

2517
01:06:13,200 --> 01:06:14,175
0,285 285,480 480,630 630,840 840,975
here, the original size is

2518
01:06:14,175 --> 01:06:15,780
0,450 450,755 1135,1380 1380,1500 1500,1605
206 bits, but then if

2519
01:06:15,780 --> 01:06:16,910
0,75 75,255 255,435 435,570 570,1130
I do the mostly encoding

2520
01:06:18,250 --> 01:06:18,975
0,245 245,350 350,455 455,575 575,725
I used have to store

2521
01:06:18,975 --> 01:06:21,230
0,150 150,300 300,480 480,785 1855,2255
eight by eight bits for

2522
01:06:21,490 --> 01:06:23,055
0,245 245,410 410,635 635,940 1290,1565
the mostly eight column, and

2523
01:06:23,055 --> 01:06:24,330
0,275 355,690 690,945 945,1140 1140,1275
then assuming that I only

2524
01:06:24,330 --> 01:06:25,125
0,135 135,360 360,600 600,720 720,795
need sixteen bits for the

2525
01:06:25,125 --> 01:06:26,340
0,150 150,455 655,960 960,1125 1125,1215
all set and the thirty

2526
01:06:26,340 --> 01:06:26,775
0,60 60,135 135,255 255,360 360,435
or two bits for the

2527
01:06:26,775 --> 01:06:28,640
0,245 1015,1260 1260,1380 1380,1605 1605,1865
value for this lookup table,

2528
01:06:28,750 --> 01:06:29,750
0,245 245,350 350,500 500,695 695,1000
which is not true because

2529
01:06:30,070 --> 01:06:32,835
0,275 275,590 590,850 2190,2525 2525,2765
obviously allocate more for additional

2530
01:06:32,835 --> 01:06:34,215
0,540 540,780 780,1035 1035,1275 1275,1380
metadata, but assuming you get

2531
01:06:34,215 --> 01:06:35,025
0,90 90,225 225,345 345,540 540,810
it down to that, it's

2532
01:06:35,025 --> 01:06:36,340
0,360 360,635
112 bits.|
|

2533
01:06:37,585 --> 01:06:38,840
0,60 60,150 150,270 270,545
So that's pretty good.|
所以这是非常好的。|

2534
01:06:41,320 --> 01:06:42,060
0,290 290,455 455,575 575,650 650,740
Another trick you do is
您使用的另一个技巧称为位图编码。

2535
01:06:42,060 --> 01:06:43,840
0,165 165,480 480,1040
called bitmap encoding.|
|

2536
01:06:43,840 --> 01:06:44,680
0,90 90,270 270,510 510,690 690,840
And the idea here is
这里的想法是，如果你有一个基数很低的属性，这意味着它有少量的唯一值。

2537
01:06:44,680 --> 01:06:46,000
0,240 240,495 495,675 675,945 945,1320
that if you have an

2538
01:06:46,000 --> 01:06:48,175
0,470 670,945 945,1155 1155,1440 1440,2175
attribute that has low cardinality,

2539
01:06:48,175 --> 01:06:49,465
0,135 135,240 240,480 480,875 955,1290
meaning it has a small

2540
01:06:49,465 --> 01:06:51,480
0,255 255,450 450,705 705,1085
number of unique values.|
|

2541
01:06:51,640 --> 01:06:53,180
0,305 305,610 780,1025 1025,1190 1190,1540
Where now, instead of storing
现在，不是在一列中存储每两个单独的值，而是实际的值。我要做的是维护位图，其中我为列中可能具有的每个值都有一个位图，并根据列或属性将位设置为1，该偏移量处的两个位具有该特定值。

2542
01:06:53,290 --> 01:06:56,505
0,260 260,485 485,850 1470,2050 2910,3215
for every single twople in

2543
01:06:56,505 --> 01:06:57,555
0,165 165,300 300,555 555,900 900,1050
in a column, here's the

2544
01:06:57,555 --> 01:06:59,535
0,180 180,455 1255,1485 1485,1665 1665,1980
actual value. What I'm staggering

2545
01:06:59,535 --> 01:07:01,100
0,105 105,210 210,450 450,845 985,1565
to do is maintain bitmaps,

2546
01:07:01,630 --> 01:07:02,670
0,215 215,275 275,395 395,605 605,1040
where I have one bitmap

2547
01:07:02,670 --> 01:07:03,975
0,225 225,450 450,765 765,1095 1095,1305
for every possible value I

2548
01:07:03,975 --> 01:07:04,640
0,90 90,195 195,300 300,405 405,665
could have in the column,

2549
01:07:05,140 --> 01:07:05,985
0,275 275,425 425,575 575,710 710,845
and the bit is set

2550
01:07:05,985 --> 01:07:07,310
0,150 150,425 565,870 870,1050 1050,1325
to one based on whether

2551
01:07:07,840 --> 01:07:09,210
0,335 335,575 575,845 845,1130 1130,1370
the the column or the

2552
01:07:09,210 --> 01:07:10,455
0,345 345,585 585,840 840,975 975,1245
attribute, the twople at that

2553
01:07:10,455 --> 01:07:12,290
0,395 835,1125 1125,1305 1305,1515 1515,1835
offset has that particular value.|
|

2554
01:07:13,790 --> 01:07:15,140
0,400
Right.|
正确的。|

2555
01:07:15,390 --> 01:07:17,435
0,400 1140,1385 1385,1535 1535,1760 1760,2045
So there are some database
所以有一些数据库系统，它们提供的位图索引基本上提供了相同的东西。您仍然保留原来的列，但它们维护的位图索引将执行与我们在这里看到的相同的技术。这是有系统的。有一家公司会在本学期晚些时候来谈论他们的数据，要么是特征库，要么是特征表格。有两个不同的人有着相同的卑鄙特征。其中一个只存储位图索引。他们，你实际上不能存储真正的数据库数据。

2556
01:07:17,435 --> 01:07:19,490
0,365 475,825 825,1175 1225,1590 1590,2055
systems that, that provide bitmap

2557
01:07:19,490 --> 01:07:20,510
0,390 390,510 510,690 690,885 885,1020
indexes that essentially give the

2558
01:07:20,510 --> 01:07:21,335
0,180 180,420 420,615 615,735 735,825
same things. You still have

2559
01:07:21,335 --> 01:07:22,520
0,75 75,270 270,635 835,1080 1080,1185
the original column, but then

2560
01:07:22,520 --> 01:07:24,005
0,135 135,410 580,1020 1020,1365 1365,1485
they maintain bitmap indexes that

2561
01:07:24,005 --> 01:07:24,710
0,105 105,210 210,315 315,465 465,705
will do the same technique

2562
01:07:24,710 --> 01:07:26,900
0,210 210,375 375,510 510,800 1870,2190
that we're seeing here. There's

2563
01:07:26,900 --> 01:07:28,535
0,120 120,410 520,825 825,1040 1300,1635
a system. There's a company

2564
01:07:28,535 --> 01:07:29,255
0,225 225,330 330,465 465,600 600,720
that's gonna come talk about

2565
01:07:29,255 --> 01:07:33,170
0,195 195,545 595,975 975,1215 1215,3915
their data later this semester,

2566
01:07:33,170 --> 01:07:34,340
0,270 270,525 525,765 765,945 945,1170
either feature base or feature

2567
01:07:34,340 --> 01:07:37,775
0,350 1330,1695 1695,1815 1815,2060 3160,3435
form. There's two different have

2568
01:07:37,775 --> 01:07:38,555
0,135 135,270 270,450 450,645 645,780
the same mean feature in

2569
01:07:38,555 --> 01:07:39,760
0,245 505,750 750,825 825,930 930,1205
them. One of them only

2570
01:07:39,840 --> 01:07:41,495
0,320 320,695 695,1145 1145,1430 1430,1655
stores bitmap indexes. They, you

2571
01:07:41,495 --> 01:07:42,460
0,255 255,405 405,540 540,690 690,965
can't actually store real data

2572
01:07:42,990 --> 01:07:44,160
0,305 305,610
base data.|
|

2573
01:07:45,210 --> 01:07:45,950
0,245 245,365 365,470 470,560 560,740
So the idea is here.
因此，这个想法就在这里。所以说我们回到我们的死神专栏，对吗？再来一次。只有两种可能的值，要么死了，要么没死。

2574
01:07:45,950 --> 01:07:46,595
0,180 180,300 300,405 405,495 495,645
So say we go back

2575
01:07:46,595 --> 01:07:47,650
0,195 195,375 375,570 570,765 765,1055
to our is dead column,

2576
01:07:48,180 --> 01:07:50,330
0,400 930,1330 1500,1820 1820,1970 1970,2150
right? Again. There's only two

2577
01:07:50,330 --> 01:07:51,470
0,210 210,525 525,810 810,1005 1005,1140
possible values, either dead or

2578
01:07:51,470 --> 01:07:53,620
0,150 150,440
not dead.|
|

2579
01:07:54,060 --> 01:07:55,415
0,350 350,590 590,830 830,1100 1100,1355
Instead, in storing in the
相反，在存储实际的单值本身时，我有两个位图。一个人说是，一个人说不，然后在每个位图中设置一个位，它对应于原始值是否有那个位图，它是否有那个特定值。

2580
01:07:55,415 --> 01:07:57,065
0,180 180,345 345,635 685,1085 1375,1650
actual single values themselves, I

2581
01:07:57,065 --> 01:07:58,775
0,180 180,345 345,480 480,755 1345,1710
have two bit maps. One

2582
01:07:58,775 --> 01:08:00,700
0,365 925,1215 1215,1425 1425,1635 1635,1925
says for yes, one says

2583
01:08:00,750 --> 01:08:03,230
0,320 320,640 1920,2180 2180,2315 2315,2480
says no, and then there's

2584
01:08:03,230 --> 01:08:04,775
0,135 135,440 460,765 765,1070 1270,1545
a bit here that set

2585
01:08:04,775 --> 01:08:06,350
0,135 135,270 270,695 715,1020 1020,1575
in each bitmap that corresponds

2586
01:08:06,350 --> 01:08:07,595
0,135 135,345 345,615 615,930 930,1245
to whether the the original

2587
01:08:07,595 --> 01:08:09,035
0,255 255,450 450,725 805,1110 1110,1440
value has that that bitmap

2588
01:08:09,035 --> 01:08:10,130
0,105 105,335 505,765 765,900 900,1095
or not, it has that

2589
01:08:10,130 --> 01:08:11,380
0,225 225,420 420,555 555,800
particular value or not.|
|

2590
01:08:12,290 --> 01:08:13,690
0,400 600,875 875,1010 1010,1190 1190,1400
Right, so I only need
对，所以我现在只需要两位，八位，十六位来存储是或否？然后现在我的位图只有18位。

2591
01:08:13,690 --> 01:08:17,080
0,290 1420,1710 1710,1920 1920,2240 3040,3390
now two, eight bits, sixteen

2592
01:08:17,080 --> 01:08:18,130
0,240 240,405 405,660 660,900 900,1050
bits to store the yes

2593
01:08:18,130 --> 01:08:19,540
0,150 150,410 820,1080 1080,1230 1230,1410
or no? And then now

2594
01:08:19,540 --> 01:08:20,760
0,165 165,330 330,585 585,885 885,1220
my bit map is just

2595
01:08:22,220 --> 01:08:23,720
0,365 365,730
eighteen bits.|
|

2596
01:08:23,940 --> 01:08:24,880
0,245 245,335 335,440 440,620 620,940
Because I have nine values
因为我有九个值，每个值需要两位，所以我可以把它降到34位。

2597
01:08:24,930 --> 01:08:25,775
0,245 245,350 350,530 530,710 710,845
and I need two bits

2598
01:08:25,775 --> 01:08:26,870
0,275 595,825 825,885 885,960 960,1095
each, so I can get

2599
01:08:26,870 --> 01:08:27,950
0,180 180,375 375,570 570,720 720,1080
this down down to 34

2600
01:08:27,950 --> 01:08:29,040
0,290
bits.|
|

2601
01:08:32,240 --> 01:08:32,900
0,75 75,210 210,375 375,525 525,660
What's an obvious problem with
这种方法最明显的问题是什么？

2602
01:08:32,900 --> 01:08:34,240
0,150 150,440
this approach?|
|

2603
01:08:35,400 --> 01:08:38,570
0,400 1260,1580 1580,2290 2310,2710 2910,3170
Yes, high cardinality really? He
是的，高基数真的吗？他说，如果你的数据是高基数的，这确实是一个糟糕的想法。是的。让我们来看一个例子。

2604
01:08:38,570 --> 01:08:39,410
0,255 255,510 510,630 630,735 735,840
said, if your data is

2605
01:08:39,410 --> 01:08:40,355
0,150 150,660 660,750 750,825 825,945
high cardinality this is a

2606
01:08:40,355 --> 01:08:42,020
0,270 270,665 865,1200 1200,1470 1470,1665
terrible idea indeed. Yes it

2607
01:08:42,020 --> 01:08:43,190
0,260 640,930 930,1005 1005,1080 1080,1170
is. Let's look at an

2608
01:08:43,190 --> 01:08:44,180
0,260
example.|
|

2609
01:08:44,300 --> 01:08:45,070
0,290 290,470 470,590 590,665 665,770
So say we have a
假设我们有一个这样的Customer表，我们有一个邮政编码列。

2610
01:08:45,070 --> 01:08:46,555
0,180 180,390 390,540 540,800 1240,1485
customer table like this and

2611
01:08:46,555 --> 01:08:47,365
0,210 210,420 420,525 525,675 675,810
we have the zip code

2612
01:08:47,365 --> 01:08:48,500
0,275
column.|
|

2613
01:08:48,500 --> 01:08:50,015
0,290 670,930 930,1080 1080,1260 1260,1515
Right. How many zip codes
正确的。美国有多少个邮政编码？猜猜看。

2614
01:08:50,015 --> 01:08:50,860
0,180 180,270 270,360 360,525 525,845
are in the United States?

2615
01:08:51,090 --> 01:08:52,320
0,400
Guess.|
|

2616
01:08:53,210 --> 01:08:54,750
0,245 245,365 365,755 755,1120 1140,1540
I heard 10,000 no more
我听到的是一万而不是十几万。但现在我们要做的是二进制搜索。是43,000，对吧？假设我们有一个表，我们有1000万行，我将为我拥有的每个唯一的邮政编码构建一个位图。好吧，我需要。

2617
01:08:55,490 --> 01:08:57,220
0,275 275,485 485,820 1410,1655 1655,1730
hundred thousand less. But now

2618
01:08:57,220 --> 01:08:59,845
0,105 105,180 180,420 420,710 2290,2625
we're doing binary search. It's

2619
01:08:59,845 --> 01:09:02,560
0,545 1255,1655 2335,2580 2580,2655 2655,2715
43,000, right? Assuming we have

2620
01:09:02,560 --> 01:09:03,340
0,90 90,270 270,435 435,585 585,780
a table, we do 10

2621
01:09:03,340 --> 01:09:05,590
0,195 195,680 1060,1460 1870,2205 2205,2250
million rows and I'm going

2622
01:09:05,590 --> 01:09:06,970
0,75 75,180 180,315 315,800 1120,1380
to build a bitmap for

2623
01:09:06,970 --> 01:09:08,500
0,180 180,405 405,660 660,1010 1240,1530
every single unique possible zip

2624
01:09:08,500 --> 01:09:10,675
0,105 105,210 210,470 970,1370 1870,2175
code I have. Well, I'm

2625
01:09:10,675 --> 01:09:12,240
0,45 45,105 105,335
going to need.|
|

2626
01:09:13,410 --> 01:09:14,360
0,290 290,455 455,605 605,740 740,950
Just to store the data,
只是为了存储数据，假设原始数据，假设我们可以，邮政编码是30位。原始数据是40兆字节。但如果我必须为每个邮政编码都有一个1000万大小的位图，现在我们的容量是5053个。所以很明显，这不是一个好主意。

2627
01:09:14,360 --> 01:09:15,995
0,350 610,900 900,1125 1125,1395 1395,1635
assuming the raw data, assuming

2628
01:09:15,995 --> 01:09:17,135
0,150 150,395 655,930 930,1020 1020,1140
we can, zip code is

2629
01:09:17,135 --> 01:09:18,680
0,210 210,545 955,1200 1200,1365 1365,1545
thirty bits. The raw data

2630
01:09:18,680 --> 01:09:20,210
0,240 240,510 510,1130 1210,1455 1455,1530
is forty megabytes. But if

2631
01:09:20,210 --> 01:09:21,190
0,105 105,240 240,375 375,615 615,980
I had to have a

2632
01:09:21,480 --> 01:09:22,870
0,305 305,560 560,860 860,1100 1100,1390
10 million size bit map

2633
01:09:24,030 --> 01:09:26,200
0,260 260,470 470,820 1590,1895 1895,2170
for every single zip code,

2634
01:09:26,550 --> 01:09:28,420
0,275 275,425 425,515 515,1415 1415,1870
now we're at 5053 gigs.

2635
01:09:29,520 --> 01:09:30,665
0,290 290,580 660,920 920,1025 1025,1145
So clearly this is a

2636
01:09:30,665 --> 01:09:31,820
0,240 240,605
bad idea.|
|

2637
01:09:31,890 --> 01:09:35,645
0,400 1170,1810 3000,3320 3320,3545 3545,3755
Um, furthermore, every time somebody
嗯，此外，每次有人添加新的两个池时，我都必须扩展该位图，因为我，你知道，因为它也必须匹配。我一直在添加更多，你知道的，在上面。因此，我必须为每一种可能的咬合都这样做。

2638
01:09:35,645 --> 01:09:36,520
0,225 225,300 300,420 420,585 585,875
adds a new two pool,

2639
01:09:37,260 --> 01:09:38,375
0,260 260,365 365,575 575,875 875,1115
I have to extend that

2640
01:09:38,375 --> 01:09:39,965
0,485 775,1035 1035,1275 1275,1485 1485,1590
bitmap because I, you know,

2641
01:09:39,965 --> 01:09:40,790
0,135 135,345 345,570 570,705 705,825
because it also have to

2642
01:09:40,790 --> 01:09:41,855
0,165 165,345 345,495 495,735 735,1065
match. I keep adding more,

2643
01:09:41,855 --> 01:09:42,650
0,225 225,360 360,480 480,645 645,795
you know, to it. So

2644
01:09:42,650 --> 01:09:43,025
0,60 60,135 135,210 210,285 285,375
I have to do that

2645
01:09:43,025 --> 01:09:44,740
0,120 120,330 330,615 615,1145
for every possible bitap.|
|

2646
01:09:44,740 --> 01:09:45,940
0,380
Right.|
正确的。|

2647
01:09:46,160 --> 01:09:47,230
0,260 260,500 500,890 890,980 980,1070
So that indexes can make
因此，索引可以产生巨大的差异，但这实际上是为了，比如当你现在有一张非常小的数字卡时，比如，可能不到10张。

2648
01:09:47,230 --> 01:09:48,355
0,150 150,360 360,680 730,960 960,1125
a huge difference, but it's

2649
01:09:48,355 --> 01:09:49,765
0,240 240,525 525,845 1105,1335 1335,1410
really for, like when you

2650
01:09:49,765 --> 01:09:50,785
0,75 75,210 210,515 535,825 825,1020
have a really small number

2651
01:09:50,785 --> 01:09:51,805
0,210 210,390 390,570 570,795 795,1020
card now, like, like less

2652
01:09:51,805 --> 01:09:53,520
0,180 180,375 375,695
than maybe ten.|
|

2653
01:09:53,680 --> 01:09:54,560
0,320 320,425 425,515 515,620 620,880
You want to do this?|
你想这么做吗？|

2654
01:09:56,210 --> 01:09:58,150
0,400 600,905 905,1210 1610,1775 1775,1940
And most systems don't do
而且大多数系统在默认情况下不会这样做。

2655
01:09:58,150 --> 01:09:59,200
0,120 120,285 285,590
this by default.|
|

2656
01:10:01,100 --> 01:10:02,695
0,275 275,515 515,980 980,1340 1340,1595
All right, delta coding. The
好了，增量编码。这里的想法是，如果从一个属性到下一个属性的值从一个属性指向下一个属性，两个属性指向下一个属性，如果它们彼此足够接近，就很抱歉。

2657
01:10:02,695 --> 01:10:03,805
0,255 255,420 420,540 540,810 810,1110
idea here is that if

2658
01:10:03,805 --> 01:10:05,790
0,225 225,545 1015,1305 1305,1575 1575,1985
the values from one attribute

2659
01:10:05,840 --> 01:10:07,165
0,245 245,350 350,610 930,1190 1190,1325
to the next from one,

2660
01:10:07,165 --> 01:10:07,645
0,120 120,195 195,255 255,315 315,480
two point to the next,

2661
01:10:07,645 --> 01:10:10,135
0,335 1405,1710 1710,2040 2040,2280 2280,2490
sorry if they're close enough

2662
01:10:10,135 --> 01:10:11,320
0,105 105,210 210,485
to each other.|
|

2663
01:10:11,320 --> 01:10:12,235
0,330 330,570 570,675 675,840 840,915
Maybe, again, I don't need
也许，再说一次，我不需要存储1，2个po的整个值。我只需要存储前一个值之间的差值。

2664
01:10:12,235 --> 01:10:13,290
0,120 120,300 300,495 495,720 720,1055
to store the entire value

2665
01:10:15,380 --> 01:10:16,495
0,245 245,350 350,470 470,730 810,1115
for one, two po. I

2666
01:10:16,495 --> 01:10:17,545
0,165 165,285 285,420 420,695 745,1050
just need to store the

2667
01:10:17,545 --> 01:10:18,895
0,285 285,510 510,660 660,1140 1140,1350
difference of the delta between

2668
01:10:18,895 --> 01:10:20,320
0,180 180,420 420,755
the previous value.|
|

2669
01:10:20,670 --> 01:10:21,500
0,230 230,380 380,485 485,635 635,830
So let's say again, I
让我们再说一遍，我有一种传感器读数，我在记录房间里的温度，每一分钟我都在存储温度，对吗？所以这里是时间戳列，假设我们存储的是64位。

2670
01:10:21,500 --> 01:10:22,610
0,210 210,420 420,740 760,1005 1005,1110
I have a kind of

2671
01:10:22,610 --> 01:10:23,510
0,270 270,450 450,600 600,735 735,900
sensor reading where I'm keeping

2672
01:10:23,510 --> 01:10:24,335
0,210 210,330 330,420 420,630 630,825
track of the temperature in

2673
01:10:24,335 --> 01:10:25,625
0,105 105,365 595,840 840,1020 1020,1290
the room, and every minute

2674
01:10:25,625 --> 01:10:28,000
0,615 615,1695 1695,1920 1920,2115 2115,2375
I'm i'm'm storing the temperature

2675
01:10:28,650 --> 01:10:30,410
0,400 1020,1265 1265,1355 1355,1520 1520,1760
right? So it is time

2676
01:10:30,410 --> 01:10:31,955
0,240 240,495 495,830 1120,1410 1410,1545
stamp column here, assuming that

2677
01:10:31,955 --> 01:10:33,920
0,135 135,395 445,915 915,1175
we're storing 64 bits.|
|

2678
01:10:33,920 --> 01:10:35,320
0,380
Uh.|
呃。|

2679
01:10:35,470 --> 01:10:36,870
0,320 320,620 620,905 905,1145 1145,1400
We know that the time
我们知道时间总是以1递增，而且，假设我能跟踪室内或室外的温度，你知道，从一分钟到下一分钟，不会有戏剧性的温度波动。

2680
01:10:36,870 --> 01:10:38,370
0,240 240,420 420,600 600,855 855,1500
is always going incre increment

2681
01:10:38,370 --> 01:10:40,455
0,180 180,470 730,1020 1020,1580 1810,2085
by one, and furthermore, assuming

2682
01:10:40,455 --> 01:10:41,040
0,105 105,195 195,345 345,495 495,585
I can keep track of

2683
01:10:41,040 --> 01:10:41,985
0,75 75,320 520,765 765,855 855,945
the temperature, you know, in

2684
01:10:41,985 --> 01:10:43,740
0,105 105,240 240,465 465,815 1465,1755
the room or outside from

2685
01:10:43,740 --> 01:10:44,565
0,180 180,375 375,525 525,630 630,825
one minute to the next,

2686
01:10:44,565 --> 01:10:45,380
0,270 270,405 405,525 525,585 585,815
there's not going to be

2687
01:10:45,580 --> 01:10:47,600
0,400 450,850 870,1300
dramatic temperature swings.|
|

2688
01:10:47,610 --> 01:10:48,275
0,275 275,455 455,515 515,590 590,665
Right. We're not going to
正确的。我们不会在一分钟内从华氏99度降到零度。

2689
01:10:48,275 --> 01:10:49,925
0,150 150,375 375,695 895,1410 1410,1650
go from like 99 degrees

2690
01:10:49,925 --> 01:10:52,220
0,210 210,435 435,785 1315,1715 2035,2295
to zero degrees within a

2691
01:10:52,220 --> 01:10:53,100
0,260
minute.|
|

2692
01:10:53,670 --> 01:10:54,545
0,275 275,500 500,695 695,785 785,875
And so what I can
所以我现在能做的就是存储，你知道，从一个二到下一个。这里的前一次有什么不同？

2693
01:10:54,545 --> 01:10:55,445
0,135 135,330 330,540 540,720 720,900
just do now is to

2694
01:10:55,445 --> 01:10:57,365
0,305 1135,1380 1380,1500 1500,1650 1650,1920
store, you know, from one

2695
01:10:57,365 --> 01:10:58,610
0,285 285,405 405,480 480,725 955,1245
two to the next. What

2696
01:10:58,610 --> 01:11:00,050
0,150 150,270 270,530 550,950 1150,1440
was the difference between the

2697
01:11:00,050 --> 01:11:01,360
0,225 225,450 450,740
previous one here?|
|

2698
01:11:01,890 --> 01:11:03,725
0,400 840,1085 1085,1330 1380,1670 1670,1835
Right. So in in case
正确的。因此，在时间戳的情况下，它只是加1，如果温度在前一个十进制之间的小数差，则增加一分钟。

2699
01:11:03,725 --> 01:11:04,910
0,240 240,480 480,675 675,930 930,1185
of the time stamp, it's

2700
01:11:04,910 --> 01:11:06,020
0,135 135,360 360,675 675,960 960,1110
just plus one, adding a

2701
01:11:06,020 --> 01:11:07,895
0,260 1330,1590 1590,1710 1710,1800 1800,1875
minute in case of the

2702
01:11:07,895 --> 01:11:11,510
0,875 2545,2985 2985,3240 3240,3495 3495,3615
temperature's decimal difference between the

2703
01:11:11,510 --> 01:11:12,740
0,165 165,470
previous one.|
|

2704
01:11:14,210 --> 01:11:15,325
0,290 290,575 575,710 710,875 875,1115
I compress this even further
我现在进一步压缩它，因为我在时间戳的第一列中有什么？我有什么？

2705
01:11:15,325 --> 01:11:16,240
0,335 385,660 660,780 780,855 855,915
now because what do I

2706
01:11:16,240 --> 01:11:17,515
0,230 520,765 765,900 900,1080 1080,1275
have in this first column

2707
01:11:17,515 --> 01:11:18,570
0,240 240,450 450,585 585,750 750,1055
here at the time stamp?

2708
01:11:18,650 --> 01:11:20,180
0,260 260,350 350,440 440,700
What do I have?|
|

2709
01:11:20,300 --> 01:11:21,270
0,260 260,380 380,500 500,665 665,970
A bunch of plus ones.
一大堆加在一起的。我们怎么才能压缩它呢？

2710
01:11:21,800 --> 01:11:22,740
0,275 275,365 365,425 425,650 650,940
How can we compress that?|
|

2711
01:11:25,360 --> 01:11:27,660
0,260 260,380 380,910 1020,1420
Run length encoding right.|
游程长度编码正确。|

2712
01:11:27,660 --> 01:11:28,410
0,195 195,285 285,405 405,615 615,750
So we can compress this
所以我们现在可以进一步压缩它，并将其转换为。

2713
01:11:28,410 --> 01:11:30,135
0,165 165,390 390,710 970,1370 1450,1725
even further now and convert

2714
01:11:30,135 --> 01:11:32,660
0,150 150,425
this into.|
|

2715
01:11:33,230 --> 01:11:34,740
0,245 245,425 425,665 665,970 1110,1510
You know, convert the combination
你知道，转换dev编码和游程长度编码的组合，来告诉你之后我有多少加一。

2716
01:11:34,850 --> 01:11:37,140
0,275 275,550 1380,1685 1685,2060 2060,2290
of the dev encoding and

2717
01:11:37,400 --> 01:11:38,695
0,275 275,410 410,905 905,1160 1160,1295
running length encoding to tell

2718
01:11:38,695 --> 01:11:39,550
0,135 135,255 255,435 435,660 660,855
you how many plus ones

2719
01:11:39,550 --> 01:11:41,140
0,150 150,375 375,740
I have afterwards.|
|

2720
01:11:43,480 --> 01:11:44,040
0,275 275,380 380,440 440,500 500,560
Right. So this is a
正确的。所以这是一个很好的例子。再一次，我们可以有乘数效应，我们可以进一步压缩压缩的数据，因为我们把它变成了一种可以利用它的形式。

2721
01:11:44,040 --> 01:11:44,910
0,135 135,405 405,645 645,765 765,870
good example. Again, we can

2722
01:11:44,910 --> 01:11:45,990
0,135 135,270 270,765 765,945 945,1080
have this multiplicer effect where

2723
01:11:45,990 --> 01:11:47,325
0,120 120,225 225,620 820,1065 1065,1335
we can compress the compressed

2724
01:11:47,325 --> 01:11:49,155
0,305 325,645 645,965 1375,1650 1650,1830
data even further because we're

2725
01:11:49,155 --> 01:11:50,055
0,120 120,270 270,420 420,615 615,900
putting into a form that

2726
01:11:50,055 --> 01:11:52,410
0,375 375,875 1705,1965 1965,2130 2130,2355
that's, that's, that can take

2727
01:11:52,410 --> 01:11:53,960
0,225 225,390 390,650
advantage of it.|
|

2728
01:11:54,200 --> 01:11:55,075
0,290 290,425 425,515 515,650 650,875
So if you go back
因此，如果您回到我们的原始数据大小。

2729
01:11:55,075 --> 01:11:56,310
0,255 255,465 465,660 660,900 900,1235
to our original data size.|
|

2730
01:11:58,140 --> 01:11:59,205
0,315 315,510 510,630 630,825 825,1065
Just for the time stamp
仅就时间戳列本身而言，我们只需要320位，但如果我们先进行深度编码，然后进行编码，则需要将其降至96位。

2731
01:11:59,205 --> 01:12:01,110
0,285 285,665 955,1230 1230,1395 1395,1905
column itself, we at 320

2732
01:12:01,110 --> 01:12:02,655
0,320 790,1020 1020,1095 1095,1275 1275,1545
bits, but if we do

2733
01:12:02,655 --> 01:12:03,900
0,180 180,300 300,765 765,990 990,1245
the depth encoding followed by

2734
01:12:03,900 --> 01:12:05,925
0,320 820,1490 1570,1830 1830,1935 1935,2025
the encoding, we need it

2735
01:12:05,925 --> 01:12:07,540
0,135 135,270 270,630 630,935
down to 96 bits.|
|

2736
01:12:08,020 --> 01:12:09,330
0,305 305,575 575,850 870,1160 1160,1310
Again, I'm showing six or
再说一次，我在这里展示了六到七个双胞胎。它没那么大。但是，再说一次，把它想象成极端的。想象一下，大概有10亿张唱片。这将是一笔巨大的节省。

2737
01:12:09,330 --> 01:12:10,320
0,180 180,525 525,690 690,900 900,990
seven twoils here. It's not

2738
01:12:10,320 --> 01:12:11,370
0,150 150,390 390,660 660,885 885,1050
that big. But again, think

2739
01:12:11,370 --> 01:12:12,750
0,90 90,270 270,620 1030,1275 1275,1380
of it extreme. Think of

2740
01:12:12,750 --> 01:12:15,420
0,260 670,960 960,1185 1185,1520 2410,2670
like a billion records. This

2741
01:12:15,420 --> 01:12:16,280
0,105 105,180 180,270 270,495 495,860
would be a massive savings.|
|

2742
01:12:19,940 --> 01:12:21,130
0,275 275,470 470,695 695,950 950,1190
The last one discussed is
最后讨论的是字典压缩，因为我也说过，这是最常见的一种，这就是我们将如何获得它，大多数系统将如何表达数据，即使是对于不是正确字符串的东西。在某些情况下，有一些列式系统会将整数数据或流数据压缩，并将它们放到字典代码中。

2743
01:12:21,130 --> 01:12:22,465
0,360 360,710 730,1020 1020,1185 1185,1335
dictionary compression because again, I

2744
01:12:22,465 --> 01:12:23,215
0,150 150,315 315,480 480,600 600,750
said this is the most

2745
01:12:23,215 --> 01:12:24,145
0,240 240,480 480,645 645,765 765,930
common one, this is how

2746
01:12:24,145 --> 01:12:25,435
0,180 180,225 225,300 300,545 1015,1290
we're going to get this,

2747
01:12:25,435 --> 01:12:26,830
0,275 385,705 705,1025 1075,1320 1320,1395
how most systems are going

2748
01:12:26,830 --> 01:12:28,360
0,90 90,240 240,530 940,1290 1290,1530
to express data, even for

2749
01:12:28,360 --> 01:12:30,150
0,180 180,300 300,540 540,890 1390,1790
things that aren't strings right.

2750
01:12:31,100 --> 01:12:32,275
0,290 290,470 470,725 725,950 950,1175
In some cases there are

2751
01:12:32,275 --> 01:12:34,350
0,365 625,1095 1095,1335 1335,1590 1590,2075
some columnar systems will compress

2752
01:12:34,370 --> 01:12:35,580
0,485 485,605 605,770 770,935 935,1210
integer data or flow data

2753
01:12:35,750 --> 01:12:37,570
0,260 260,395 395,670 690,1090 1290,1820
and putting them to dictionary

2754
01:12:37,570 --> 01:12:38,420
0,410
codes.|
|

2755
01:12:39,590 --> 01:12:40,510
0,335 335,545 545,680 680,800 800,920
The idea here is that
这里的想法是，如果我们有反复看到的值，而不是在一列中重复存储该值，我们将把它转换为。

2756
01:12:40,510 --> 01:12:42,030
0,105 105,255 255,560 670,1070 1120,1520
if we have values that

2757
01:12:42,050 --> 01:12:43,690
0,400 990,1250 1250,1385 1385,1490 1490,1640
we see over and over

2758
01:12:43,690 --> 01:12:45,355
0,320 940,1185 1185,1290 1290,1500 1500,1665
again, instead of storing that

2759
01:12:45,355 --> 01:12:47,340
0,270 270,905 1255,1545 1545,1710 1710,1985
value repeatedly within a column,

2760
01:12:47,660 --> 01:12:48,580
0,320 320,365 365,500 500,725 725,920
we're going to convert that

2761
01:12:48,580 --> 01:12:49,900
0,290
into.|
|

2762
01:12:49,940 --> 01:12:51,920
0,350 350,800 800,890 890,1360
Some 32 bit integer.|
一些32位整数。|

2763
01:12:52,040 --> 01:12:53,650
0,260 260,365 365,470 470,730 1290,1610
And then we maintain a
然后我们维护一个映射数据结构，知道如何获取它的字典，字典代码，第三个桶整数，并将其转换回原始值。

2764
01:12:53,650 --> 01:12:55,410
0,435 435,645 645,960 960,1185 1185,1760
mapping data structure, the dictionary

2765
01:12:55,580 --> 01:12:56,590
0,275 275,470 470,635 635,785 785,1010
that knows how to take

2766
01:12:56,590 --> 01:12:58,360
0,320 400,735 735,1185 1185,1490 1510,1770
that, that dictionary code, the

2767
01:12:58,360 --> 01:12:59,770
0,135 135,285 285,740 850,1200 1200,1410
third tub integer, and convert

2768
01:12:59,770 --> 01:13:01,435
0,120 120,300 300,620 1150,1440 1440,1665
it back into an original

2769
01:13:01,435 --> 01:13:03,140
0,335
value.|
|

2770
01:13:03,420 --> 01:13:04,220
0,335 335,560 560,605 605,650 650,800
Typically we're going to have,
通常我们会有，这是一个值的一对一对应。我们将有一个字典代码。这里有一些技巧。我认为任何商业系统都不会这样做，你可以说，如果我看到多个属性，模式在一起，我会将它们两个或三个的组合转换为单个字典代码，以获得进一步的压缩。但同样，我只在学术文献中看到过这一点。

2771
01:13:04,220 --> 01:13:04,820
0,210 210,285 285,390 390,480 480,600
it's a one to one

2772
01:13:04,820 --> 01:13:06,650
0,650 670,945 945,1185 1185,1545 1545,1830
correspondence for one value. We'll

2773
01:13:06,650 --> 01:13:08,225
0,120 120,300 300,705 705,1010 1300,1575
have one dictionary code. There

2774
01:13:08,225 --> 01:13:10,100
0,275 565,915 915,1265 1495,1740 1740,1875
is some techniques. I don't

2775
01:13:10,100 --> 01:13:11,000
0,60 60,195 195,405 405,660 660,900
think any commercial system does

2776
01:13:11,000 --> 01:13:12,310
0,290 400,660 660,810 810,1005 1005,1310
this where you can say

2777
01:13:12,420 --> 01:13:13,750
0,245 245,380 380,575 575,875 875,1330
if I see multiple attributes,

2778
01:13:15,210 --> 01:13:16,835
0,260 260,500 500,880 1050,1430 1430,1625
the patterns together, I'll convert

2779
01:13:16,835 --> 01:13:17,735
0,195 195,465 465,690 690,795 795,900
the combination of the two

2780
01:13:17,735 --> 01:13:18,695
0,90 90,335 445,735 735,870 870,960
of them or three of

2781
01:13:18,695 --> 01:13:19,895
0,165 165,420 420,615 615,765 765,1200
them into a single dictionary

2782
01:13:19,895 --> 01:13:21,110
0,305 565,810 810,900 900,1035 1035,1215
code to get even further

2783
01:13:21,110 --> 01:13:24,365
0,410 880,1280 1630,2030 2800,3120 3120,3255
compression. But again, I've only

2784
01:13:24,365 --> 01:13:25,420
0,165 165,285 285,450 450,705 705,1055
seen that in academic literature.|
|

2785
01:13:27,030 --> 01:13:27,995
0,260 260,380 380,515 515,740 740,965
And then we need a
然后，我们需要一种快速编码和解码的方法，允许同时进行范围和点查询。所以点查询是显而易见的，就像我想要说的那样，你知道，Andy映射到的字符串，你知道，代码一，o一，我知道如何做精确的查找和那些，但理想情况下，我希望能够对压缩数据进行范围查询。

2786
01:13:27,995 --> 01:13:29,420
0,195 195,375 375,585 585,900 900,1425
way to do fast encoding

2787
01:13:29,420 --> 01:13:30,460
0,90 90,540 540,645 645,765 765,1040
and decoding on the fly

2788
01:13:30,870 --> 01:13:32,140
0,365 365,635 635,785 785,950 950,1270
that allows to do both

2789
01:13:32,850 --> 01:13:34,805
0,320 320,530 530,725 725,1210 1680,1955
range and point queries. So

2790
01:13:34,805 --> 01:13:35,945
0,165 165,420 420,630 630,900 900,1140
point queries are obvious, like

2791
01:13:35,945 --> 01:13:36,470
0,195 195,300 300,375 375,420 420,525
I want to be able

2792
01:13:36,470 --> 01:13:37,835
0,150 150,410 490,720 720,950 1030,1365
to say, you know, the

2793
01:13:37,835 --> 01:13:39,545
0,240 240,525 525,825 825,1145 1465,1710
string Andy maps to, you

2794
01:13:39,545 --> 01:13:40,600
0,195 195,465 465,645 645,780 780,1055
know, code one, o one,

2795
01:13:40,860 --> 01:13:41,420
0,245 245,335 335,410 410,470 470,560
I know how to do

2796
01:13:41,420 --> 01:13:42,400
0,150 150,330 330,630 630,735 735,980
the exact lookupables and those,

2797
01:13:43,050 --> 01:13:44,270
0,320 320,860 860,995 995,1130 1130,1220
but ideally I want to

2798
01:13:44,270 --> 01:13:44,900
0,60 60,135 135,315 315,525 525,630
be able to also be

2799
01:13:44,900 --> 01:13:45,940
0,75 75,150 150,270 270,510 510,1040
able to do range queries

2800
01:13:46,260 --> 01:13:47,720
0,290 290,575 575,880
on compressed data.|
|

2801
01:13:47,720 --> 01:13:48,530
0,225 225,330 330,450 450,630 630,810
And so I want my
因此，我希望我的字典代码也具有与原始值实际相同的顺序。

2802
01:13:48,530 --> 01:13:49,850
0,435 435,720 720,870 870,1095 1095,1320
dictionary codes to have the

2803
01:13:49,850 --> 01:13:52,550
0,290 1150,1820 1930,2250 2250,2460 2460,2700
same ordering that the original

2804
01:13:52,550 --> 01:13:54,400
0,350 430,690 690,885 885,1220
values actually did, too.|
|

2805
01:13:54,640 --> 01:13:55,275
0,245 245,380 380,455 455,545 545,635
And we'll see how to
我们稍后会看看如何做到这一点。

2806
01:13:55,275 --> 01:13:56,000
0,105 105,255 255,375 375,465 465,725
do that in a second.|
|

2807
01:13:57,600 --> 01:13:58,250
0,260 260,395 395,485 485,545 545,650
So say this is my
假设这是我的原始数据，一堆我以前学生的名字。它的压缩版本可以是，同样，我有我的原始列，把它们转换成32位整数，然后我就有了这个映射表。

2808
01:13:58,250 --> 01:13:59,465
0,165 165,470 730,975 975,1095 1095,1215
original data, a bunch of

2809
01:13:59,465 --> 01:14:00,730
0,245 295,585 585,750 750,945 945,1265
names of my former students.

2810
01:14:02,640 --> 01:14:04,580
0,365 365,730 990,1475 1475,1745 1745,1940
Then the compressed version of

2811
01:14:04,580 --> 01:14:06,560
0,180 180,360 360,620 1000,1400 1690,1980
this could be, again, I

2812
01:14:06,560 --> 01:14:07,895
0,180 180,450 450,765 765,1080 1080,1335
have my original column, convert

2813
01:14:07,895 --> 01:14:10,480
0,165 165,455 1645,2040 2040,2130 2130,2585
those into 32 bit integers,

2814
01:14:10,680 --> 01:14:11,560
0,260 260,365 365,470 470,605 605,880
and then I just had

2815
01:14:11,610 --> 01:14:13,540
0,290 290,635 635,860 860,1210 1530,1930
this mapping table here that.|
|

2816
01:14:14,320 --> 01:14:15,600
0,395 395,670 780,1055 1055,1175 1175,1280
Converts the allows me to
转换允许我查找给定的代码，原始值是什么，或者给定的原始值是什么，代码是什么？这就是词典。

2817
01:14:15,600 --> 01:14:16,575
0,120 120,240 240,360 360,620 640,975
look up to say given

2818
01:14:16,575 --> 01:14:17,600
0,255 255,495 495,570 570,720 720,1025
code, what's the original value

2819
01:14:17,770 --> 01:14:18,615
0,275 275,395 395,470 470,605 605,845
or for a given original

2820
01:14:18,615 --> 01:14:20,540
0,335 835,1245 1245,1515 1515,1650 1650,1925
value, what's what's the code?

2821
01:14:20,710 --> 01:14:22,380
0,245 245,440 440,515 515,1000
And that's the dictionary.|
|

2822
01:14:22,820 --> 01:14:23,470
0,245 245,380 380,500 500,560 560,650
So now we can go
所以现在我们可以回到我的例子，我在最开始的例子，在我和D G twopl中，从名称等于的用户中选择star，我可以通过首先在字典中进行查找来将字符串和转换成字典代码。

2823
01:14:23,470 --> 01:14:24,145
0,135 135,240 240,360 360,540 540,675
back to my example that

2824
01:14:24,145 --> 01:14:24,910
0,75 75,255 255,495 495,615 615,765
I had in the very

2825
01:14:24,910 --> 01:14:25,825
0,210 210,360 360,555 555,765 765,915
beginning with me and D

2826
01:14:25,825 --> 01:14:27,745
0,165 165,575 835,1235 1435,1740 1740,1920
G twopl where select star

2827
01:14:27,745 --> 01:14:28,780
0,150 150,405 405,645 645,840 840,1035
from users where name equals,

2828
01:14:28,780 --> 01:14:31,290
0,260 910,1215 1215,1500 1500,1880 2110,2510
and I can convert the

2829
01:14:31,970 --> 01:14:34,660
0,305 305,610 780,1180 2070,2315 2315,2690
string and into the dictionary

2830
01:14:34,660 --> 01:14:35,770
0,195 195,405 405,600 600,780 780,1110
code by doing a lookup

2831
01:14:35,770 --> 01:14:37,500
0,240 240,405 405,495 495,1010
first in the dictionary.|
|

2832
01:14:37,660 --> 01:14:39,045
0,335 335,545 545,755 755,1040 1040,1385
Then now I scan through
然后，现在我浏览我的My列，只进行查找或基于整数进行比较。所以我不需要在扫描的时候通过。如果我不这样做，如果我不压缩我的常量，那么当我扫描的时候，我必须一个一个地解压缩，然后再进行查找。我基本上失去了所有的好处，所有的压缩。

2833
01:14:39,045 --> 01:14:40,770
0,395 775,1080 1080,1335 1335,1545 1545,1725
my my column and just

2834
01:14:40,770 --> 01:14:42,380
0,320 370,825 825,1005 1005,1245 1245,1610
do lookup or do do

2835
01:14:42,880 --> 01:14:44,300
0,545 545,740 740,875 875,965 965,1420
comparisons based on the integers.

2836
01:14:44,590 --> 01:14:45,450
0,230 230,320 320,560 560,710 710,860
So I don't need to

2837
01:14:45,450 --> 01:14:46,440
0,180 180,360 360,480 480,675 675,990
go through as I'm scanning

2838
01:14:46,440 --> 01:14:47,970
0,290 760,1020 1020,1125 1125,1350 1350,1530
along. If I don't do,

2839
01:14:47,970 --> 01:14:49,065
0,165 165,270 270,465 465,810 810,1095
if I don't compress my

2840
01:14:49,065 --> 01:14:50,445
0,240 240,545 835,1095 1095,1215 1215,1380
my constant, then as I

2841
01:14:50,445 --> 01:14:51,680
0,210 210,435 435,615 615,855 855,1235
scan along, I gotta go

2842
01:14:51,790 --> 01:14:52,800
0,530 530,680 680,770 770,875 875,1010
decompress each of these one

2843
01:14:52,800 --> 01:14:53,940
0,150 150,440 610,870 870,1005 1005,1140
by one and then do

2844
01:14:53,940 --> 01:14:55,575
0,120 120,420 420,690 690,980 1330,1635
my lookup. I'm basically losing

2845
01:14:55,575 --> 01:14:57,350
0,180 180,315 315,525 525,875 1195,1775
all the benefit, any compression.|
|

2846
01:14:57,920 --> 01:14:59,030
0,350 460,705 705,870 870,960 960,1110
Right. And that's what my
正确的。这就是我的SQL必须做的，因为它们无法解释词典中的实际内容。它们无法解释压缩字节的实际含义。但在这里，因为我们是数据系统，我们，我们建立了词典，我们控制它，我们知道如何阅读和解释它。我们可以AND WE和SQL，所以我们知道查询想要做什么。我们知道如何获取该常量，将其转换为字典代码，然后直接对压缩数据进行扫描。

2847
01:14:59,030 --> 01:14:59,975
0,240 240,330 330,450 450,690 690,945
sql has to do because

2848
01:14:59,975 --> 01:15:01,235
0,165 165,585 585,855 855,1095 1095,1260
they can't interpret what's actually

2849
01:15:01,235 --> 01:15:02,105
0,150 150,270 270,570 570,675 675,870
in the dictionary. They can't

2850
01:15:02,105 --> 01:15:03,560
0,245 505,765 765,870 870,1110 1110,1455
interpret what the compressed bytes

2851
01:15:03,560 --> 01:15:04,835
0,195 195,470 850,1080 1080,1155 1155,1275
actually mean. But in this

2852
01:15:04,835 --> 01:15:06,215
0,180 180,485 745,1080 1080,1305 1305,1380
case here, because we're the

2853
01:15:06,215 --> 01:15:07,820
0,195 195,545 805,1170 1170,1425 1425,1605
data system, we, we built

2854
01:15:07,820 --> 01:15:09,110
0,120 120,570 570,885 885,1140 1140,1290
the dictionary, we control it,

2855
01:15:09,110 --> 01:15:09,635
0,105 105,195 195,285 285,390 390,525
we know how to read

2856
01:15:09,635 --> 01:15:11,150
0,150 150,405 405,705 705,1025 1225,1515
it and interpret it. We

2857
01:15:11,150 --> 01:15:12,605
0,290 460,720 720,840 840,1080 1080,1455
can and we and sql,

2858
01:15:12,605 --> 01:15:13,025
0,105 105,180 180,270 270,345 345,420
so we know what the

2859
01:15:13,025 --> 01:15:14,090
0,150 150,300 300,420 420,665 775,1065
query wants to do. We

2860
01:15:14,090 --> 01:15:14,825
0,195 195,345 345,435 435,555 555,735
know how to take that

2861
01:15:14,825 --> 01:15:16,250
0,305 925,1170 1170,1275 1275,1365 1365,1425
constant, convert it to the

2862
01:15:16,250 --> 01:15:18,140
0,330 330,620 1030,1430 1480,1770 1770,1890
dictionary code, then then do

2863
01:15:18,140 --> 01:15:18,965
0,135 135,375 375,600 600,735 735,825
our scan directly on the

2864
01:15:18,965 --> 01:15:20,200
0,225 225,545
compressed data.|
|

2865
01:15:23,790 --> 01:15:24,960
0,400
So.|
所以。|

2866
01:15:25,210 --> 01:15:25,965
0,245 245,320 320,455 455,620 620,755
How do we actually do
我们到底要怎么做呢？做编码和解码，对吗？再说一次，对于一个给定的，给定的最低值，我们知道有一种方法可以按Form，然后反转它。所以你要指出的关键是，不会有一个神奇的散列函数可以为我们做到这一点。

2867
01:15:25,965 --> 01:15:27,330
0,275 535,795 795,900 900,1260 1260,1365
this? Do the encoding and

2868
01:15:27,330 --> 01:15:29,670
0,530 730,1130 1540,1890 1890,2175 2175,2340
decoding, right? Well, again, for

2869
01:15:29,670 --> 01:15:31,635
0,75 75,320 760,1160 1270,1740 1740,1965
a given, given unest value,

2870
01:15:31,635 --> 01:15:32,115
0,195 195,285 285,345 345,405 405,480
we know had a way

2871
01:15:32,115 --> 01:15:33,855
0,90 90,335 805,1095 1095,1385 1495,1740
to go press form and

2872
01:15:33,855 --> 01:15:35,595
0,165 165,390 390,695 1165,1530 1530,1740
then reverse it. So the

2873
01:15:35,595 --> 01:15:36,060
0,120 120,210 210,270 270,360 360,465
key thing you point out

2874
01:15:36,060 --> 01:15:36,705
0,120 120,315 315,465 465,600 600,645
is there's not going to

2875
01:15:36,705 --> 01:15:37,635
0,30 30,105 105,345 345,720 720,930
be a magic hash function

2876
01:15:37,635 --> 01:15:38,460
0,210 210,360 360,495 495,660 660,825
that can do this for

2877
01:15:38,460 --> 01:15:39,400
0,260
us.|
|

2878
01:15:39,400 --> 01:15:42,220
0,290
Right.|
正确的。|

2879
01:15:42,700 --> 01:15:45,080
0,335 335,890 890,1160 1160,1420 1980,2380
Any reversible hash function is,
任何可逆的散列函数都会产生比值的版本大得多的东西，所以不要把它缩小到30位整数。

2880
01:15:45,130 --> 01:15:46,890
0,400 780,1025 1025,1235 1235,1535 1535,1760
is going to generate something

2881
01:15:46,890 --> 01:15:48,225
0,180 180,285 285,495 495,830 970,1335
that's something much larger likely

2882
01:15:48,225 --> 01:15:49,005
0,225 225,330 330,450 450,570 570,780
than the version of value,

2883
01:15:49,005 --> 01:15:50,130
0,285 285,605 655,900 900,990 990,1125
so not get it down

2884
01:15:50,130 --> 01:15:51,500
0,240 240,480 480,705 705,900 900,1370
to a thirty bit integer.|
|

2885
01:15:52,150 --> 01:15:53,490
0,400 930,1145 1145,1235 1235,1280 1280,1340
Right. So we're going to
正确的。因此，我们必须建立一个我们维护的数据结构，使我们能够做到这一点。

2886
01:15:53,490 --> 01:15:54,285
0,105 105,255 255,450 450,615 615,795
have to build a data

2887
01:15:54,285 --> 01:15:56,685
0,335 355,755 1075,1365 1365,1655 2125,2400
structure that we maintain that

2888
01:15:56,685 --> 01:15:57,500
0,165 165,315 315,435 435,555 555,815
allows us to do this.|
|

2889
01:15:58,600 --> 01:15:59,610
0,305 305,500 500,665 665,830 830,1010
And as I said, we
就像我说的，我们想要的是保持原始值的顺序，这样压缩数据，压缩的字典代码，这些东西在词法上或与原始数据具有相同的顺序。

2890
01:15:59,610 --> 01:16:00,450
0,225 225,465 465,705 705,780 780,840
want something that's going to

2891
01:16:00,450 --> 01:16:01,935
0,150 150,540 540,735 735,1230 1230,1485
be preserve the ordering of

2892
01:16:01,935 --> 01:16:03,480
0,165 165,360 360,695 1045,1350 1350,1545
the original values, such that

2893
01:16:03,480 --> 01:16:04,890
0,210 210,765 765,1050 1050,1200 1200,1410
the compressed data, the compressed

2894
01:16:04,890 --> 01:16:07,155
0,420 420,920 1390,1740 1740,2040 2040,2265
dictionary codes, those things have

2895
01:16:07,155 --> 01:16:10,040
0,180 180,420 420,1025 1765,2595 2595,2885
the same ordering leographically or

2896
01:16:11,530 --> 01:16:12,680
0,305 305,455 455,620 620,845 845,1150
as the original data does.|
|

2897
01:16:14,350 --> 01:16:15,825
0,245 245,365 365,545 545,850 1140,1475
So going back here, right?
所以要回到这里，对吗？如果我再有一次，我有一堆我想要的名字。

2898
01:16:15,825 --> 01:16:16,755
0,195 195,330 330,570 570,810 810,930
If I have again, I

2899
01:16:16,755 --> 01:16:17,745
0,90 90,335 535,795 795,885 885,990
have a bunch of these

2900
01:16:17,745 --> 01:16:21,420
0,275 865,1170 1170,1410 1410,1745
names I want my.|
|

2901
01:16:21,420 --> 01:16:22,215
0,90 90,210 210,315 315,675 675,795
I want the dictionary that
我想要我生成的字典到代码，这样如果一个。

2902
01:16:22,215 --> 01:16:24,830
0,195 195,695 1375,1775 1855,2160 2160,2615
I'm generating to the codes

2903
01:16:26,080 --> 01:16:28,120
0,290 290,575 575,875 875,1180
such that if one.|
|

2904
01:16:28,120 --> 01:16:29,200
0,195 195,285 285,480 480,810 810,1080
If the original value comes
如果原始值在另一个版本之前的顺序是4，则值是字典代码也应该在它之前。

2905
01:16:29,200 --> 01:16:30,160
0,165 165,390 390,630 630,810 810,960
a four in the in

2906
01:16:30,160 --> 01:16:31,410
0,135 135,255 255,360 360,800 850,1250
the in the ordering before

2907
01:16:31,550 --> 01:16:33,355
0,290 290,500 500,820 960,1265 1265,1805
another version, value is dictionary

2908
01:16:33,355 --> 01:16:34,330
0,240 240,405 405,540 540,750 750,975
code should come before it

2909
01:16:34,330 --> 01:16:35,440
0,180 180,470
as well.|
|

2910
01:16:36,280 --> 01:16:37,875
0,230 230,320 320,425 425,670 1230,1595
So I would have my
所以我会让我的词典基本上是分类的。现在，这允许我执行这样的查询，即用户名为安迪、a和d，后跟通配符的SELECT星。

2911
01:16:37,875 --> 01:16:39,675
0,390 390,480 480,720 720,1235 1555,1800
dictionary is basically sorted. So

2912
01:16:39,675 --> 01:16:40,695
0,245 265,570 570,795 795,945 945,1020
now this allows me to

2913
01:16:40,695 --> 01:16:42,330
0,120 120,375 375,510 510,785 1315,1635
do queries like this select

2914
01:16:42,330 --> 01:16:43,365
0,210 210,360 360,555 555,765 765,1035
star from users were named

2915
01:16:43,365 --> 01:16:45,045
0,390 390,785 925,1215 1215,1395 1395,1680
like Andy, a and d,

2916
01:16:45,045 --> 01:16:47,120
0,315 315,630 630,885 885,1445
followed by the wildcard.|
|

2917
01:16:47,120 --> 01:16:48,740
0,150 150,410 850,1110 1110,1350 1350,1620
And so if we operate
因此，如果我们直接对压缩数据进行操作，我们可以将这个LIKE子句转换为BETWING子句。

2918
01:16:48,740 --> 01:16:50,600
0,210 210,405 405,675 675,980 1600,1860
directly on compressed data, we

2919
01:16:50,600 --> 01:16:52,660
0,240 240,615 615,1010 1330,1680 1680,2060
can convert this like clause

2920
01:16:53,010 --> 01:16:55,440
0,335 335,670 720,1070 1070,1450
into a between clause.|
|

2921
01:16:55,630 --> 01:16:56,490
0,275 275,395 395,530 530,710 710,860
Because we could look up
因为我们可以在字典中查找，只在字典、值上运行LIKE部分，找到匹配的值，找到匹配值的最小值和最大值，然后将LIKE重写为调用之间的。

2922
01:16:56,490 --> 01:16:58,730
0,120 120,225 225,770 1630,1935 1935,2240
in the dictionary, run the

2923
01:16:58,780 --> 01:17:00,255
0,350 350,700 900,1190 1190,1355 1355,1475
like portion just on the

2924
01:17:00,255 --> 01:17:03,015
0,455 535,935 1015,1415 1975,2370 2370,2760
dictionary, the values, find the

2925
01:17:03,015 --> 01:17:05,175
0,285 285,495 495,815 1525,1860 1860,2160
ones that match, find the

2926
01:17:05,175 --> 01:17:06,740
0,240 240,375 375,615 615,995 1165,1565
min and Max values for

2927
01:17:07,150 --> 01:17:09,345
0,290 290,820 1020,1420 1770,2030 2030,2195
the matching values, and then

2928
01:17:09,345 --> 01:17:10,770
0,375 375,525 525,705 705,1025 1105,1425
rewrite the like into a

2929
01:17:10,770 --> 01:17:12,100
0,240 240,560
between calls.|
|

2930
01:17:12,100 --> 01:17:13,320
0,90 90,255 255,540 540,870 870,1220
And then now writ through
然后现在趁我的专栏还在压缩的时候把它写下来。

2931
01:17:13,370 --> 01:17:14,755
0,305 305,610 840,1100 1175,1250 1250,1385
my column while it's still

2932
01:17:14,755 --> 01:17:15,980
0,425
compressed.|
|

2933
01:17:17,160 --> 01:17:18,125
0,305 305,470 470,590 590,740 740,965
Again, we can do this
同样，我们可以这样做，因为它是SQL，我们知道，我们知道它在WHERE子句中。它不是任意的python代码，也不是c代码。我们确切地知道WHERE子句想要做什么，我们可以聪明地、聪明地和转换。这为我们做了重写。

2934
01:17:18,125 --> 01:17:19,610
0,210 210,605 625,990 990,1305 1305,1485
because it's, it's sql, we

2935
01:17:19,610 --> 01:17:20,795
0,290 640,885 885,975 975,1125 1125,1185
know, we know it's in

2936
01:17:20,795 --> 01:17:22,025
0,90 90,240 240,575 745,1080 1080,1230
the where clause. It's not

2937
01:17:22,025 --> 01:17:23,405
0,480 480,855 855,1020 1020,1185 1185,1380
arbitrary python code or c

2938
01:17:23,405 --> 01:17:24,665
0,305 355,615 615,795 795,1065 1065,1260
code. We know exactly what

2939
01:17:24,665 --> 01:17:25,760
0,245 385,645 645,735 735,840 840,1095
the, what the where clause

2940
01:17:25,760 --> 01:17:27,245
0,225 225,360 360,620 970,1305 1305,1485
wants to do and we

2941
01:17:27,245 --> 01:17:28,415
0,75 75,240 240,525 525,870 870,1170
can be smart, intelligent and

2942
01:17:28,415 --> 01:17:31,745
0,180 180,455 2635,2910 2910,3030 3030,3330
convert. This do the rewriting

2943
01:17:31,745 --> 01:17:32,720
0,180 180,425
for us.|
|

2944
01:17:33,050 --> 01:17:34,530
0,275 275,500 500,785 785,1100 1100,1480
And again, you as the,
再说一次，不管你们是不是应用程序程序员，但是一些脚本程序，他们不需要知道下面到底发生了什么，对吗？他们只需编写LIKE子句，数据系统就可以变得智能，并为您重写它，从而获得更好的性能。

2945
01:17:34,820 --> 01:17:36,805
0,335 335,670 1110,1445 1445,1895 1895,1985
the, the application programmer or

2946
01:17:36,805 --> 01:17:37,585
0,120 120,255 255,390 390,585 585,780
not you guys, but some

2947
01:17:37,585 --> 01:17:39,100
0,345 345,605 955,1230 1230,1425 1425,1515
javascript program, they don't have

2948
01:17:39,100 --> 01:17:39,880
0,150 150,360 360,525 525,600 600,780
to know what the hell

2949
01:17:39,880 --> 01:17:41,590
0,210 210,390 390,555 555,800 1390,1710
going underneath the covers, right?

2950
01:17:41,590 --> 01:17:42,415
0,195 195,345 345,525 525,675 675,825
They just write the like

2951
01:17:42,415 --> 01:17:43,435
0,330 330,570 570,660 660,780 780,1020
clause and the data system

2952
01:17:43,435 --> 01:17:44,530
0,225 225,480 480,720 720,870 870,1095
can be can be smart

2953
01:17:44,530 --> 01:17:45,820
0,320 550,930 930,1050 1050,1155 1155,1290
and rewrite it for you

2954
01:17:45,820 --> 01:17:47,340
0,165 165,300 300,495 495,830
and get better performance.|
|

2955
01:17:49,970 --> 01:17:51,020
0,400
So.|
所以。|

2956
01:17:51,830 --> 01:17:53,260
0,335 335,575 575,845 845,1175 1175,1430
In some cases here you
在这里的某些情况下，你仍然必须这样做。问题是在这种情况下，您是否仍然执行原始专栏，因为我需要。

2957
01:17:53,260 --> 01:17:56,035
0,150 150,255 255,375 375,650 2530,2775
still have to do. The

2958
01:17:56,035 --> 01:17:57,565
0,135 135,285 285,420 420,695 1255,1530
question is whether you still

2959
01:17:57,565 --> 01:17:58,930
0,165 165,405 405,675 675,995 1135,1365
to perform original column in

2960
01:17:58,930 --> 01:17:59,785
0,120 120,315 315,540 540,705 705,855
this case here, since I

2961
01:17:59,785 --> 01:18:01,720
0,255 255,605
need the.|
|

2962
01:18:01,720 --> 01:18:02,940
0,150 150,285 285,555 555,885 885,1220
I need the output of
我需要名称属性的输出。我仍然要去撕开专栏，真正地看着它们。然而，在某些情况下，数据甚至可以更智能，它可以在不实际查看压缩数据的情况下回答查询。

2963
01:18:02,990 --> 01:18:05,370
0,400 480,880 1380,1780 1830,2105 2105,2380
of the of the name

2964
01:18:05,720 --> 01:18:07,165
0,490 810,1100 1100,1250 1250,1355 1355,1445
attribute. I still have to

2965
01:18:07,165 --> 01:18:08,310
0,245 295,615 615,750 750,870 870,1145
go rip through the column

2966
01:18:08,990 --> 01:18:10,470
0,400 720,980 980,1100 1100,1220 1220,1480
and actually look at them.

2967
01:18:10,880 --> 01:18:12,355
0,335 335,605 605,920 920,1265 1265,1475
In some cases, though, the

2968
01:18:12,355 --> 01:18:13,950
0,210 210,575 625,900 900,1155 1155,1595
data can be even smarter

2969
01:18:14,420 --> 01:18:15,550
0,230 230,320 320,455 455,730 750,1130
and it can answer queries

2970
01:18:15,550 --> 01:18:17,070
0,260 340,675 675,975 975,1230 1230,1520
without actually looking at the

2971
01:18:17,180 --> 01:18:18,660
0,440 440,760
compressed data.|
|

2972
01:18:18,670 --> 01:18:21,015
0,260 260,520 1140,1475 1475,1810 2010,2345
But just operate directly on
而是直接在词典上操作。

2973
01:18:21,015 --> 01:18:22,560
0,225 225,785
the dictionary.|
|

2974
01:18:23,100 --> 01:18:24,545
0,400 480,725 725,845 845,1100 1100,1445
So instead of saying select
因此，如果它是与用户不同的名称，而不是说SELECT NAME from USERS？

2975
01:18:24,545 --> 01:18:25,970
0,285 285,480 480,755 1045,1305 1305,1425
name from users, if it

2976
01:18:25,970 --> 01:18:27,250
0,240 240,555 555,810 810,1005 1005,1280
was distinct name from users?|
|

2977
01:18:28,220 --> 01:18:28,985
0,255 255,390 390,570 570,660 660,765
Where I don't need to
我不需要获得实际的双胞胎本身，我只需要获得唯一的实际值。然后，对于这里的查询，在转换为Better之后，或者将这里的通配符转换为字典值之后，我只需要知道字典中实际存在什么值。

2978
01:18:28,985 --> 01:18:30,185
0,135 135,330 330,525 525,885 885,1200
get the actual twoils themselves,

2979
01:18:30,185 --> 01:18:30,755
0,195 195,270 270,375 375,465 465,570
I just need to get

2980
01:18:30,755 --> 01:18:32,360
0,195 195,405 405,695 1255,1500 1500,1605
the actual values that are

2981
01:18:32,360 --> 01:18:34,880
0,260 1000,1400 1690,1980 1980,2205 2205,2520
unique. Then for this query

2982
01:18:34,880 --> 01:18:36,350
0,350 550,885 885,1095 1095,1245 1245,1470
here, after I do my

2983
01:18:36,350 --> 01:18:40,660
0,350 460,860 2770,3120 3120,3380 3910,4310
conversion to converting to between

2984
01:18:40,830 --> 01:18:43,235
0,395 395,680 680,970 1440,1840 1950,2405
or convert the this wildc

2985
01:18:43,235 --> 01:18:44,960
0,120 120,330 330,635 835,1235 1495,1725
card here into the the

2986
01:18:44,960 --> 01:18:46,670
0,285 285,560 1030,1320 1320,1530 1530,1710
dictionary values, I only need

2987
01:18:46,670 --> 01:18:47,915
0,195 195,450 450,705 705,945 945,1245
to know what what values

2988
01:18:47,915 --> 01:18:49,180
0,315 315,525 525,645 645,720 720,1265
actually exist in the dictionary.|
|

2989
01:18:49,760 --> 01:18:50,405
0,90 90,195 195,435 435,540 540,645
And I don't need to
我不需要使用DISTINCT来查看这个查询的实际列，假设我的表中只有四个名字，但我有十亿行，我只需要查看字典中的四行就可以回答它。

2990
01:18:50,405 --> 01:18:51,155
0,135 135,300 300,435 435,585 585,750
go look at the actual

2991
01:18:51,155 --> 01:18:52,810
0,275 595,855 855,1020 1020,1305 1305,1655
column for this query here

2992
01:18:53,370 --> 01:18:55,150
0,245 245,425 425,760 1320,1550 1550,1780
with a distinct, you know,

2993
01:18:55,440 --> 01:18:56,900
0,305 305,485 485,635 635,910 1140,1460
assuming I only have four

2994
01:18:56,900 --> 01:18:58,835
0,320 490,890 940,1245 1245,1550 1690,1935
names in my table, but

2995
01:18:58,835 --> 01:18:59,980
0,75 75,135 135,255 255,510 510,1145
I have a billion rows,

2996
01:19:00,210 --> 01:19:01,145
0,290 290,515 515,725 725,845 845,935
I only need to look

2997
01:19:01,145 --> 01:19:02,735
0,135 135,330 330,875 1045,1395 1395,1590
at four rows in the

2998
01:19:02,735 --> 01:19:04,440
0,405 405,570 570,750 750,1085
dictionary to answer it.|
|

2999
01:19:05,000 --> 01:19:06,430
0,305 305,610 900,1235 1235,1325 1325,1430
And again, I've said this
再说一次，我已经说过很多次了，我们可以这样做，因为数据，因为IS，负责压缩这个。

3000
01:19:06,430 --> 01:19:07,570
0,165 165,470 520,780 780,945 945,1140
multiple times, we can do

3001
01:19:07,570 --> 01:19:10,300
0,290 310,710 1360,1635 1635,1910 2440,2730
this because the data, because

3002
01:19:10,300 --> 01:19:11,830
0,135 135,380 460,860 1030,1350 1350,1530
the is, is responsible for

3003
01:19:11,830 --> 01:19:13,060
0,345 345,590
compressing this.|
|

3004
01:19:14,040 --> 01:19:15,605
0,400 450,950 950,1100 1100,1355 1355,1565
Now, parquet and, or one
现在，拼图和，或者说，他们有一个很大的限制是，当你使用他们的库和实用程序时，他们实际上不会向你公开词典。所以你不能做我在这里说的这个把戏。如果你使用偏执或右偏执或解压缩数据，当他把数据还给你时，你不能直接对压缩数据进行操作。

3005
01:19:15,605 --> 01:19:16,445
0,75 75,135 135,240 240,630 630,840
of the big limitations that

3006
01:19:16,445 --> 01:19:17,735
0,165 165,360 360,665 805,1065 1065,1290
they have is they don't

3007
01:19:17,735 --> 01:19:19,190
0,120 120,675 675,885 885,1275 1275,1455
actually expose the dictionary to

3008
01:19:19,190 --> 01:19:21,110
0,260 1000,1260 1260,1380 1380,1635 1635,1920
you when you use their

3009
01:19:21,110 --> 01:19:22,880
0,330 330,435 435,830 1390,1635 1635,1770
libraries and utilities. So you

3010
01:19:22,880 --> 01:19:23,810
0,255 255,390 390,585 585,765 765,930
can't do this trick I'm

3011
01:19:23,810 --> 01:19:24,425
0,90 90,210 210,360 360,495 495,615
talking about here. If you're

3012
01:19:24,425 --> 01:19:26,630
0,120 120,435 435,695 1105,1505 1765,2205
using parane or right parane

3013
01:19:26,630 --> 01:19:27,905
0,270 270,825 825,960 960,1125 1125,1275
or decompress the data, when

3014
01:19:27,905 --> 01:19:28,505
0,75 75,165 165,285 285,450 450,600
he gives it back to

3015
01:19:28,505 --> 01:19:29,750
0,135 135,315 315,725 775,1050 1050,1245
you, you can't operate directly

3016
01:19:29,750 --> 01:19:31,000
0,180 180,420 420,710
on compressed data.|
|

3017
01:19:31,200 --> 01:19:31,985
0,410 410,545 545,635 635,710 710,785
That's actually one of the
这实际上是我观点的最大局限之一。有两种格式。

3018
01:19:31,985 --> 01:19:34,265
0,245 415,1005 1005,1385 1735,2055 2055,2280
biggest limitations of my opinion.

3019
01:19:34,385 --> 01:19:35,680
0,75 75,195 195,575
There's two formats.|
|

3020
01:19:36,330 --> 01:19:37,505
0,320 320,530 530,755 755,995 995,1175
But again, other systems that
但同样，其他无需PAR即可执行本机压缩的系统能够、能够、能够做到这一点。

3021
01:19:37,505 --> 01:19:38,810
0,165 165,360 360,750 750,1050 1050,1305
do native compression without par

3022
01:19:38,810 --> 01:19:40,190
0,320 460,765 765,1020 1020,1245 1245,1380
or can, can, can do

3023
01:19:40,190 --> 01:19:41,160
0,135 135,410
this trick.|
|

3024
01:19:42,430 --> 01:19:43,545
0,275 275,440 440,725 725,995 995,1115
All right. So what is
好的。那么这张数据图表是什么呢？

3025
01:19:43,545 --> 01:19:45,840
0,105 105,270 270,575
this data chart?|
|

3026
01:19:45,840 --> 01:19:46,470
0,135 135,225 225,330 330,480 480,630
What is the data structure
我们的词典将使用什么数据结构？因此，最常见的方法将是非常简单的数组。

3027
01:19:46,470 --> 01:19:47,040
0,165 165,195 195,255 255,405 405,570
we're going to use for

3028
01:19:47,040 --> 01:19:48,600
0,105 105,590 1120,1365 1365,1440 1440,1560
our dictionary? So the most

3029
01:19:48,600 --> 01:19:49,350
0,240 240,480 480,630 630,705 705,750
common approach is going to

3030
01:19:49,350 --> 01:19:50,540
0,120 120,285 285,510 510,825 825,1190
be a really simple array.|
|

3031
01:19:51,200 --> 01:19:52,235
0,240 240,360 360,540 540,765 765,1035
And this works great if
如果文件是可使用的，这很有效，因为我只构建一次数组，并且我永远不会在适当的位置调整某些东西的大小，也不会移动东西，我只需在完成后就可以构建它。如果你需要一些动态的并且可以支持更新的东西，你需要一个哈希表或者一个A、B加树。这些是哈希表。我在那里是不是不那么常见了？

3032
01:19:52,235 --> 01:19:53,375
0,225 225,390 390,885 885,1020 1020,1140
the files areutable because I

3033
01:19:53,375 --> 01:19:54,365
0,150 150,285 285,450 450,750 750,990
build the array once and

3034
01:19:54,365 --> 01:19:55,450
0,105 105,270 270,420 420,765 765,1085
I never to resize things

3035
01:19:55,710 --> 01:19:57,605
0,350 350,590 590,785 785,1090 1590,1895
in certain things in place

3036
01:19:57,605 --> 01:19:59,470
0,305 1045,1290 1290,1395 1395,1560 1560,1865
and to move things around,

3037
01:19:59,610 --> 01:20:00,590
0,260 260,365 365,610 630,890 890,980
I can just build it

3038
01:20:00,590 --> 01:20:02,195
0,135 135,345 345,590 1240,1500 1500,1605
once I'm done. If you

3039
01:20:02,195 --> 01:20:03,320
0,120 120,300 300,630 630,915 915,1125
need something that's dynamic and

3040
01:20:03,320 --> 01:20:04,685
0,150 150,390 390,740 970,1230 1230,1365
can support updates, you need

3041
01:20:04,685 --> 01:20:05,705
0,165 165,315 315,600 600,825 825,1020
either a hash table or

3042
01:20:05,705 --> 01:20:06,995
0,105 105,255 255,465 465,785 1015,1290
A B plus tree. These

3043
01:20:06,995 --> 01:20:08,320
0,255 255,555 555,825 825,1005 1005,1325
are the hash table. Is

3044
01:20:08,580 --> 01:20:10,480
0,305 305,515 515,755 755,1210
I less common there?|
|

3045
01:20:10,700 --> 01:20:11,920
0,400 480,785 785,965 965,1085 1085,1220
Actually, these things are less
事实上，这些事情不太常见。大多数人做数组，并假设块将是，压缩的块将是不可变的，并且只有当我需要重建它的时候。然后我会重建阵列，然后我意识到我完了。时间到了，让我粗略地展示一下它的样子。因此，基本上您的列中有原始数据。所以你需要做的第一件事就是建立你的字典，然后，所有要做的就是你拥有的值的排序列表，然后。

3046
01:20:11,920 --> 01:20:12,940
0,270 270,525 525,705 705,870 870,1020
common. Most people do the

3047
01:20:12,940 --> 01:20:14,995
0,290 400,750 750,1100 1570,1845 1845,2055
array and assume the blocks

3048
01:20:14,995 --> 01:20:17,020
0,180 180,315 315,605 1555,1800 1800,2025
are going be, the compressed

3049
01:20:17,020 --> 01:20:17,515
0,210 210,345 345,405 405,435 435,495
blocks are going to be

3050
01:20:17,515 --> 01:20:18,940
0,545 565,840 840,1080 1080,1290 1290,1425
immutable and only if I

3051
01:20:18,940 --> 01:20:21,160
0,180 180,470 1510,1785 1785,2085 2085,2220
need to to rebuild it.

3052
01:20:21,160 --> 01:20:22,170
0,120 120,330 330,600 600,735 735,1010
Then I'll rebuild the array

3053
01:20:22,190 --> 01:20:22,915
0,230 230,350 350,485 485,605 605,725
and I realize I'm over.

3054
01:20:22,915 --> 01:20:23,670
0,180 180,300 300,375 375,480 480,755
Time is let me show

3055
01:20:24,110 --> 01:20:24,990
0,290 290,410 410,485 485,605 605,880
roughly what it looks like.

3056
01:20:25,790 --> 01:20:26,725
0,245 245,425 425,620 620,785 785,935
So basically you have your

3057
01:20:26,725 --> 01:20:27,720
0,180 180,435 435,600 600,720 720,995
original data in your column.

3058
01:20:28,400 --> 01:20:29,230
0,335 335,530 530,665 665,770 770,830
So the first thing you

3059
01:20:29,230 --> 01:20:30,370
0,45 45,105 105,270 270,590 880,1140
need to do is build

3060
01:20:30,370 --> 01:20:32,095
0,105 105,620 790,1080 1080,1370 1390,1725
your dictionary and again, all

3061
01:20:32,095 --> 01:20:32,890
0,300 300,375 375,465 465,630 630,795
that's going to be is

3062
01:20:32,890 --> 01:20:34,500
0,195 195,600 600,885 885,1245 1245,1610
a sorted list of the

3063
01:20:35,000 --> 01:20:36,180
0,275 275,410 410,665 665,920 920,1180
of the values you have

3064
01:20:36,620 --> 01:20:38,720
0,290 290,545 545,910
and then the.|
|

3065
01:20:38,720 --> 01:20:39,605
0,195 195,315 315,495 495,645 645,885
And he stored the length
他储存了一段时间。

3066
01:20:39,605 --> 01:20:42,080
0,270 270,575
of the.|
|

3067
01:20:42,230 --> 01:20:43,840
0,275 275,440 440,730 1200,1460 1460,1610
Of the string and then
字符串的偏移量，然后是字典代码，就是这个数组的偏移量。

3068
01:20:43,840 --> 01:20:45,565
0,290 460,855 855,1410 1410,1575 1575,1725
now the dictionary code is

3069
01:20:45,565 --> 01:20:46,180
0,105 105,195 195,330 330,480 480,615
going to be, is just

3070
01:20:46,180 --> 01:20:48,715
0,260 310,645 645,980 1690,2090 2230,2535
an offset into this array

3071
01:20:48,715 --> 01:20:49,640
0,305
here.|
|

3072
01:20:49,640 --> 01:20:51,005
0,180 180,315 315,615 615,920 970,1365
So my compressed data would
所以我的压缩数据应该是这样的，这些只是将字节偏移量设置到数组中。

3073
01:20:51,005 --> 01:20:52,790
0,270 270,420 420,695 1315,1605 1605,1785
look like this, and these

3074
01:20:52,790 --> 01:20:54,500
0,135 135,830 940,1200 1200,1485 1485,1710
are justsets the byte offset

3075
01:20:54,500 --> 01:20:56,420
0,290 490,795 795,1100
into the array.|
|

3076
01:20:56,420 --> 01:20:57,530
0,120 120,380 550,855 855,990 990,1110
And so now when I'm
所以现在当我做扫描时，我想说，如果我有第二个条目，它是17，我跳跃a乘以17的偏移量，我可以在里面查看。

3077
01:20:57,530 --> 01:20:58,565
0,105 105,285 285,590 640,915 915,1035
doing a scan and I

3078
01:20:58,565 --> 01:20:59,510
0,90 90,195 195,390 390,645 645,945
want to say, OK, if

3079
01:20:59,510 --> 01:21:05,060
0,380 1090,1490 4060,4460 4900,5265 5265,5550
I have the second entry,

3080
01:21:05,060 --> 01:21:06,605
0,270 270,530 940,1215 1215,1380 1380,1545
it's seventeen, I jump a

3081
01:21:06,605 --> 01:21:09,020
0,275 1015,1260 1260,1395 1395,1685 2155,2415
by offset at seventeen and

3082
01:21:09,020 --> 01:21:10,030
0,120 120,270 270,480 480,705 705,1010
I can look in the.|
|

3083
01:21:11,100 --> 01:21:12,170
0,225 225,465 465,690 690,810 810,1070
Down here I can look
在这里，我可以查看标题，然后告诉我后面的字符串有多大。

3084
01:21:12,220 --> 01:21:13,035
0,245 245,350 350,575 575,680 680,815
in the header and tell

3085
01:21:13,035 --> 01:21:14,055
0,275 325,630 630,795 795,900 900,1020
me how big is the

3086
01:21:14,055 --> 01:21:15,340
0,150 150,425
string afterwards.|
|

3087
01:21:15,500 --> 01:21:16,450
0,230 230,290 290,635 635,800 800,950
So the dictionary itself is
因此，字典本身实际上就是一个由这样的字节组成的数组。

3088
01:21:16,450 --> 01:21:17,545
0,195 195,375 375,570 570,855 855,1095
literally just an array packed

3089
01:21:17,545 --> 01:21:19,800
0,135 135,360 360,480 480,755
of bytes like that.|
|

3090
01:21:20,150 --> 01:21:21,500
0,400
Okay.|
好吧。|

3091
01:21:22,220 --> 01:21:23,635
0,260 260,455 455,790 1050,1295 1295,1415
All right, so to finish
好了，最后，你知道列上的这一行开始变得非常重要，我们会在期中考试之前主要讨论查询执行和其他事情时看到这一点，因为行存储和列存储系统之间的区别或区别再次影响到数据系统的所有其他部分，如何进行恢复，如何进行QU，如何运行事务，如何优化查询。所以现在理解这一点非常重要，我们将在整个学期中一次又一次地看到这两种方法之间的权衡。然后大多数数据系统要获得最佳的压缩比，你想要对自己进行自然的压缩，而字典编码是常见的一种，所以。

3092
01:21:23,635 --> 01:21:26,905
0,275 2515,2760 2760,2880 2880,3060 3060,3270
up, you know this row

3093
01:21:26,905 --> 01:21:27,700
0,180 180,330 330,510 510,690 690,795
over is column starting to

3094
01:21:27,700 --> 01:21:28,540
0,90 90,270 270,480 480,630 630,840
be really important and we'll

3095
01:21:28,540 --> 01:21:29,500
0,180 180,405 405,615 615,795 795,960
see this show up when

3096
01:21:29,500 --> 01:21:30,580
0,135 135,300 300,495 495,810 810,1080
we talk about query execution

3097
01:21:30,580 --> 01:21:33,580
0,165 165,330 330,650 2350,2685 2685,3000
and other things mostly before

3098
01:21:33,580 --> 01:21:35,095
0,300 300,465 465,860 1030,1320 1320,1515
before the midterm because again

3099
01:21:35,095 --> 01:21:36,625
0,305 595,870 870,1275 1275,1440 1440,1530
the, the distinction or the

3100
01:21:36,625 --> 01:21:37,540
0,225 225,465 465,585 585,765 765,915
difference between a row store

3101
01:21:37,540 --> 01:21:38,340
0,60 60,135 135,300 300,510 510,800
and a column store system

3102
01:21:39,140 --> 01:21:41,395
0,400 540,1250 1250,1630 1710,2030 2030,2255
have ramifications through throughout all

3103
01:21:41,395 --> 01:21:42,130
0,210 210,390 390,495 495,570 570,735
other parts of the data

3104
01:21:42,130 --> 01:21:43,600
0,320 640,885 885,990 990,1170 1170,1470
system, how you do recovery,

3105
01:21:43,600 --> 01:21:44,490
0,240 240,360 360,480 480,615 615,890
how you could do Qu,

3106
01:21:44,540 --> 01:21:45,400
0,245 245,320 320,395 395,605 605,860
how you want to run

3107
01:21:45,400 --> 01:21:47,275
0,290 1270,1515 1515,1605 1605,1695 1695,1875
transactions, how you want to

3108
01:21:47,275 --> 01:21:48,610
0,270 270,390 390,785 1015,1260 1260,1335
optimize your queries. And so

3109
01:21:48,610 --> 01:21:49,300
0,150 150,270 270,405 405,540 540,690
it's really important to understand

3110
01:21:49,300 --> 01:21:51,190
0,150 150,440 760,1160 1180,1590 1590,1890
this now and well well

3111
01:21:51,190 --> 01:21:52,330
0,360 360,570 570,690 690,1005 1005,1140
we'll see the tradeoffs between

3112
01:21:52,330 --> 01:21:53,395
0,105 105,240 240,530 610,900 900,1065
the two approaches again and

3113
01:21:53,395 --> 01:21:55,020
0,275 625,915 915,1080 1080,1260 1260,1625
again throughout the entire semester.

3114
01:21:55,820 --> 01:21:57,265
0,260 260,425 425,730 840,1160 1160,1445
And then most data systems

3115
01:21:57,265 --> 01:21:58,015
0,210 210,300 300,375 375,480 480,750
to get the best compression

3116
01:21:58,015 --> 01:21:58,810
0,270 270,495 495,615 615,720 720,795
ratio, you want to do

3117
01:21:58,810 --> 01:22:00,970
0,75 75,525 525,825 825,1160 1900,2160
it natively to yourself and

3118
01:22:00,970 --> 01:22:02,490
0,360 360,630 630,870 870,1185 1185,1520
dictionary coding is common one,

3119
01:22:03,230 --> 01:22:04,100
0,400
so.|
|

3120
01:22:04,320 --> 01:22:05,720
0,260 260,380 380,640 840,1175 1175,1400
I showed this three, three
我在三三节课前就展示过了。数据存储存在两个问题。首先，我们如何在磁盘上表示数据。到目前为止，我们已经介绍了这一点。那么，从下周开始，当我们将事物带入记忆时，我们将如何处理它呢？我们怎么储存它呢？当我们进行更改时，如何安全地写回内容？

3121
01:22:05,720 --> 01:22:07,535
0,360 360,650 1150,1380 1380,1575 1575,1815
lectures ago. There was two

3122
01:22:07,535 --> 01:22:08,840
0,165 165,300 300,465 465,785 1015,1305
problems in data storage. First,

3123
01:22:08,840 --> 01:22:09,770
0,150 150,255 255,345 345,590 640,930
how we can represent data

3124
01:22:09,770 --> 01:22:11,195
0,165 165,650 700,1050 1050,1215 1215,1425
on disk. We've covered that

3125
01:22:11,195 --> 01:22:13,895
0,210 210,515 1195,1500 1500,1805 2365,2700
so far. So starting next

3126
01:22:13,895 --> 01:22:16,325
0,335 745,1145 1825,2085 2085,2235 2235,2430
week now when we bring

3127
01:22:16,325 --> 01:22:17,930
0,195 195,390 390,695 1285,1530 1530,1605
things into memory, what do

3128
01:22:17,930 --> 01:22:18,680
0,90 90,210 210,315 315,540 540,750
we do with it? How

3129
01:22:18,680 --> 01:22:19,565
0,60 60,180 180,360 360,645 645,885
do we store it? And

3130
01:22:19,565 --> 01:22:20,090
0,90 90,150 150,225 225,360 360,525
how do we write things

3131
01:22:20,090 --> 01:22:21,965
0,180 180,390 390,710 1210,1610 1630,1875
back out safely when we

3132
01:22:21,965 --> 01:22:24,120
0,150 150,455
make changes?|
|

3133
01:22:24,220 --> 01:22:45,020
0,335 335,530 530,20255 20255,20510 20510,20800
Alright hit itfuck hook up
好的，他妈的，每克28克，这取决于它是不是起来了你没有听到暴徒的声音，但你还是闭嘴了我用下面的母夹打你，告诉你，抬头告诉我，让我看看你的脸，我有一块黑板，敲打着V型，找不到ST风格的，就像大便一样，你不能在多米尼加人那里系花边，或者你们叫我多米尼加黑色的黑色皮革黑苏木，我全黑的，脏的，把你送到每一个大门，你得到你的鼓励，试图滑冰，这是你的第一个错误为了那个蛋糕，你的家人看着你的体重，我的体重，网络状态，我是如何生活的，告诉我生活的恩典。

3134
01:22:45,130 --> 01:22:46,830
0,530 530,740 740,1090 1140,1475 1475,1700
28 a gram depending on

3135
01:22:46,830 --> 01:22:48,270
0,165 165,480 480,830 970,1215 1215,1440
if it's up you ain't

3136
01:22:48,270 --> 01:22:49,515
0,120 120,255 255,450 450,770 940,1245
hear the mob yet still

3137
01:22:49,515 --> 01:22:50,565
0,195 195,375 375,555 555,780 780,1050
got your shut up I

3138
01:22:50,565 --> 01:22:51,480
0,255 255,390 390,510 510,675 675,915
smack you with the bottom

3139
01:22:51,480 --> 01:22:52,575
0,330 330,600 600,750 750,915 915,1095
mother clip to tell you

3140
01:22:52,575 --> 01:22:53,715
0,195 195,485 595,885 885,1035 1035,1140
look up show me what

3141
01:22:53,715 --> 01:22:54,720
0,135 135,360 360,645 645,855 855,1005
it sa at for a

3142
01:22:54,720 --> 01:22:55,905
0,180 180,390 390,660 660,960 960,1185
blow your face back I

3143
01:22:55,905 --> 01:22:57,225
0,150 150,315 315,780 780,1080 1080,1320
gotta a blackboard taps the

3144
01:22:57,225 --> 01:22:58,665
0,270 270,660 660,870 870,1175 1225,1440
ve can't trace that St

3145
01:22:58,665 --> 01:22:59,745
0,105 105,270 270,510 510,825 825,1080
style is like t for

3146
01:22:59,745 --> 01:23:00,915
0,255 255,480 480,795 795,990 990,1170
poop you can't lace that

3147
01:23:00,915 --> 01:23:02,400
0,150 150,300 300,1080 1080,1320 1320,1485
at the Dominican or you

3148
01:23:02,400 --> 01:23:04,155
0,255 255,510 510,675 675,1410 1410,1755
guys call me Dominican black

3149
01:23:04,155 --> 01:23:05,850
0,435 435,690 690,1095 1095,1380 1380,1695
sclly black leather black Su

3150
01:23:05,850 --> 01:23:07,485
0,555 555,750 750,990 990,1320 1320,1635
timberins my all black dirty

3151
01:23:07,485 --> 01:23:08,400
0,225 225,435 435,630 630,795 795,915
eight to send you to

3152
01:23:08,400 --> 01:23:09,735
0,150 150,420 420,770 940,1200 1200,1335
the per gates you get

3153
01:23:09,735 --> 01:23:10,905
0,495 495,660 660,810 810,1005 1005,1170
youravat trying to skate and

3154
01:23:10,905 --> 01:23:12,405
0,210 210,330 330,600 600,995 1195,1500
that's your first mistake I

3155
01:23:12,405 --> 01:23:13,410
0,180 180,435 435,660 660,810 810,1005
in line for that cake

3156
01:23:13,410 --> 01:23:14,540
0,165 165,435 435,705 705,855 855,1130
your family see your weight

3157
01:23:14,620 --> 01:23:16,275
0,400 510,845 845,1100 1100,1415 1415,1655
my have weight the the

3158
01:23:16,275 --> 01:23:18,150
0,225 225,605 1165,1440 1440,1665 1665,1875
web state how I'm living

3159
01:23:18,150 --> 01:23:19,520
0,255 255,495 495,720 720,990 990,1370
to tell I living grace.|
|
