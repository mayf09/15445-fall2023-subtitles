1
00:00:32,200 --> 00:00:34,040
你这周末有场演出，是吗？

2
00:00:35,650 --> 00:00:50,130
这是真的吗？

3
00:00:50,130 --> 00:00:53,780
我们在星期三的课堂上宣布。

4
00:00:54,040 --> 00:00:55,860
我们有很多事情要讨论，

5
00:00:55,860 --> 00:00:56,840
所以，让我们直接开始吧。

6
00:00:57,700 --> 00:01:00,200
所以在你们的[]，

7
00:01:00,360 --> 00:01:02,900
项目 #0 昨晚就该交了，

8
00:01:03,370 --> 00:01:06,230
我们还没有完成，也没有看到每个人的结果，

9
00:01:06,340 --> 00:01:08,790
我想我们有大约 150 人完成了，

10
00:01:08,790 --> 00:01:09,590
这很好，

11
00:01:10,810 --> 00:01:13,280
项目 #1 已经放出了，截至到，

12
00:01:14,050 --> 00:01:16,290
抱歉，家庭作业 #1 已经放出一段时间了，

13
00:01:16,290 --> 00:01:19,070
但我们将最后期限推迟到了 15 号，

14
00:01:19,660 --> 00:01:20,450
也就是四天后，

15
00:01:21,130 --> 00:01:23,090
所以这会在 Gradescope 反应出来，

16
00:01:23,260 --> 00:01:26,570
然后项目 #1 已经放出，将在 10 月 1 日截止。

17
00:01:27,340 --> 00:01:28,550
任何关于家庭作业 #1 的问题，

18
00:01:29,740 --> 00:01:33,015
知道有人在 Piazza 上张贴了关于项目 #1 的帖子，

19
00:01:33,015 --> 00:01:34,790
排行榜的作业还没有工作，

20
00:01:35,380 --> 00:01:36,800
我们仍然，我们正在解决这个问题，

21
00:01:36,970 --> 00:01:42,000
我们会在本周晚些时候把它推送到 GitHub 上，

22
00:01:42,230 --> 00:01:44,500
然后我将在周三讨论排行榜是什么，

23
00:01:44,500 --> 00:01:47,490
它的含义是什么，为什么它很重要。

24
00:01:49,550 --> 00:01:53,130
好的，另外一件事，是额外的事情，

25
00:01:53,450 --> 00:01:55,950
如果你想学习我们在这门课上讨论的以外的东西，

26
00:01:56,330 --> 00:01:59,790
接下来会有几场关于数据库的讨论，

27
00:02:00,230 --> 00:02:02,005
所以今天课后的 4:30 ，

28
00:02:02,005 --> 00:02:04,740
我们有 Qdrant 的人，来自德国，

29
00:02:05,060 --> 00:02:06,775
它们是向量数据库之一，

30
00:02:06,775 --> 00:02:10,530
针对 LLM 或 ChatGBT 之类的设置，

31
00:02:10,670 --> 00:02:12,810
他们将谈论他们系统的内部结构，

32
00:02:13,250 --> 00:02:14,910
这将是在 4:30 ，通过 Zoom 。

33
00:02:15,380 --> 00:02:16,885
明天下午 6 点，

34
00:02:16,885 --> 00:02:20,700
Databricks 的人在盖茨大楼的某个地方开展讲座，

35
00:02:20,870 --> 00:02:21,870
这是一场招聘讲座，

36
00:02:21,890 --> 00:02:23,790
但这些可能会满足你的需求，

37
00:02:24,320 --> 00:02:26,280
然后你可以与他们谈论在那里找到工作的问题，

38
00:02:27,350 --> 00:02:32,160
在过去的两三年里， Databricks 录取了几乎所有我最好的学生，

39
00:02:33,170 --> 00:02:34,380
他们都去了 Databricks ，

40
00:02:34,460 --> 00:02:36,570
我在 7 月份在那里，他们都做得很好，

41
00:02:37,730 --> 00:02:39,660
他们有很多钱，但没有给我们任何钱。

42
00:02:42,560 --> 00:02:44,070
然后 OtterTune 是我的初创公司，

43
00:02:44,450 --> 00:02:48,580
我以前的博士生，也是联合创始人， Dana Van Aken ，

44
00:02:48,580 --> 00:02:49,750
她将发表演讲，

45
00:02:49,880 --> 00:02:54,895
我们如何利用机器学习来优化数据库系统， Postgres MySQL ，

46
00:02:54,895 --> 00:02:55,180
在下周。

47
00:02:55,180 --> 00:02:55,470
是的。

48
00:02:55,550 --> 00:02:57,270
我们在哪里找到关于地点的信息？

49
00:02:59,060 --> 00:03:02,370
所以我的演讲， Qdrant 这个， OtterTune 这个，是在 Zoom 上，

50
00:03:02,600 --> 00:03:03,865
然后如果你打开幻灯片，

51
00:03:03,865 --> 00:03:06,060
这里的链接会把你带到日程，

52
00:03:07,190 --> 00:03:07,860
盖茨大楼的某个地方，

53
00:03:09,100 --> 00:03:10,160
对于 Databricks 这个。

54
00:03:10,930 --> 00:03:11,330
是的。

55
00:03:12,460 --> 00:03:12,860
还有其他问题吗，

56
00:03:13,900 --> 00:03:14,700
这些也是可选的，

57
00:03:14,700 --> 00:03:16,490
如果你想要超越课程中要谈论的东西。

58
00:03:16,690 --> 00:03:18,195
我喜欢这种演讲的地方是，

59
00:03:18,195 --> 00:03:20,750
即使你现在什么都不懂，

60
00:03:21,460 --> 00:03:23,600
我们整个学期都在谈论这些话题，

61
00:03:23,770 --> 00:03:25,665
然后你就会意识到我并没有疯，

62
00:03:25,665 --> 00:03:27,375
好吧，我是疯了，但不是那么疯狂，

63
00:03:27,375 --> 00:03:28,875
我不是在胡编乱造，

64
00:03:28,875 --> 00:03:30,860
这就是我们在本学期要讨论的内容，

65
00:03:31,150 --> 00:03:34,430
你应该知道适用于建立真正的系统。

66
00:03:36,770 --> 00:03:39,060
好的，上一节课我们谈到了，

67
00:03:40,670 --> 00:03:44,185
你们会有什么样的框架的初始设置，

68
00:03:44,185 --> 00:03:47,110
描述我们如何建立一个数据管理系统，

69
00:03:47,110 --> 00:03:51,600
我们讨论了它如何成为面向磁盘的架构，

70
00:03:52,430 --> 00:03:59,155
其中系统中的所有组件都基于这一关键前提，

71
00:03:59,155 --> 00:04:01,560
数据库的主要搜索位置，

72
00:04:01,670 --> 00:04:03,180
当它处于静止状态时，

73
00:04:03,500 --> 00:04:07,315
将位于某些非易失性磁盘上，

74
00:04:07,315 --> 00:04:09,030
SSD ，旋转磁盘硬盘，并不重要。

75
00:04:09,520 --> 00:04:12,210
系统的组件实际上是，

76
00:04:12,620 --> 00:04:15,625
在磁盘和内存之间来回移动数据，

77
00:04:15,625 --> 00:04:16,830
因为它是一个冯·诺伊曼架构，

78
00:04:16,880 --> 00:04:20,710
当它处于静止状态时，你不能对其进行操作。

79
00:04:20,710 --> 00:04:24,720
所以，这就是我们试图实现的总体目标。

80
00:04:24,950 --> 00:04:26,580
当然，现在由于磁盘速度很慢，

81
00:04:26,930 --> 00:04:29,070
我们需要使用一系列技巧和其他技术，

82
00:04:29,240 --> 00:04:33,720
来隐藏磁盘访问的停滞，

83
00:04:34,130 --> 00:04:35,760
通过最大化顺序 IO 的数量。

84
00:04:36,380 --> 00:04:38,395
我们今天一开始就会看到，

85
00:04:38,395 --> 00:04:39,670
今天我们将讨论不同的方法，

86
00:04:39,670 --> 00:04:41,875
这是我们上一节课讨论的另一种方法，

87
00:04:41,875 --> 00:04:43,590
它试图最大化顺序 IO 。

88
00:04:44,610 --> 00:04:46,655
然后，还会有其他东西，比如过滤器和索引，

89
00:04:46,655 --> 00:04:48,875
这是一种减少必须实际查看的数据量的方法，

90
00:04:48,875 --> 00:04:49,690
当我们在运行查询时。

91
00:04:50,540 --> 00:04:53,550
然后我们还讨论了一种面向页面的存储方案，

92
00:04:54,440 --> 00:04:55,590
插槽页面架构，

93
00:04:55,850 --> 00:05:02,100
它允许我们在堆文件中存储任意长度、可变长度的 tuple ，

94
00:05:02,510 --> 00:05:06,900
然后我们可以根据需要扩展 tuple 的大小，

95
00:05:07,040 --> 00:05:09,480
根据它是否适合页面。

96
00:05:10,000 --> 00:05:10,260
好的。

97
00:05:12,240 --> 00:05:15,310
所以我会说，我们上次所描述的是，

98
00:05:15,510 --> 00:05:18,580
我将粗略地称为面向 tuple 的存储方案，

99
00:05:19,340 --> 00:05:20,320
这实际上意味着，

100
00:05:20,320 --> 00:05:21,940
这个系统实际上是关于，

101
00:05:21,940 --> 00:05:24,220
我有一个 tuple ，我要把它放在某个地方，

102
00:05:24,220 --> 00:05:28,825
页面的布局基于这一点，

103
00:05:28,825 --> 00:05:30,810
我有一个 tuple ，让我把它存储起来。

104
00:05:31,800 --> 00:05:33,310
所以，在这个架构中，

105
00:05:33,420 --> 00:05:34,870
如果你想要插入一个新的 tuple ，

106
00:05:35,310 --> 00:05:36,250
你可以做的方法是，

107
00:05:36,420 --> 00:05:37,780
你可以查看页面目录，

108
00:05:38,040 --> 00:05:40,870
在堆文件中找到某个位置，

109
00:05:41,190 --> 00:05:42,400
一个有空闲插槽的页面，

110
00:05:43,020 --> 00:05:45,005
我们说页面目录维护了元数据，

111
00:05:45,005 --> 00:05:46,510
关于哪些空间是可用的。

112
00:05:47,850 --> 00:05:50,650
然后一旦我们有了，我们想要插入 tuple 的页面，

113
00:05:51,090 --> 00:05:53,660
如果这不是内存，

114
00:05:53,660 --> 00:05:55,390
他们就必须去磁盘获取它，

115
00:05:55,530 --> 00:05:56,585
我们将在下周讨论，

116
00:05:56,585 --> 00:05:57,095
我们如何做到，

117
00:05:57,095 --> 00:05:59,290
但是想想读取一个文件，带入内存，

118
00:05:59,940 --> 00:06:01,535
一旦我们有了那个页面，

119
00:06:01,535 --> 00:06:02,860
我们就去查看那个 slot array ，

120
00:06:03,240 --> 00:06:06,370
我们说，可以存储这个 tuple 的下一个空闲插槽是什么，

121
00:06:06,960 --> 00:06:10,000
更新 slot array ，将 tuple 放入页面中，

122
00:06:10,350 --> 00:06:11,110
然后我们就完成了。

123
00:06:12,900 --> 00:06:15,610
在这个环境中更新 tuple 基本上是相同的，

124
00:06:16,650 --> 00:06:19,990
我们将有一些方法来获得 tuple 的 record ID ，

125
00:06:20,610 --> 00:06:24,480
我们说这通常是页面 ID 和偏移量或插槽编号，

126
00:06:24,480 --> 00:06:26,020
忽略我们如何获得它，

127
00:06:26,610 --> 00:06:28,490
索引将为我们做什么，

128
00:06:28,490 --> 00:06:30,640
忽略它，假设我们可以做到，

129
00:06:30,930 --> 00:06:32,495
我们再一次去页面目录，

130
00:06:32,495 --> 00:06:33,550
找到这个页面的位置，

131
00:06:33,870 --> 00:06:35,690
如果它在内存中，我们就没问题了，

132
00:06:35,690 --> 00:06:37,150
如果没有，我们就得去磁盘上拿到它，

133
00:06:37,470 --> 00:06:39,850
然后查看页面和 slot array ，找到偏移量，

134
00:06:39,990 --> 00:06:41,795
然后如果是新的 tuple ，

135
00:06:41,795 --> 00:06:44,080
我们试图安装的更新 tuple ，

136
00:06:44,600 --> 00:06:47,950
如果它与原始 tuple ，存在的 tuple 大小相同，

137
00:06:48,090 --> 00:06:49,180
那么我们只需覆盖它，

138
00:06:49,380 --> 00:06:52,550
如果没有，那么你可能需要找到另一个可以容纳它的页面，

139
00:06:52,550 --> 00:06:55,350
那么我们正在查看的页面中没有空间。

140
00:06:56,030 --> 00:07:03,000
这就是堆文件使用面向页面架构的核心理念，

141
00:07:03,140 --> 00:07:04,590
这是基于 tuple 的，

142
00:07:04,790 --> 00:07:06,930
这基本上就是任何系统的实际运作方式。

143
00:07:09,120 --> 00:07:10,270
那么，这有什么问题呢，

144
00:07:12,070 --> 00:07:13,430
我们在上一节课中，谈到了一些内容，

145
00:07:18,610 --> 00:07:19,310
它是高效的吗，

146
00:07:22,580 --> 00:07:23,640
对于读取，可能是，

147
00:07:24,620 --> 00:07:26,350
因为如果我需要整个 tuple ，

148
00:07:26,350 --> 00:07:27,840
我会去一个页面拿到它，

149
00:07:28,040 --> 00:07:28,710
这是可以的，

150
00:07:29,450 --> 00:07:30,775
但是如果我开始更新某些内容，

151
00:07:30,775 --> 00:07:33,030
我开始写入操作，做插入、更新、删除，

152
00:07:33,410 --> 00:07:35,940
我的页面可能会变得支离破碎，

153
00:07:36,620 --> 00:07:38,630
我可能有一些页面没有被充分利用，

154
00:07:38,630 --> 00:07:42,035
这意味着我有一点空闲空间，

155
00:07:42,035 --> 00:07:43,480
无法容纳任何新的 tuple ，

156
00:07:44,430 --> 00:07:45,640
它不够大放下一个新的 tuple ，

157
00:07:45,900 --> 00:07:47,645
所以我不能用它，它就浪费了，

158
00:07:47,645 --> 00:07:51,040
它就在那里，

159
00:07:51,570 --> 00:07:53,920
甚至在之前，如果我运行那个空间，

160
00:07:54,000 --> 00:07:55,810
如果我必须插入一个新的 tuple ，

161
00:07:56,220 --> 00:07:57,080
我必须分配，

162
00:07:57,080 --> 00:07:58,505
假设我的 tuple 什么都没有，

163
00:07:58,505 --> 00:07:59,615
我把它插入到 tuple 中，

164
00:07:59,615 --> 00:08:00,370
我分配一个页面，

165
00:08:00,660 --> 00:08:02,140
我在那个页面中插入一个 tuple ，

166
00:08:02,460 --> 00:08:03,850
那一页上没有其他东西了，

167
00:08:04,500 --> 00:08:06,965
同样，根据我的页面大小，

168
00:08:06,965 --> 00:08:09,070
每个系统的大小可能会有所不同，

169
00:08:09,660 --> 00:08:11,410
有一大堆空闲空间没有被使用。

170
00:08:13,960 --> 00:08:16,280
我们面临的下一个挑战是无用的磁盘 I/O ，

171
00:08:16,660 --> 00:08:17,955
所以，如果我更新一个 tuple ，

172
00:08:17,955 --> 00:08:18,780
如果它不在内存中，

173
00:08:18,780 --> 00:08:20,120
我必须去磁盘上取回它，

174
00:08:20,320 --> 00:08:21,660
但如果在那个页面的那一边，

175
00:08:21,660 --> 00:08:24,260
我能得到什么，

176
00:08:24,260 --> 00:08:25,700
我们不是每页存储一个 tuple ，

177
00:08:25,700 --> 00:08:30,940
我的意思是，你可以，但你通常不想这么做，

178
00:08:31,230 --> 00:08:33,890
所以，现在如果我要去更新一个页面，抱歉，一个 tuple ，

179
00:08:33,890 --> 00:08:36,160
我必须获取整个页面，并带来一堆数据，

180
00:08:36,420 --> 00:08:38,140
这可能甚至不是我需要的，

181
00:08:38,370 --> 00:08:40,060
因为还有一堆其他的 tuple 我没有更新。

182
00:08:41,670 --> 00:08:42,910
当我要做写入的时候也是一样的，

183
00:08:43,950 --> 00:08:45,365
如果我只更新一个 tuple ，

184
00:08:45,365 --> 00:08:47,680
我必须把这一页中的 20 个 tuple 带入内存中，

185
00:08:47,880 --> 00:08:49,480
现在我要把那 20 个 tuple 写回去。

186
00:08:52,470 --> 00:08:53,650
最后一个问题是，

187
00:08:53,790 --> 00:08:55,930
我们可能会得到大量随机磁盘 I/O ，

188
00:08:56,340 --> 00:09:00,610
再说一次，一种[回避的]答案，

189
00:09:00,690 --> 00:09:03,580
对于人们问的，这个更有效率，或者哪种方法更好，

190
00:09:03,900 --> 00:09:06,985
答案是，它总是取决于数据库。

191
00:09:06,985 --> 00:09:10,470
所以，如果你的工作负载是每次查询只更新一个 tuple ，

192
00:09:10,790 --> 00:09:12,840
那么这个架构可能并不是那么糟糕，

193
00:09:13,340 --> 00:09:15,600
但如果我一次更新 20 个 tuple ，

194
00:09:16,130 --> 00:09:18,150
而这 20 个 tuple 在 20 个单独的页面中，

195
00:09:18,770 --> 00:09:21,930
我必须读取 20 个单独的页面，从磁盘到内存，

196
00:09:22,160 --> 00:09:23,035
我必须更新它们，

197
00:09:23,035 --> 00:09:27,120
我必须写出 20 个不同的页面到内存中，从内存到磁盘，

198
00:09:27,260 --> 00:09:28,380
这是随机 I/O ，

199
00:09:29,060 --> 00:09:30,000
速度会更慢。

200
00:09:32,910 --> 00:09:35,620
然后不一定是架构本身的问题，

201
00:09:35,880 --> 00:09:38,800
但情况可能是，我们在一个环境中操作，

202
00:09:39,180 --> 00:09:41,110
我们不能进行就地更新，

203
00:09:41,820 --> 00:09:43,570
我们认为可以在页面架构中做的，

204
00:09:44,560 --> 00:09:47,450
这意味着我不能获取磁盘中的页面，将其放入内存，

205
00:09:48,010 --> 00:09:50,480
进行更新，然后将其写回原来的位置，

206
00:09:52,585 --> 00:09:55,850
你不能在某些云存储系统中这样做，

207
00:09:56,170 --> 00:09:58,500
S3 ，你可以使用版本控制来解决这个问题，

208
00:09:58,500 --> 00:10:02,030
但我不能在一些云数据库系统就地更新，

209
00:10:02,260 --> 00:10:05,775
Hadoop 文件系统，这那么常见，

210
00:10:05,775 --> 00:10:07,170
但这是另一个很好的例子，

211
00:10:07,170 --> 00:10:08,955
它是分布式文件系统，

212
00:10:08,955 --> 00:10:10,800
我同样不能进行就地更新，

213
00:10:10,800 --> 00:10:11,900
我只能做追加。

214
00:10:13,030 --> 00:10:16,370
所以这个面向 tuple 的页面架构在这个环境中是不起作用的，

215
00:10:16,420 --> 00:10:17,360
因为我不能做，

216
00:10:17,710 --> 00:10:19,670
我不能修改一个页面，然后把它写回我得到的地方。

217
00:10:22,130 --> 00:10:24,100
所以，这就是为什么我们需要研究潜在的替代方法，

218
00:10:24,100 --> 00:10:26,370
特别是我刚才谈到的所有问题，

219
00:10:27,110 --> 00:10:30,120
这些问题将通过日志结构存储方案来解决。

220
00:10:31,160 --> 00:10:34,900
除了堆文件页面架构，

221
00:10:35,340 --> 00:10:39,040
日志结构存储可能是人们在数据库系统中采用的第二种最常见的方法，

222
00:10:39,330 --> 00:10:40,720
这在今天可能更加常见，

223
00:10:40,860 --> 00:10:44,270
因为嵌入式存储管理器，比如 RocksDB ，

224
00:10:44,270 --> 00:10:45,400
它们是日志结构的。

225
00:10:45,940 --> 00:10:48,000
你见过使用 RocksDB 的数据库系统吗，

226
00:10:48,230 --> 00:10:49,570
它们本质上是日志结构，

227
00:10:49,570 --> 00:10:51,000
因为 Rocksdb 是日志结构的。

228
00:10:52,550 --> 00:10:53,880
然后我们将讨论另一种方法，

229
00:10:53,960 --> 00:10:54,940
不完全是日志结构，

230
00:10:54,940 --> 00:10:56,260
它是这两者的某种融合，

231
00:10:56,260 --> 00:10:57,450
也就是面向索引的存储，

232
00:10:58,220 --> 00:11:00,210
这就是 MySQL 和 SQLite 以及其他所使用的。

233
00:11:00,440 --> 00:11:01,770
然后，我们将结束讨论，

234
00:11:01,910 --> 00:11:04,950
如何实际表示 tuple 中的属性数据。

235
00:11:06,280 --> 00:11:09,420
同样，我们研究文件的样子，页面的样子，

236
00:11:09,420 --> 00:11:10,490
我们仍然在那个世界里，

237
00:11:10,690 --> 00:11:11,910
然后我们会花更多的时间来讨论，

238
00:11:11,910 --> 00:11:13,290
实际的单个 tuple 是什么样子的，

239
00:11:13,290 --> 00:11:14,900
在单个 tuple 中的值。

240
00:11:15,800 --> 00:11:16,200
好的？

241
00:11:17,840 --> 00:11:18,370
好的。

242
00:11:19,960 --> 00:11:23,570
好的，所以日志结构存储是一个古老的想法，

243
00:11:24,850 --> 00:11:28,190
它与日志结构文件系统有松散的关系，

244
00:11:28,210 --> 00:11:29,970
（日志文件系统）早了大约十年，

245
00:11:29,970 --> 00:11:31,970
日志结构文件系统，大约在 1980 年代，

246
00:11:32,320 --> 00:11:37,280
日志结构存储最早是在 90 年代中期提出的，

247
00:11:38,260 --> 00:11:39,180
实际上，在课本中，

248
00:11:39,180 --> 00:11:40,700
他们称为日志结构合并树，

249
00:11:41,470 --> 00:11:44,325
我不打算描述日志结构合并树是什么样子的，

250
00:11:44,325 --> 00:11:48,210
因为我认为你不需要知道它的树部分的细节。

251
00:11:48,950 --> 00:11:53,500
所以我将描述基本上相同的想法，但没有引入树，

252
00:11:53,500 --> 00:11:55,200
因为这会使事情变得更加复杂。

253
00:11:56,570 --> 00:11:58,560
但高层次的想法才是我所关心的，

254
00:11:58,820 --> 00:11:59,970
是我想让你们明白的。

255
00:12:01,040 --> 00:12:03,060
所以，日志结构存储的基本思想是，

256
00:12:03,890 --> 00:12:05,550
不是存储单独的 tuple ，

257
00:12:06,140 --> 00:12:10,470
我们将维护对 tuple 修改的日志记录，

258
00:12:11,560 --> 00:12:14,115
我认为这是一个键值存储，键值系统，

259
00:12:14,115 --> 00:12:17,510
所以我要做一些操作， PUT 和 DELETE ，

260
00:12:18,330 --> 00:12:21,190
然后我将有一个键值对，

261
00:12:21,270 --> 00:12:23,620
其中的键对应于某个 tuple 的标识符，

262
00:12:24,090 --> 00:12:25,780
我们不能使用以前使用的 record ID ，

263
00:12:25,800 --> 00:12:26,870
因为我们不会有页面，

264
00:12:26,870 --> 00:12:28,150
我们不会有所有的[集合]和插槽，

265
00:12:28,200 --> 00:12:29,200
所以它不会是那样，

266
00:12:29,610 --> 00:12:31,895
但它会是一些键标识符，

267
00:12:31,895 --> 00:12:35,470
然后有效负载将是实际的 tuple 本身，

268
00:12:35,850 --> 00:12:38,350
我试图在 PUT 中安装。

269
00:12:39,730 --> 00:12:43,700
所以，当应用程序插入数据进行更改时，

270
00:12:44,350 --> 00:12:47,030
我们将把新的日志条目追加到内存缓冲区中，

271
00:12:47,850 --> 00:12:49,840
按照它们到达的顺序，

272
00:12:50,400 --> 00:12:52,480
然后在某个时候缓冲区会变满，

273
00:12:52,740 --> 00:12:54,070
我们要把它写到磁盘上。

274
00:12:56,380 --> 00:12:57,170
很简单，对吧？

275
00:12:58,550 --> 00:12:59,820
好的，让我们来看一个例子，

276
00:12:59,930 --> 00:13:03,870
我们要做的只有两个操作， PUT 和 DELETE ，

277
00:13:04,160 --> 00:13:06,280
这里没有插入，因为那只有一个 PUT ，

278
00:13:06,280 --> 00:13:07,015
这里没有更新，

279
00:13:07,015 --> 00:13:10,590
因为 PUT 只是盲目地写入在之前的任何东西上。

280
00:13:12,130 --> 00:13:15,410
所以，在内存中的日志文件中，

281
00:13:15,970 --> 00:13:18,570
我们将从最旧到最新，

282
00:13:18,570 --> 00:13:20,870
所以，在文件的开头或缓冲区的开头，

283
00:13:21,100 --> 00:13:22,515
这将是最旧的条目，

284
00:13:22,515 --> 00:13:27,515
我们只是追加它们，当我们做出修改时。

285
00:13:27,515 --> 00:13:28,430
所以应用程序可能会说，

286
00:13:28,430 --> 00:13:31,570
我想继续，做一个 PUT 在记录 103 上，

287
00:13:31,980 --> 00:13:33,760
103 的来自哪里，我们不在乎，

288
00:13:33,930 --> 00:13:37,450
假设系统的其他上层为我们解决了这一问题，

289
00:13:38,250 --> 00:13:40,900
然后，日志记录中的有效负载是，

290
00:13:41,040 --> 00:13:45,400
我们将记录 103 的值设置为 a1 。

291
00:13:47,090 --> 00:13:48,870
同样的事情，下一个出现了，

292
00:13:49,580 --> 00:13:50,790
他想做一个 PUT 到 104 ，

293
00:13:51,080 --> 00:13:54,270
然后更新那个记录，

294
00:13:54,500 --> 00:13:55,860
然后，如果我们有一个 DELETE ，

295
00:13:56,630 --> 00:14:00,420
我们在日志记录中有 DELETE 操作，

296
00:14:00,650 --> 00:14:02,670
然后使用相同的 tuple 标识符，

297
00:14:03,080 --> 00:14:06,080
随着我们继续，将它追加到日志中，

298
00:14:08,710 --> 00:14:10,070
所以在这个例子中，

299
00:14:12,260 --> 00:14:16,050
我们并不需要去读取原始记录是什么，

300
00:14:16,160 --> 00:14:17,130
原始的 tuple 是什么，

301
00:14:17,570 --> 00:14:19,080
任何时候我们想要更新日志。

302
00:14:21,560 --> 00:14:23,520
想想这个系统的下层，

303
00:14:24,020 --> 00:14:25,045
显然，如果我要执行查询，

304
00:14:25,045 --> 00:14:27,810
比如更新表设置 ID ，

305
00:14:27,980 --> 00:14:29,950
或者设置值等于值加一，

306
00:14:29,950 --> 00:14:31,350
我必须知道原始值是什么，

307
00:14:32,270 --> 00:14:34,170
这实质上就是先读后写，

308
00:14:34,430 --> 00:14:36,100
但在这个系统的最低层，

309
00:14:36,100 --> 00:14:37,800
我们不需要知道，

310
00:14:38,150 --> 00:14:42,090
给定的键的原始值是多少。

311
00:14:45,590 --> 00:14:49,560
同样，这与面向 tuple 的架构不同，

312
00:14:49,640 --> 00:14:53,035
在那里，我必须获取包含原始 tuple 的页面，

313
00:14:53,035 --> 00:14:54,120
然后才能更新它，

314
00:14:54,140 --> 00:14:57,280
在这里，我不用这么做。

315
00:14:59,510 --> 00:15:03,030
在某个时刻，内存中页面会变满，

316
00:15:03,470 --> 00:15:05,160
我们必须将其写到磁盘，

317
00:15:06,230 --> 00:15:09,240
这就是获取内存页的全部内容，

318
00:15:09,470 --> 00:15:12,240
并将其[拖到]磁盘上的一堆页中，

319
00:15:12,410 --> 00:15:13,560
清空我的内存缓冲区，

320
00:15:13,820 --> 00:15:17,130
然后开始用新的日志条目填充它，

321
00:15:18,440 --> 00:15:19,530
然后当它变满的时候，

322
00:15:19,580 --> 00:15:21,180
同样的事情，我把它写出去。

323
00:15:23,710 --> 00:15:25,310
现在，关于这一点，重要的是，

324
00:15:25,330 --> 00:15:26,760
有两件重要的事情需要指出，

325
00:15:26,760 --> 00:15:27,500
当我们做这个的时候。

326
00:15:27,820 --> 00:15:31,310
首先，这一切现在都是顺序 I/O ，

327
00:15:31,310 --> 00:15:36,010
因为我的内存中页面可能是 1 兆字节或者 10 兆字节，

328
00:15:36,450 --> 00:15:37,340
当它变满时，

329
00:15:37,340 --> 00:15:40,540
我将这 10 兆字节按顺序写出到磁盘上的文件中。

330
00:15:41,170 --> 00:15:44,720
所以，无论是在面向 tuple 架构或面向页面架构中，

331
00:15:44,860 --> 00:15:48,380
我都会有 20 个 tuple 分布在 20 个不同的页面上。

332
00:15:49,300 --> 00:15:51,380
在这种环境中，在这种设置下，

333
00:15:51,640 --> 00:15:54,465
这 20 个 tuple 总是在同一页面上，

334
00:15:54,465 --> 00:15:55,130
当我写出它们时，

335
00:15:55,690 --> 00:15:57,110
因为这是追加日志记录。

336
00:15:59,030 --> 00:16:00,930
这个架构中的另一件重要事情是，

337
00:16:01,160 --> 00:16:04,230
一旦将页面写入磁盘，它就是不可变的，

338
00:16:05,600 --> 00:16:08,670
这意味着我们永远不能回去做原地更新，

339
00:16:10,240 --> 00:16:11,100
我们会压缩它，

340
00:16:11,100 --> 00:16:12,890
我们很快就会看到，基本上就是垃圾回收，

341
00:16:13,330 --> 00:16:16,100
但我们永远不能覆盖以前已经存在的日志记录，

342
00:16:18,410 --> 00:16:20,155
我们现在还不了解分布式数据库，

343
00:16:20,155 --> 00:16:23,350
但是确保你的文件是不变的是有一些好处的，

344
00:16:23,350 --> 00:16:27,990
忽略比如，如果我在云存储上，我不能进行就地更新，

345
00:16:29,210 --> 00:16:30,370
但它现在确实容易了，

346
00:16:30,370 --> 00:16:31,680
如果它只是附加日志，

347
00:16:32,030 --> 00:16:34,960
这本质上就是 Paxos 或 Raft 所做的，

348
00:16:34,960 --> 00:16:38,370
添加日志记录，永远不会回去和进行更改。

349
00:16:39,510 --> 00:16:43,000
它可以修改日志，将是新的日志条目。

350
00:16:43,800 --> 00:16:45,050
所以，这将使架构变得容易很多，

351
00:16:45,050 --> 00:16:47,020
一旦存储在磁盘上，并且不需要更新，

352
00:16:47,880 --> 00:16:50,350
现在，我们将忽略，

353
00:16:50,430 --> 00:16:53,315
如果我需要写出内存缓冲区，

354
00:16:53,315 --> 00:16:56,350
在它完全满之前，

355
00:16:56,610 --> 00:16:58,720
比如，如果我运行一个查询或事务，

356
00:16:58,800 --> 00:17:01,205
希望确保将我的更改写入磁盘，

357
00:17:01,205 --> 00:17:04,960
在我告诉外界，数据被安全地写入磁盘之前，

358
00:17:05,130 --> 00:17:06,700
我可能会写出这个日志缓冲区，

359
00:17:07,280 --> 00:17:09,820
在它完成之前，在它装满之前，

360
00:17:11,010 --> 00:17:12,400
但我会把它写到一个单独的位置，

361
00:17:13,230 --> 00:17:15,250
一个本地磁盘，在那里我可以进行这种写操作。

362
00:17:16,480 --> 00:17:18,140
但是，我们现在将忽略这个。

363
00:17:20,200 --> 00:17:22,700
好的，所以，在日志结构架构中，

364
00:17:23,110 --> 00:17:24,705
这将使我们的写入速度非常快，

365
00:17:24,705 --> 00:17:26,450
比面向 tuple 的结构快得多，

366
00:17:27,250 --> 00:17:28,890
因为，我们只是追加日志记录，

367
00:17:28,890 --> 00:17:30,020
并按顺序写出它们。

368
00:17:31,885 --> 00:17:33,060
现在什么可能会变得更慢？

369
00:17:34,560 --> 00:17:35,120
读取。

370
00:17:35,120 --> 00:17:38,710
在计算机科学和数据库系统中，没有免费的午餐，

371
00:17:38,910 --> 00:17:40,430
所以我们让写入更快，

372
00:17:40,430 --> 00:17:41,920
但现在读取可能会变得更慢。

373
00:17:43,160 --> 00:17:44,860
那么，为了读取，我们必须做些什么，

374
00:17:44,860 --> 00:17:48,630
好的，假设我们系统中的某些东西已经计算出，

375
00:17:49,100 --> 00:17:52,140
ID 或我需要的日志记录的键，

376
00:17:52,460 --> 00:17:54,090
比如 102 103 104 ，

377
00:17:54,830 --> 00:17:55,920
我们现在可以忽略它，

378
00:17:56,870 --> 00:18:00,150
为了我们找到给定键的日志记录，

379
00:18:01,520 --> 00:18:03,150
我们首先要检查内存中的页面，

380
00:18:04,520 --> 00:18:07,200
从末尾开始，因为这是最新的记录，

381
00:18:07,610 --> 00:18:11,875
然后以相反的顺序顺序扫描，

382
00:18:11,875 --> 00:18:12,900
返回到开头，

383
00:18:13,430 --> 00:18:14,970
直到我们找到我们想要的日志条目，

384
00:18:17,050 --> 00:18:17,960
如果它不在那里，

385
00:18:18,370 --> 00:18:19,620
我们可能不得不去磁盘，

386
00:18:19,620 --> 00:18:20,510
我们稍后会讲到这个。

387
00:18:22,570 --> 00:18:23,360
那么，这是高效的吗？

388
00:18:25,090 --> 00:18:26,120
不是。

389
00:18:26,770 --> 00:18:27,855
所以，绕过这个的一种方法，

390
00:18:27,855 --> 00:18:30,230
这就是教科书中日志结构合并树的来源，

391
00:18:30,340 --> 00:18:32,090
但同样，我们不必担心细节，

392
00:18:32,380 --> 00:18:36,835
它们将维护某种类型的索引，

393
00:18:36,835 --> 00:18:38,250
对于每个 record ID ，

394
00:18:39,200 --> 00:18:43,320
它将告诉你内存缓冲区页面中的位置，

395
00:18:43,640 --> 00:18:48,615
或者如果它不在内存中，那么它在磁盘上的哪里，

396
00:18:48,615 --> 00:18:50,600
所以，要获得 record ID 104 ，

397
00:18:50,890 --> 00:18:52,635
我只需在这个索引中进行一些查找，

398
00:18:52,635 --> 00:18:54,500
我不会告诉你它是什么数据结构，无关紧要，

399
00:18:54,760 --> 00:18:56,480
它通常会是 B+ 树，

400
00:18:57,280 --> 00:18:59,775
但是一些系统使用 Trie ，一些系统使用跳表，

401
00:18:59,775 --> 00:19:00,350
无所谓，

402
00:19:01,030 --> 00:19:02,480
做我的查找，查找 104 ，

403
00:19:02,620 --> 00:19:04,550
然后我会告诉你内存页面的偏移量是多少，

404
00:19:05,500 --> 00:19:08,060
内存缓冲区里有我要找的数据。

405
00:19:09,140 --> 00:19:10,770
在这种情况下，我想查看 103 ，

406
00:19:10,970 --> 00:19:12,360
然后我必须去磁盘，并获得它。

407
00:19:13,100 --> 00:19:13,500
好的。

408
00:19:19,030 --> 00:19:19,790
到现在为止还好吗？

409
00:19:20,260 --> 00:19:20,660
好的。

410
00:19:33,650 --> 00:19:34,380
所以，你的问题是，

411
00:19:34,430 --> 00:19:36,990
是否可能在仅追加的文件系统中实现索引？

412
00:19:40,970 --> 00:19:41,815
所以，是的。

413
00:19:41,815 --> 00:19:43,320
所以你这样做的方式就像是，

414
00:19:45,650 --> 00:19:47,880
你可以把它当作一个日志本身，

415
00:19:48,740 --> 00:19:51,690
然后你在内存中在它上面构建一个数据结构，

416
00:19:51,770 --> 00:19:54,490
比如在 B+ 树中，

417
00:19:55,110 --> 00:19:56,710
典型的操作类似于，

418
00:19:56,940 --> 00:19:58,840
当你在磁盘上写入页面时，

419
00:20:00,030 --> 00:20:02,440
你仍在维护数据结构本身，

420
00:20:02,670 --> 00:20:05,110
比如孩子和双亲之间的指针等，

421
00:20:05,370 --> 00:20:07,210
在这种环境中，

422
00:20:07,680 --> 00:20:11,530
你可以通过重放日志来重建内存中的索引，

423
00:20:11,640 --> 00:20:13,840
这样你就可以在只读文件系统中执行此操作。

424
00:20:18,185 --> 00:20:19,240
事实上，我不知道 RocksDB 所做的。

425
00:20:20,380 --> 00:20:20,780
是的。

426
00:20:21,220 --> 00:20:28,270
所以问题是，

427
00:20:28,470 --> 00:20:30,010
这个索引是不是相同的索引，

428
00:20:30,030 --> 00:20:32,860
当你在 SQLite 中运行 CREATE INDEX 时得到的。

429
00:20:33,390 --> 00:20:35,950
特别指 SQLite ，不是。

430
00:20:39,970 --> 00:20:41,660
好的， SQLite 不是日志结构的，

431
00:20:42,550 --> 00:20:46,580
你是说，这与主键索引相同吗，

432
00:20:51,370 --> 00:20:54,110
可能，是的，但并不总是，

433
00:20:54,670 --> 00:20:55,610
SQL 有点复杂，

434
00:20:55,690 --> 00:20:56,780
页面索引，

435
00:20:56,920 --> 00:21:01,530
你可以有非表索引，

436
00:21:01,530 --> 00:21:03,680
然后主键表索引，

437
00:21:04,120 --> 00:21:05,120
给我一点时间，我们会讲到这个。

438
00:21:07,740 --> 00:21:08,620
把这个想象成这样，

439
00:21:10,630 --> 00:21:13,610
它几乎就像查找记录的内部记账，

440
00:21:14,380 --> 00:21:15,405
几乎就像页面目录，

441
00:21:15,405 --> 00:21:19,730
这不是你必须向 SQL 查询本身公开的内容，

442
00:21:20,200 --> 00:21:21,710
但你可以使用它们。

443
00:21:38,460 --> 00:21:40,180
所以你的问题是，

444
00:21:40,740 --> 00:21:43,060
这个索引指向的是发生在内存中的事情，

445
00:21:43,560 --> 00:21:44,560
这不是真的，

446
00:21:44,760 --> 00:21:45,670
它可以指向磁盘。

447
00:21:52,860 --> 00:21:54,050
为什么我们要存储所有东西，

448
00:21:54,720 --> 00:21:55,340
我们马上就会做这个，

449
00:21:55,780 --> 00:21:59,600
但是，在这个例子中，

450
00:21:59,600 --> 00:22:03,070
我有 ID 等于 103 ，

451
00:22:03,120 --> 00:22:05,230
它不在内存中，它在磁盘上的某个地方，

452
00:22:05,790 --> 00:22:07,480
那么，在哪里，

453
00:22:08,220 --> 00:22:09,800
我不能丢弃整个文件，

454
00:22:09,880 --> 00:22:11,990
我得把它拿出来，

455
00:22:12,740 --> 00:22:14,170
它是昂贵的，它是压缩的，

456
00:22:14,615 --> 00:22:15,250
我们稍后会讲到这个。

457
00:22:17,210 --> 00:22:17,610
是的。

458
00:22:30,460 --> 00:22:31,190
他的说法是，

459
00:22:33,060 --> 00:22:34,720
为什么我们需要存储这个 DEL 记录，

460
00:22:34,920 --> 00:22:38,750
如果它已经被删除了，为什么还要保存它。

461
00:22:42,690 --> 00:22:44,740
因为这里会有 PUT ，

462
00:22:44,850 --> 00:22:47,770
比如 102 ，有一个 PUT 在它前面，

463
00:22:48,060 --> 00:22:50,200
但是假如另一个 PUT 已经写在磁盘上，

464
00:22:50,820 --> 00:22:53,900
想象我回到过去，

465
00:22:54,580 --> 00:22:55,880
我想确保，

466
00:22:56,140 --> 00:23:03,000
如果我没有删除，那么它确实存在，

467
00:23:03,170 --> 00:23:04,060
因为我不能回去，

468
00:23:04,060 --> 00:23:05,680
好的， 102 被删除了，

469
00:23:05,680 --> 00:23:07,410
让我找一个它所在的页面，然后把它拉出来，

470
00:23:07,490 --> 00:23:08,280
我不能那么做，

471
00:23:08,630 --> 00:23:09,850
所以我追加一个日志记录，说，

472
00:23:09,850 --> 00:23:12,295
好的，如果你回到过去，查看 102 ，

473
00:23:12,295 --> 00:23:13,500
它已经被删除了。

474
00:23:14,790 --> 00:23:16,240
我们将在稍后将它们合并，

475
00:23:16,380 --> 00:23:18,340
以删除这些内容的多余条目。

476
00:23:22,320 --> 00:23:26,410
好的，就像这两个人提到的那样，

477
00:23:26,880 --> 00:23:30,370
一些日志记录，我们不需要永远维护它们，

478
00:23:31,190 --> 00:23:33,130
DELETE 就是这样的例子，

479
00:23:33,130 --> 00:23:35,430
或者 PUT 一遍又一遍地在同一个键上。

480
00:23:36,230 --> 00:23:38,725
所以，在日志结构数据库系统中，

481
00:23:38,725 --> 00:23:39,430
他们要做的是，

482
00:23:39,430 --> 00:23:41,850
定期运行一些后台作业，

483
00:23:42,640 --> 00:23:44,070
用来压缩页面，

484
00:23:45,070 --> 00:23:49,340
把它们结合起来，减少多余的操作。

485
00:23:50,600 --> 00:23:51,415
在这个例子中，

486
00:23:51,415 --> 00:23:53,430
我有页面 #1 和页面 #2 ，

487
00:23:53,570 --> 00:23:57,910
这是从最新到最旧，抱歉，最旧到最新，

488
00:23:57,910 --> 00:23:59,760
所以这个比这个旧，

489
00:24:00,170 --> 00:24:01,620
所以如果我想压缩它们，

490
00:24:01,940 --> 00:24:03,190
那么你需要做的就是，

491
00:24:03,190 --> 00:24:05,790
这是我关心的最新条目，

492
00:24:06,050 --> 00:24:10,440
对于这两个页面中引用的键，

493
00:24:10,640 --> 00:24:12,300
所以 103 104 ，

494
00:24:12,650 --> 00:24:14,370
然后我们删除 101 和 102 ，

495
00:24:14,570 --> 00:24:16,415
然后放入 105 ，

496
00:24:16,415 --> 00:24:18,730
这里有一个 PUT 105 ，

497
00:24:18,840 --> 00:24:21,820
但是因为这个比这个 105 更新，

498
00:24:22,140 --> 00:24:23,110
我们知道我们不需要，

499
00:24:23,280 --> 00:24:24,850
我们想要这个，而不是这个，

500
00:24:25,050 --> 00:24:26,710
所以不需要存储两个 105 ，

501
00:24:26,730 --> 00:24:29,200
我们只需要存储一个，在我们的合并页面中。

502
00:24:30,980 --> 00:24:32,965
正如他也提到的，

503
00:24:32,965 --> 00:24:34,290
情况可能是，

504
00:24:35,420 --> 00:24:37,950
我不需要在这一点上存储 DELETE ，

505
00:24:38,900 --> 00:24:41,870
因为系统上的其他部分，

506
00:24:41,870 --> 00:24:46,210
表明我已经从索引中删除了 102 101 ，

507
00:24:46,470 --> 00:24:48,400
任何人查找，他们会看到键没有找到，

508
00:24:48,630 --> 00:24:51,160
所以我不需要存储这个日志条目。

509
00:24:53,790 --> 00:24:54,850
这就是所谓的压缩，

510
00:24:56,550 --> 00:24:58,840
同样，这也没有免费午餐，

511
00:24:59,400 --> 00:25:02,980
日志结构存储将使插入速度更快，

512
00:25:03,270 --> 00:25:04,540
因为它只追加日志，

513
00:25:04,860 --> 00:25:06,970
但在某个时刻，我们必须去清理东西。

514
00:25:09,110 --> 00:25:11,200
好的，所以我们的想法是，

515
00:25:11,200 --> 00:25:13,680
我们做这种压缩，

516
00:25:13,910 --> 00:25:20,430
现在我们得到日志记录的压缩形式，

517
00:25:20,630 --> 00:25:22,170
这只是在磁盘上，

518
00:25:22,190 --> 00:25:23,725
我们无法进行就地更新，

519
00:25:23,725 --> 00:25:26,440
这就是取一个磁盘页，另一个磁盘页，

520
00:25:26,440 --> 00:25:27,630
然后写出一个新的，

521
00:25:27,710 --> 00:25:29,700
我们不能覆盖现有的。

522
00:25:31,770 --> 00:25:33,620
另一件需要跟踪的重要事情是，

523
00:25:33,620 --> 00:25:34,690
一旦它存储在磁盘上，

524
00:25:35,010 --> 00:25:37,210
我们就知道它旧于，

525
00:25:38,220 --> 00:25:41,025
一旦我们在磁盘上有了一个页面，

526
00:25:41,025 --> 00:25:42,375
并且我们已经压缩了它，

527
00:25:42,375 --> 00:25:46,700
删除多余的或拥有相同的键的反复操作，

528
00:25:46,840 --> 00:25:50,480
这意味着在我们压缩的磁盘页中，

529
00:25:50,560 --> 00:25:53,870
它只包含，或者每个键只被引用一次，

530
00:25:55,890 --> 00:25:59,045
在这一点上，我们不再关心日志中的时间顺序，

531
00:25:59,045 --> 00:26:02,000
我们不关心最新到最旧。

532
00:26:03,410 --> 00:26:06,055
所以现在如果我们需要支持的操作是

533
00:26:06,055 --> 00:26:10,200
在磁盘上找出键 103 104 105 ，

534
00:26:10,250 --> 00:26:11,560
时间顺序对我们没有帮助，

535
00:26:11,560 --> 00:26:13,315
实际上，我们要做的是，

536
00:26:13,315 --> 00:26:16,270
对磁盘页进行排序，基于键进行排序，

537
00:26:16,270 --> 00:26:22,150
根据键对此页中的日志记录进行排序。

538
00:26:23,040 --> 00:26:24,010
所以我们这样做，

539
00:26:25,920 --> 00:26:27,830
因为，现在我需要知道的是，

540
00:26:27,830 --> 00:26:29,110
如果我看着这个页面，

541
00:26:29,340 --> 00:26:31,510
我知道这些页面比其他页面更老，

542
00:26:32,790 --> 00:26:34,355
所以我有一些类似的元数据，

543
00:26:34,355 --> 00:26:37,720
但每个日志记录，我不需要知道一个比另一个更老。

544
00:26:40,210 --> 00:26:43,050
所以当你做压缩的时候，

545
00:26:43,050 --> 00:26:45,410
然后你根据键值对它们进行排序，

546
00:26:46,660 --> 00:26:49,160
这些有时被称为排序字符串表或 SSTables ，

547
00:26:49,900 --> 00:26:54,590
我想这个术语是 Jeff Dean 和 Sandjay 创造的，

548
00:26:54,850 --> 00:26:56,150
当他们在谷歌写 LevelDB 时，

549
00:26:56,440 --> 00:26:58,910
这是为了 2000 年中期的 bigtable 。

550
00:27:00,930 --> 00:27:03,550
这样做的好处是，

551
00:27:03,810 --> 00:27:05,920
当我要去取这一页时，

552
00:27:06,120 --> 00:27:07,220
我不会去找，

553
00:27:07,220 --> 00:27:10,720
比如给我这个时间戳的 103 的 PUT ，

554
00:27:10,860 --> 00:27:12,430
你只是查找 PUT 103 ，

555
00:27:13,240 --> 00:27:16,980
所以你需要尽快找到那个记录，

556
00:27:17,600 --> 00:27:19,050
如果你进行了排序，

557
00:27:19,130 --> 00:27:21,955
你可以以某种方式构建索引或过滤器，

558
00:27:21,955 --> 00:27:24,690
快速跳到你要查找的记录，

559
00:27:24,740 --> 00:27:26,910
而不必在整个文件中执行二分搜索。

560
00:27:27,770 --> 00:27:31,200
所以有一些元数据和每个 SSTable 页的 header ，

561
00:27:31,790 --> 00:27:32,700
跟踪，

562
00:27:33,050 --> 00:27:35,400
抱歉，由多个页面组成的文件，

563
00:27:35,810 --> 00:27:40,170
跟踪不同键的偏移量在哪里。

564
00:27:42,310 --> 00:27:42,710
是的。

565
00:27:47,890 --> 00:27:48,540
问题是，

566
00:27:48,540 --> 00:27:55,600
我们所讨论的索引不是准确地对应东西所在的位置吗，

567
00:27:56,310 --> 00:27:59,170
不一定，你可能想要保持，

568
00:28:03,410 --> 00:28:05,700
你可能想要保持一个更[]的索引，它说，

569
00:28:06,050 --> 00:28:08,500
这里可能不是你要找的东西的确切偏移量，

570
00:28:08,500 --> 00:28:11,160
但这是页面，这是包含它的文件，

571
00:28:11,390 --> 00:28:12,550
一旦你找到那个文件，

572
00:28:12,550 --> 00:28:14,730
它会告诉你在哪里找到它。

573
00:28:16,150 --> 00:28:17,775
是的，也许我在这里没有画出一个很好的例子，

574
00:28:17,775 --> 00:28:18,950
我要说的是，这个页面，

575
00:28:19,570 --> 00:28:21,480
这可以是 SSD 文件的多个页面，

576
00:28:21,480 --> 00:28:22,965
通常是因为这些内容变大了，

577
00:28:22,965 --> 00:28:24,500
所以它是单个页面。

578
00:28:26,190 --> 00:28:26,950
后面的，是的。

579
00:28:30,740 --> 00:28:32,400
对于 SSTable 还是内存中的？

580
00:28:33,470 --> 00:28:34,110
内存中的。

581
00:28:35,390 --> 00:28:38,970
是的，因为你不想在重新启动时重新创建它，

582
00:28:39,830 --> 00:28:41,160
正如我之前所说的，

583
00:28:41,570 --> 00:28:44,430
你可以只将文件和页面本身写入磁盘，

584
00:28:45,680 --> 00:28:48,535
也可以只维护一个日志记录，它说，

585
00:28:48,535 --> 00:28:49,650
以下是如何重建索引。

586
00:28:51,590 --> 00:28:56,640
是的。{ - - -}

587
00:28:57,770 --> 00:28:58,300
是的，问题是，

588
00:28:58,300 --> 00:28:59,580
为什么我们不按某种顺序来写这些页，

589
00:29:01,250 --> 00:29:01,840
这就是他们所做的。

590
00:29:01,840 --> 00:29:02,100
是的。

591
00:29:09,580 --> 00:29:10,215
绝对是的，

592
00:29:10,215 --> 00:29:11,420
所以他的陈述是正确的，

593
00:29:11,770 --> 00:29:15,315
压缩不会对读取的性能产生影响吗，

594
00:29:15,315 --> 00:29:17,925
因为你不仅仅是拿着锁，

595
00:29:17,925 --> 00:29:19,160
你在做磁盘 I/O ，

596
00:29:20,470 --> 00:29:21,945
因为现在你在，

597
00:29:21,945 --> 00:29:23,510
我们稍后会看到不同类型的压缩，

598
00:29:23,590 --> 00:29:25,910
现在，你可能会带入吉字节的文件，

599
00:29:26,290 --> 00:29:27,860
压缩文件，并将其写回，

600
00:29:28,270 --> 00:29:29,030
所以绝对是的。

601
00:29:29,680 --> 00:29:30,500
再说一次，没有免费的午餐。

602
00:29:35,950 --> 00:29:36,350
好的。

603
00:29:37,980 --> 00:29:41,440
有两种主要方法可以进行压缩，

604
00:29:42,870 --> 00:29:46,540
这里我将使用的术语是 RocksDB 中使用的。

605
00:29:48,230 --> 00:29:51,360
所以，最简单的形式被称为万能压缩，

606
00:29:51,980 --> 00:29:56,610
你只需要取磁盘上相邻的日志文件，

607
00:29:56,690 --> 00:30:00,480
同样，多个页面，考虑兆字节、吉字节、太字节，

608
00:30:00,950 --> 00:30:06,180
然后你只需要取两个相邻的日志文件，

609
00:30:06,290 --> 00:30:07,795
然后压缩它们，

610
00:30:07,795 --> 00:30:11,425
所以我取这两个，做一个排序合并，

611
00:30:11,425 --> 00:30:12,280
它们已经排序了，

612
00:30:12,280 --> 00:30:13,470
所以现在我只是做一次合并，

613
00:30:13,490 --> 00:30:18,820
看看是否你查找的不同的键，

614
00:30:18,820 --> 00:30:20,130
是否一个包含另一个，

615
00:30:20,510 --> 00:30:23,340
假设这个比这个旧，

616
00:30:23,480 --> 00:30:27,990
如果我看到更新或 PUT ，对于这里的 103 和那里的 103 ，

617
00:30:28,100 --> 00:30:29,215
那么我知道我想要那个，

618
00:30:29,215 --> 00:30:32,830
我可以扔掉另一个。

619
00:30:33,210 --> 00:30:38,050
我可以对这些日志文件的任何可能组合执行相同的操作，

620
00:30:38,190 --> 00:30:42,700
我可以继续把它们编码成更紧凑的形式。

621
00:30:46,180 --> 00:30:48,170
另一种方法是进行所谓的水平压缩，

622
00:30:48,700 --> 00:30:51,500
同样，这也是 LevelDB 的来源。

623
00:30:53,590 --> 00:30:55,730
实际上，在座的谁听说过 LevelDB ，

624
00:30:56,960 --> 00:30:57,550
这里没几个人，

625
00:30:57,550 --> 00:30:58,770
谁听说过 RocksDB ，

626
00:30:59,930 --> 00:31:01,320
更多，好的，不会太多。

627
00:31:01,580 --> 00:31:05,275
RocksDB 是 Facebook 对 LevelDB 的 fork ，

628
00:31:05,275 --> 00:31:07,920
谷歌写了 LevelDB ， RocksDB fork 了它，

629
00:31:08,180 --> 00:31:11,910
他们做的第一件事就是删除了 mmap ，

630
00:31:12,620 --> 00:31:13,555
然后他们扩展了它，

631
00:31:13,555 --> 00:31:14,650
做了一系列其他的事情，

632
00:31:14,650 --> 00:31:17,400
所以这个水平压缩来自 LevelDB 。

633
00:31:18,260 --> 00:31:19,950
好的，所以你有文件在磁盘上，

634
00:31:20,990 --> 00:31:23,220
在零级，它们将是一定的大小，

635
00:31:23,660 --> 00:31:25,590
你一直在添加更多的文件，

636
00:31:25,790 --> 00:31:27,240
直到某一点，你运行压缩，

637
00:31:27,770 --> 00:31:33,030
然后你将它们组合成一个更大的文件，在下一个级别，

638
00:31:33,380 --> 00:31:35,460
在顶层制造更多的它们，

639
00:31:35,690 --> 00:31:37,270
并在某个时候合并在一起，

640
00:31:37,270 --> 00:31:39,210
一旦我在下一级足够多，

641
00:31:39,440 --> 00:31:41,335
然后我会对那个进行压缩，

642
00:31:41,335 --> 00:31:42,420
并在较低的级别产生一些东西，

643
00:31:42,470 --> 00:31:43,615
所以在某种程度上是层级式下降的，

644
00:31:43,615 --> 00:31:46,350
随着我的下降，文件越来越大。

645
00:31:51,140 --> 00:31:52,440
所以正如我所说的，

646
00:31:53,180 --> 00:31:57,550
因为 RocksDB 已经成为许多数据库供应商的默认选择，

647
00:31:57,550 --> 00:31:59,010
人们构建数据库系统，

648
00:31:59,300 --> 00:32:03,420
作为要使用的底层存储管理器，

649
00:32:04,340 --> 00:32:07,540
它们本质上是日志结构的，

650
00:32:07,540 --> 00:32:09,475
但他们在 RocksDB 上构建的是，

651
00:32:09,475 --> 00:32:12,925
所有的 SQL 解析层， SQL 执行，索引，

652
00:32:12,925 --> 00:32:14,760
所有我们将在整个学期讨论的其他内容。

653
00:32:15,450 --> 00:32:19,930
RocksDB 本质上只提供键值 API ，

654
00:32:20,670 --> 00:32:21,320
你不需要，

655
00:32:21,320 --> 00:32:23,865
在我的例子中，

656
00:32:23,865 --> 00:32:24,920
我只说这是值，

657
00:32:24,940 --> 00:32:27,890
这是我要存储在日志中的有效负载，

658
00:32:28,630 --> 00:32:31,665
它没有属性或列的概念，

659
00:32:31,665 --> 00:32:33,855
即使我说我的表中有 10 列，

660
00:32:33,855 --> 00:32:35,000
但我只更新了其中的一列，

661
00:32:35,140 --> 00:32:37,880
我的 PUT 记录必须包含所有 10 列。

662
00:32:39,060 --> 00:32:42,965
我们将在期中考试后看到多版本控制，

663
00:32:42,965 --> 00:32:43,960
我们可以更聪明地使用它，

664
00:32:44,220 --> 00:32:46,960
它看起来很像日志结构存储，

665
00:32:47,250 --> 00:32:48,790
但现在我们可以忽略它。

666
00:32:50,090 --> 00:32:51,340
这几乎就是 Postgres ，

667
00:32:51,340 --> 00:32:54,360
这就是 Postgres 在 1980 年代最初设想的，

668
00:32:55,970 --> 00:32:57,480
它看起来很像这样。

669
00:32:58,200 --> 00:33:01,130
所以他们说 RocksDB 是非常流行的，

670
00:33:01,630 --> 00:33:03,470
LevelDB ，它是 LevelDB 的 fork ，

671
00:33:03,580 --> 00:33:05,910
这只是部分不同公司，

672
00:33:05,910 --> 00:33:09,410
使用了日志结构存储，

673
00:33:09,490 --> 00:33:10,760
有些是以 RocksDB 为基础的，

674
00:33:11,080 --> 00:33:13,190
CockroachDB 最初是使用 RocksDB ，

675
00:33:13,210 --> 00:33:15,710
他们把它扔掉，使用 Go 写了自己的东西，叫做 Pebble ，

676
00:33:16,030 --> 00:33:18,740
Cassandra 有自己的日志结构存储，

677
00:33:19,150 --> 00:33:21,825
TiDB 有 TiKV ，

678
00:33:21,825 --> 00:33:23,130
我想 Dgraph 使用 BadgerDB ，

679
00:33:23,130 --> 00:33:26,540
但是很多这些都使用日志结构系统。

680
00:33:28,280 --> 00:33:29,700
我们已经说过读取速度较慢，

681
00:33:30,140 --> 00:33:31,080
但是还有哪些其他问题，

682
00:33:31,280 --> 00:33:33,535
我们使用日志结构存储，

683
00:33:33,535 --> 00:33:35,430
我们说过读取速度较慢，压缩昂贵，

684
00:33:35,840 --> 00:33:39,000
这种方法还有一个核心问题。

685
00:33:40,150 --> 00:33:40,550
是的。

686
00:33:40,780 --> 00:33:42,410
它的磁盘效率似乎较低。

687
00:33:43,060 --> 00:33:44,660
你说的磁盘效率是什么意思？

688
00:33:44,920 --> 00:33:47,390
比如你必须存储每个 tuple 的额外副本，

689
00:33:47,590 --> 00:33:50,000
当你压缩时，你必须新建，

690
00:33:50,580 --> 00:33:52,940
你必须使用磁盘的其他部分，所以。

691
00:33:54,430 --> 00:33:55,350
所以他的说法是，

692
00:33:55,350 --> 00:33:57,735
它的效率不高，

693
00:33:57,735 --> 00:34:00,810
因为你必须存储一个 tuple 的多个副本，

694
00:34:00,810 --> 00:34:02,090
因为有一堆 PUT ，

695
00:34:02,560 --> 00:34:03,620
然后当你进行压缩时，

696
00:34:03,820 --> 00:34:05,270
你必须有一个临时区域，

697
00:34:05,800 --> 00:34:08,300
或多或少你有两个原始文件，

698
00:34:08,380 --> 00:34:10,010
你试图压缩两个或更多，

699
00:34:10,210 --> 00:34:12,470
然后你写出一个新的，是的。

700
00:34:14,450 --> 00:34:16,020
我们说是，这是一个问题，是的。

701
00:34:18,930 --> 00:34:22,780
但是与这个压缩相关，我在做什么，

702
00:34:23,160 --> 00:34:25,060
在早些时候的某个时候，

703
00:34:25,170 --> 00:34:27,370
我在内存中保存了这些日志记录，

704
00:34:27,840 --> 00:34:28,960
我写出到磁盘中，

705
00:34:29,280 --> 00:34:30,640
现在对于压缩，我在做什么。

706
00:34:31,910 --> 00:34:35,520
将其读回内存，再写回磁盘。

707
00:34:36,730 --> 00:34:37,970
所以，这称为写入放大。

708
00:34:39,200 --> 00:34:41,400
这里的问题是，

709
00:34:41,600 --> 00:34:44,160
对于每一种逻辑写入，我的应用程序所做的，

710
00:34:44,390 --> 00:34:46,440
插入一个 tuple ，更新一个 tuple ，

711
00:34:46,850 --> 00:34:49,380
我要读取和写回磁盘多少次，

712
00:34:50,670 --> 00:34:56,945
以一种日志结构方法，可能是无限的，

713
00:34:56,945 --> 00:34:58,960
如果我继续压缩，一遍又一遍地压缩，

714
00:34:59,790 --> 00:35:01,030
显然这不会发生，

715
00:35:01,260 --> 00:35:05,490
但是，我可能会做，

716
00:35:05,540 --> 00:35:10,850
对于一个逻辑写入，我可能会做几十次物理写入，

717
00:35:11,080 --> 00:35:12,860
因为我要带回到内存，然后把它写回出去。

718
00:35:14,560 --> 00:35:17,510
在使用插槽页面的页面架构中，

719
00:35:17,650 --> 00:35:18,680
我们没有这个问题，

720
00:35:19,640 --> 00:35:21,240
当我更新一个单独的 tuple 时，

721
00:35:21,470 --> 00:35:25,020
我会引入内存，更新它，然后写回它，

722
00:35:26,290 --> 00:35:28,970
如果我不再更新它，也不再把它写出去，

723
00:35:30,030 --> 00:35:32,345
我们忽略了备份，我们忽略了预先日志，

724
00:35:32,345 --> 00:35:33,820
我们将在本学期晚些时候讨论这个问题，

725
00:35:34,260 --> 00:35:37,845
但是，如果我没有读取，我没有使用它，

726
00:35:37,845 --> 00:35:40,440
我不会把它带入内存再带回，

727
00:35:40,440 --> 00:35:41,840
在日志结构存储中，你必须这样做。

728
00:35:43,200 --> 00:35:43,600
好的？

729
00:35:45,710 --> 00:35:47,245
所以，如果你想超越这一点，

730
00:35:47,245 --> 00:35:49,645
教科书中的日志结构合并树部分，

731
00:35:49,645 --> 00:35:52,440
我认为这有点过于复杂，

732
00:35:53,000 --> 00:35:54,060
因为它实际上是，

733
00:35:54,680 --> 00:35:56,490
如何合并这些树为基础的，

734
00:35:56,570 --> 00:35:57,870
它看起来像是水平压缩，

735
00:35:58,100 --> 00:36:00,390
但我理解的是低级别的数据结构，

736
00:36:00,800 --> 00:36:02,350
我想让你们明白的关键一点是，

737
00:36:02,350 --> 00:36:05,400
这是一种不同的存储 tuple 的方法，

738
00:36:06,180 --> 00:36:07,630
通过这些日志记录，

739
00:36:07,650 --> 00:36:09,730
我们会看到这个想法再次出现，

740
00:36:10,020 --> 00:36:11,680
当我们讨论多版本控制，

741
00:36:11,820 --> 00:36:14,830
当我们讨论分布式事务、分布式数据库时。

742
00:36:19,350 --> 00:36:19,925
这个问题是，

743
00:36:19,925 --> 00:36:21,910
为什么水平压缩比普遍压实更受欢迎，

744
00:36:22,110 --> 00:36:23,980
我不知道是不是真的，

745
00:36:25,440 --> 00:36:26,765
我不认为这有什么不同，

746
00:36:26,765 --> 00:36:30,700
事实上，是的，我不知道它们之间的权衡是什么，

747
00:36:33,000 --> 00:36:34,090
除了它像是，

748
00:36:36,170 --> 00:36:38,910
我想它是一种更干净的架构，

749
00:36:40,040 --> 00:36:41,500
我知道在这个级别，我将压缩，

750
00:36:41,500 --> 00:36:43,290
它将达到这个尺寸，并进入下一级别，

751
00:36:43,550 --> 00:36:45,030
然而，在普遍模式中，

752
00:36:45,410 --> 00:36:46,900
你必须有一些额外的逻辑方面，

753
00:36:46,900 --> 00:36:48,865
如果我可以合并这个和这个，

754
00:36:48,865 --> 00:36:49,705
或者这个和这个，

755
00:36:49,705 --> 00:36:50,550
我应该做哪一个，

756
00:36:51,710 --> 00:36:52,950
但是我不认为，

757
00:36:53,660 --> 00:36:57,300
RocksDB 手册中有很多关于[]的信息，

758
00:36:57,380 --> 00:36:58,860
如果你想看的话，我可以在之后贴在 Piazza 上。

759
00:37:00,910 --> 00:37:01,310
是的。

760
00:37:01,690 --> 00:37:10,830
所以他的问题是，

761
00:37:10,830 --> 00:37:11,990
我所说的压缩期是什么意思，

762
00:37:12,280 --> 00:37:16,245
你会有某种触发阈值，

763
00:37:16,245 --> 00:37:18,630
或者是说是时候压缩了，

764
00:37:18,630 --> 00:37:20,870
如果是水平压缩，它可能是，

765
00:37:20,890 --> 00:37:26,240
我有三个这样的，运行压缩，

766
00:37:26,500 --> 00:37:28,790
也可能是我做了这么多写入，开始压缩。

767
00:37:29,660 --> 00:37:32,640
这就是说，它可以在任何时候完成，

768
00:37:33,460 --> 00:37:35,450
它不需要由读取触发吗？

769
00:37:35,940 --> 00:37:38,030
对的，它不需要要由读取触发，

770
00:37:38,590 --> 00:37:39,860
任何时候，是的。

771
00:37:40,150 --> 00:37:42,650
但这就像是，这是怎么做的。

772
00:37:46,290 --> 00:37:49,820
这就像，你需要给你的车换机油，

773
00:37:49,820 --> 00:37:54,340
你可以在你应该走的里程之外走很长一段时间，

774
00:37:54,510 --> 00:37:55,925
但这是你不应该的，

775
00:37:55,925 --> 00:37:57,280
所以这有点像是最佳实践，

776
00:37:57,960 --> 00:37:59,800
你想确保你准备好了，

777
00:38:00,510 --> 00:38:02,050
做你需要做的维护，

778
00:38:02,250 --> 00:38:03,980
但当然，如果你每秒都在运行它，

779
00:38:03,980 --> 00:38:05,680
那么这会使你的读取速度变慢，

780
00:38:05,820 --> 00:38:06,455
所以，它是如何平衡，

781
00:38:06,455 --> 00:38:08,590
如何弄清楚在什么时候做这件事。

782
00:38:08,850 --> 00:38:09,950
同样，我们将看到这一点，

783
00:38:09,950 --> 00:38:11,650
当我们讨论 Postgres 和多版本控制时，

784
00:38:11,670 --> 00:38:13,090
有一种叫自动 vacuum 的东西，

785
00:38:13,620 --> 00:38:15,260
它应该什么时候运行，它应该如何运行，

786
00:38:15,260 --> 00:38:17,990
这取决于工作量和硬件。

787
00:38:22,480 --> 00:38:22,880
好的。

788
00:38:25,840 --> 00:38:29,395
所以，我们到目前为止谈到的两种方法，

789
00:38:29,395 --> 00:38:35,400
日志结构存储和面向页面存储，

790
00:38:36,230 --> 00:38:37,345
这是面向 tuple 的存储，

791
00:38:37,345 --> 00:38:38,970
这是方法，

792
00:38:39,990 --> 00:38:42,490
这一切都依赖索引查找独立的 tuple ，

793
00:38:42,720 --> 00:38:49,810
tuple 本身独立于表的核心存储，

794
00:38:50,040 --> 00:38:51,610
在面向 tuple 的存储中，

795
00:38:51,960 --> 00:38:53,680
有这些页面，它们是无序的，

796
00:38:54,000 --> 00:38:55,540
并获取 record ID ，

797
00:38:55,980 --> 00:38:57,520
给我们页面编号和 slot 编号，

798
00:38:57,870 --> 00:39:00,610
还有一些其他神奇的数据结构或索引，

799
00:39:00,720 --> 00:39:01,750
会把我们带到那里，

800
00:39:02,100 --> 00:39:03,610
日志结构存储也是如此，

801
00:39:03,870 --> 00:39:05,765
我们需要一个索引告诉我们，

802
00:39:05,765 --> 00:39:06,820
对于给定的 record ID ，

803
00:39:07,110 --> 00:39:10,310
到哪里去查找我们寻找的数据。

804
00:39:11,180 --> 00:39:14,370
所以，另一种方法是，

805
00:39:14,480 --> 00:39:16,980
如果我们只保持 tuple 自动排序，会怎么样，

806
00:39:18,610 --> 00:39:20,990
只需将其放入索引本身，

807
00:39:22,280 --> 00:39:24,250
现在，你没有单独的区别，

808
00:39:24,250 --> 00:39:25,915
这里是日志结构存储和索引，

809
00:39:25,915 --> 00:39:28,680
这是是页面插槽和索引，

810
00:39:29,240 --> 00:39:30,420
这些都只是索引。

811
00:39:31,910 --> 00:39:35,250
这就是所谓的索引组织存储或索引组织表，

812
00:39:36,050 --> 00:39:37,830
这里的想法是，

813
00:39:38,870 --> 00:39:40,440
假设我们有一些树数据结构，

814
00:39:41,030 --> 00:39:43,440
或者可以是哈希表，现在我们假设是树，

815
00:39:44,630 --> 00:39:49,770
不是让树中的叶节点带有值，

816
00:39:49,910 --> 00:39:51,660
值为我们提供 record ID ，

817
00:39:52,130 --> 00:39:54,480
告诉我们应该去哪里，找到包含我们要查找的数据的页面，

818
00:39:54,890 --> 00:39:57,720
如果叶子它们自己只是包含 tuple 的数据页面，

819
00:39:59,300 --> 00:40:00,745
所以现在当我想要做一个查找，

820
00:40:00,745 --> 00:40:02,580
并且说帮我找到键 102 ，

821
00:40:02,990 --> 00:40:05,340
我跟随这个索引，然后到达底部，

822
00:40:06,250 --> 00:40:08,720
达到底部，

823
00:40:09,550 --> 00:40:11,240
这是我要找的索引，

824
00:40:12,365 --> 00:40:13,570
抱歉，这是我要找的数据。

825
00:40:15,590 --> 00:40:15,895
是吧？

826
00:40:15,895 --> 00:40:16,855
所以这个想法看起来就像，

827
00:40:16,855 --> 00:40:19,405
这是一个粗略的图 B 树，

828
00:40:19,405 --> 00:40:21,000
它很快就会讲到，

829
00:40:21,200 --> 00:40:23,425
这里有内部节点，然后是叶子节点，

830
00:40:23,425 --> 00:40:25,495
内部节点基本上是告诉你，

831
00:40:25,495 --> 00:40:27,420
对于给定的键，我应该向左还是向右，

832
00:40:29,040 --> 00:40:30,280
而在叶子节点本身，

833
00:40:30,900 --> 00:40:33,250
这些会看起来像插槽页面，

834
00:40:34,710 --> 00:40:35,770
但不同的是，

835
00:40:35,850 --> 00:40:41,380
我们将对页面本身基于键进行排序，

836
00:40:41,880 --> 00:40:44,170
而不仅是随机位置，

837
00:40:45,440 --> 00:40:48,270
基于我们在 slot array 中的空闲空间。

838
00:40:49,500 --> 00:40:51,410
所以，现在，当我想要查找，

839
00:40:51,410 --> 00:40:52,480
帮我查找键 102 ，

840
00:40:52,740 --> 00:40:53,830
我遍历索引，

841
00:40:54,030 --> 00:40:56,260
我到达一个叶节点，在这里弹出，

842
00:40:56,460 --> 00:41:00,010
然后我对键列表进行二分搜索，

843
00:41:00,420 --> 00:41:01,520
然后这将给我一个偏移量，

844
00:41:01,520 --> 00:41:02,890
查找我要查找的数据。

845
00:41:05,590 --> 00:41:08,300
这就是， MySQL ，当你使用 InnoDB 引擎时，

846
00:41:08,320 --> 00:41:10,410
这就是你在 SQLite 中得到的，

847
00:41:10,410 --> 00:41:11,360
这也是你得到的，

848
00:41:11,800 --> 00:41:12,950
我想我在上一节课上讲过，

849
00:41:12,970 --> 00:41:18,145
在 SQLite 中，他们有一个称为 rowid 的内部主键，

850
00:41:18,145 --> 00:41:19,740
我们可以通过 SQL 看到它，

851
00:41:19,940 --> 00:41:24,540
但它与你在表本身中定义的主键略有不同，

852
00:41:25,250 --> 00:41:27,720
因为它们使用的是索引组织存储，

853
00:41:27,980 --> 00:41:29,890
然后 rowid 是键，

854
00:41:29,890 --> 00:41:34,030
你在索引里查找一些东西。

855
00:41:35,260 --> 00:41:38,210
所以，对于逻辑主键，

856
00:41:39,040 --> 00:41:41,420
客户、学生电子邮件地址，

857
00:41:41,590 --> 00:41:42,860
我们将有一个单独的索引，

858
00:41:43,540 --> 00:41:46,640
然后将电子邮件地址映射到 rowid ，

859
00:41:46,990 --> 00:41:48,950
然后在主键索引中进行查找，

860
00:41:49,990 --> 00:41:52,720
以获得你查找的 tuple 。

861
00:41:59,790 --> 00:42:00,365
问题是，

862
00:42:00,365 --> 00:42:00,950
它是两个键，

863
00:42:00,950 --> 00:42:03,760
一个键用于进入页面，另一个键在页面内，

864
00:42:05,130 --> 00:42:06,005
不，如果我，

865
00:42:06,005 --> 00:42:09,190
如果是 SQLite ，帮我找到 rowid 等于 1 ，

866
00:42:10,060 --> 00:42:12,320
我只是遍历这个索引，键基于 rowid ，

867
00:42:13,100 --> 00:42:14,165
我登上了这页，

868
00:42:14,165 --> 00:42:15,545
现在，我需要在页面中查找，

869
00:42:15,545 --> 00:42:16,660
rowid 1 在哪里，

870
00:42:17,010 --> 00:42:20,795
我需要这样查找。

871
00:42:20,795 --> 00:42:21,610
整个树都是排序的，

872
00:42:22,950 --> 00:42:23,585
它必须是，

873
00:42:23,585 --> 00:42:25,690
因为它是一棵平衡树。

874
00:42:28,530 --> 00:42:32,560
你可以在 SQL Server 和 Oracle 中获得这个，

875
00:42:32,760 --> 00:42:33,650
但不是在默认情况下，

876
00:42:33,650 --> 00:42:34,810
你得告诉它，我想要这个，

877
00:42:36,030 --> 00:42:38,200
如果你使用 MySQL SQLite ，默认情况下会得到这个，

878
00:42:40,050 --> 00:42:40,910
我不认为你能关掉它们。

879
00:42:41,290 --> 00:42:41,690
是的。

880
00:42:48,180 --> 00:42:49,210
是的，所以他的问题是，

881
00:42:49,920 --> 00:42:50,950
这是一个很好的观点，

882
00:42:51,120 --> 00:42:53,590
这种方法是否仍然受到我们之前讨论过的事情的影响，

883
00:42:53,610 --> 00:42:59,620
比如碎片化和随机 I/O ，

884
00:43:00,090 --> 00:43:05,750
对于碎片化，是的，这是不可避免的，

885
00:43:05,750 --> 00:43:09,455
因为在 B+ 树中，它需要至少半满，

886
00:43:09,455 --> 00:43:12,220
所以你会有一堆叶节点是空的，

887
00:43:12,240 --> 00:43:13,210
这是不可避免的，

888
00:43:13,380 --> 00:43:16,210
就随机 I/O 而言，

889
00:43:17,210 --> 00:43:20,110
如果是更新到叶节点中的随机位置，

890
00:43:20,110 --> 00:43:21,270
是的，这是不可避免的，

891
00:43:21,350 --> 00:43:23,830
但如果只是插入，

892
00:43:24,480 --> 00:43:29,420
然后，使用 SQLite rowid 是一个例子，

893
00:43:29,560 --> 00:43:31,340
rowid 只是一个内部计数器，

894
00:43:31,480 --> 00:43:33,770
对于每新的 tuple ，它将递增 1 ，

895
00:43:34,000 --> 00:43:35,040
1 2 3 4 5 6 7 ，

896
00:43:35,040 --> 00:43:36,230
它是单调递增的，

897
00:43:36,670 --> 00:43:38,450
所以如果我继续插入到 SQLite ，

898
00:43:38,890 --> 00:43:42,010
我只是继续追加到树的这一边，

899
00:43:42,060 --> 00:43:43,570
不会碰树的另一边，

900
00:43:44,160 --> 00:43:46,430
所以它不会做大量的随机 I/O 那么糟糕，

901
00:43:46,430 --> 00:43:48,650
它不如做顺序 I/O 那么好，

902
00:43:48,650 --> 00:43:50,050
你从日志结构得到的，

903
00:43:50,190 --> 00:43:53,530
但它比在面向 tuple 存储中的更好，

904
00:43:53,550 --> 00:43:56,360
因为至少现在树[引导]

905
00:43:56,360 --> 00:43:58,360
只更新这边的页面，

906
00:43:59,130 --> 00:44:00,520
所以，这是有好处的。

907
00:44:02,720 --> 00:44:03,120
是的。

908
00:44:03,170 --> 00:44:08,350
问题是，

909
00:44:08,350 --> 00:44:12,595
rowid 是查找页面， key ID 是查找 tuple 吗，

910
00:44:12,595 --> 00:44:14,620
不，所以我想说的是，

911
00:44:14,620 --> 00:44:20,640
在 SQLite 中，是主键、索引，

912
00:44:21,020 --> 00:44:23,820
存储 tuple 在叶节点中，

913
00:44:23,990 --> 00:44:27,360
但是，与你在 CREATE TABLE 语句中告诉它的主键不同，

914
00:44:27,920 --> 00:44:30,630
它们有一个内部 rowid 是主键，

915
00:44:31,340 --> 00:44:34,950
所以，如果查看电子邮件地址等于 Andy ，

916
00:44:36,710 --> 00:44:38,790
还有一些其他索引将为你提供 rowid ，

917
00:44:39,260 --> 00:44:42,000
然后你使用它来遍历主键索引。

918
00:44:42,750 --> 00:44:45,245
在 MySQL innodb 中，

919
00:44:45,245 --> 00:44:46,510
他们不使用 rowid ，

920
00:44:47,520 --> 00:44:50,200
它将是 CREATE TABLE 语句中声明的真正主键，

921
00:44:50,310 --> 00:44:51,910
这将是你在这里使用的键，

922
00:44:52,350 --> 00:44:54,670
这就是你在这里的查找。

923
00:45:01,020 --> 00:45:03,550
同样，页面插槽架构，

924
00:45:03,990 --> 00:45:06,910
其中键和偏移量在一个方向上增长，

925
00:45:06,930 --> 00:45:09,460
然后 tuple 在另一个方向上增长。

926
00:45:12,280 --> 00:45:23,815
好的，在文件中存储 tuple 的三种主要方法是，

927
00:45:23,815 --> 00:45:25,620
堆存储，具有插槽页面，

928
00:45:26,030 --> 00:45:29,640
日志结构存储，带有追加和 SSTables ，[避免磁盘]，

929
00:45:29,720 --> 00:45:31,380
然后这个索引组织存储。

930
00:45:32,090 --> 00:45:34,080
还有其他的，比如 ISAM ，

931
00:45:35,150 --> 00:45:37,620
但这些是古老的或它们是遗产，

932
00:45:39,365 --> 00:45:40,090
我们不需要担心这个。

933
00:45:41,560 --> 00:45:45,470
好的，那么我们现在谈谈，

934
00:45:46,890 --> 00:45:52,150
一旦我们有，我们有了 tuple ，

935
00:45:53,430 --> 00:45:54,770
现在让我们来谈谈它里面有什么。

936
00:45:56,920 --> 00:45:59,450
所以 tuple 是一个字节序列，

937
00:46:00,590 --> 00:46:03,210
这是数据库管理系统的工作，

938
00:46:03,740 --> 00:46:06,265
基于存储在目录中的模式，

939
00:46:06,265 --> 00:46:07,710
比如当你调用 CREATE TABLE 时，

940
00:46:08,520 --> 00:46:10,580
我有这些类型的属性，

941
00:46:11,260 --> 00:46:12,555
这是数据库系统的工作，

942
00:46:12,555 --> 00:46:14,600
解释这些字节实际是什么，

943
00:46:15,160 --> 00:46:18,930
以及如何执行你想要对其执行的任何操作，

944
00:46:18,930 --> 00:46:21,800
如果我有两列， A 列加上 B 列，

945
00:46:22,360 --> 00:46:23,660
数据库系统就会知道，

946
00:46:23,680 --> 00:46:26,000
好的， A 列是一个 32 位整数，

947
00:46:26,170 --> 00:46:27,675
B 列是一个 64 位整数，

948
00:46:27,675 --> 00:46:28,580
因此，我需要做，

949
00:46:29,110 --> 00:46:33,800
基于这两种类型的加法运算符。

950
00:46:35,390 --> 00:46:36,925
所以你可以再想一想，

951
00:46:36,925 --> 00:46:40,830
只要把它想象成一个字节缓冲区，一个字符数组，

952
00:46:42,170 --> 00:46:43,015
有一些 header ，

953
00:46:43,015 --> 00:46:47,580
来跟踪它的大小，空值，

954
00:46:48,140 --> 00:46:48,540
我们稍后会讲到，

955
00:46:49,070 --> 00:46:50,680
然后在 header 完成后，

956
00:46:50,680 --> 00:46:56,440
在第一个偏移量，你会有第一个列， id 列，

957
00:46:56,970 --> 00:46:59,885
接下来，我们知道 id 是一个整数，

958
00:46:59,885 --> 00:47:01,060
所以这将是 32 位，

959
00:47:01,470 --> 00:47:04,570
然后，在 32 位之后，我们有 value ，它将是 64 位。

960
00:47:05,240 --> 00:47:07,655
所以在数据库系统内部，

961
00:47:07,655 --> 00:47:09,220
如果你想做 C++ ，

962
00:47:09,720 --> 00:47:15,755
是寻找 tuple 的起始位置，

963
00:47:15,755 --> 00:47:17,150
使用 slot array 方法，

964
00:47:17,150 --> 00:47:19,780
或者我们如何跳到页面中的那个偏移量，

965
00:47:20,610 --> 00:47:22,985
header 总是与每个 tuple 相同的大小，

966
00:47:22,985 --> 00:47:24,070
我们知道如何跳过（的 tuple），

967
00:47:24,480 --> 00:47:26,435
现在我们只做一个简单的算术运算，

968
00:47:26,435 --> 00:47:31,480
我知道我要寻找的第一列的偏移量是，

969
00:47:31,890 --> 00:47:34,330
这个 header 后面的很多位或字节，

970
00:47:34,670 --> 00:47:36,600
或者，如果我想要第二列，如何到达那里。

971
00:47:37,770 --> 00:47:38,830
varchar 有点复杂，

972
00:47:38,940 --> 00:47:41,200
你必须存储字段的长度，

973
00:47:41,520 --> 00:47:45,770
该长度可以在 header 中或者在列中，

974
00:47:46,570 --> 00:47:47,420
现在并不重要，

975
00:47:47,920 --> 00:47:48,900
但本质上你说做的，

976
00:47:48,900 --> 00:47:50,060
你只是在做一些地址，

977
00:47:50,740 --> 00:47:52,970
你做重新解释转换，

978
00:47:53,170 --> 00:47:57,110
系统本身应该处理那个地址，

979
00:47:58,180 --> 00:48:01,640
通过地址将其作为 32 位整数或 64 位整数或任何类型。

980
00:48:03,700 --> 00:48:06,080
那是数据库引擎做的解释吗？

981
00:48:06,700 --> 00:48:08,670
是的，还会有谁来做这件事，

982
00:48:11,350 --> 00:48:12,615
我们编写 SQL ，

983
00:48:12,615 --> 00:48:14,535
SQL ，这里没有解释 SQL 解释，

984
00:48:14,535 --> 00:48:15,440
这就是实现。

985
00:48:18,470 --> 00:48:20,005
这门课就是我们在做这件事，

986
00:48:20,005 --> 00:48:22,080
而不是 JavaScript 程序员。

987
00:48:24,790 --> 00:48:27,530
好的，上节课有人提出了这个问题，

988
00:48:28,270 --> 00:48:29,235
这是一个很好的话题，

989
00:48:29,235 --> 00:48:30,440
我想把它包括进去，

990
00:48:30,520 --> 00:48:33,280
它是，我们现在需要注意的一件事，

991
00:48:35,180 --> 00:48:38,130
当我们开始存储这些比特时，处理对齐，

992
00:48:39,430 --> 00:48:42,680
以确保我们存储的数据对齐，

993
00:48:44,800 --> 00:48:47,250
与 CPU 实际想要如何操作数据。

994
00:48:49,150 --> 00:48:49,970
那么我说的是什么意思？

995
00:48:51,350 --> 00:48:52,555
我使用 AndySux 原因是，

996
00:48:52,555 --> 00:48:54,060
人们拿了我的幻灯片，

997
00:48:54,230 --> 00:48:55,590
他们不知道 AndySux 是什么意思，

998
00:48:55,670 --> 00:49:01,140
所以，在 Google 上搜索，你就能找到是谁复制了它。

999
00:49:01,140 --> 00:49:04,665
所以，我们需要确保，

1000
00:49:04,665 --> 00:49:09,590
我们的所有属性都基于 CPU 的单词边界，

1001
00:49:09,880 --> 00:49:11,450
或我们运行的任何体系结构来对齐，

1002
00:49:11,980 --> 00:49:15,495
以确保我们不会出现意外的行为，

1003
00:49:15,495 --> 00:49:17,150
在对这些数据进行操作时，

1004
00:49:19,020 --> 00:49:20,980
而且 CPU 不需要做额外的工作。

1005
00:49:22,450 --> 00:49:24,315
假设我有一张表，

1006
00:49:24,315 --> 00:49:25,340
我这里有四个列，

1007
00:49:25,630 --> 00:49:30,290
我有 32 位整数， 64 位时间戳，

1008
00:49:30,550 --> 00:49:34,010
一个 4 字节字符，然后是一个 zipcode 。

1009
00:49:34,690 --> 00:49:38,310
假设我们要分解我们的 char array ，

1010
00:49:38,310 --> 00:49:40,430
把这个 tuple 表示成 64 位字，

1011
00:49:40,720 --> 00:49:42,260
高速缓存行是 64 字节的，

1012
00:49:43,180 --> 00:49:45,350
但是 Postgres 行是基于 64 位的，

1013
00:49:45,610 --> 00:49:47,180
我不知道 SQLite 做的，

1014
00:49:48,380 --> 00:49:51,680
但他们都在做一些这个的变体。

1015
00:49:51,680 --> 00:49:53,315
所以我要做的第一件事是，

1016
00:49:53,315 --> 00:49:55,390
我们有，对于 id 列，那是 32 位，

1017
00:49:55,620 --> 00:49:56,440
我们把它存储在那里，

1018
00:49:56,790 --> 00:50:01,445
然后我们有这个 date 时间戳，创建日期，它是 64 位，

1019
00:50:01,445 --> 00:50:03,130
所以我们在那之后存储它，

1020
00:50:03,270 --> 00:50:06,190
以此类推，还有其他的。

1021
00:50:07,480 --> 00:50:11,000
所以，现在当我想在系统中进行查找时，

1022
00:50:11,110 --> 00:50:15,110
对我为这个 tuple 获得的数组进行一些操作，

1023
00:50:15,280 --> 00:50:17,420
比如客户日期，创建日期，

1024
00:50:18,230 --> 00:50:19,360
这样做的问题在于，

1025
00:50:19,360 --> 00:50:24,685
那个属性将跨越两个字，

1026
00:50:24,685 --> 00:50:26,700
因为每个字都是 64 位，

1027
00:50:26,960 --> 00:50:28,860
第一个 id 字段为 32 位，

1028
00:50:29,060 --> 00:50:31,710
所以这个 64 位跨越两个连续的字。

1029
00:50:33,770 --> 00:50:35,700
有人知道当你在 CPU 中这样做的时候，会发生什么吗，

1030
00:50:36,290 --> 00:50:37,780
当你试图跳到一个内存地址，

1031
00:50:37,780 --> 00:50:40,860
并对一些跨越字边界的东西进行操作时，

1032
00:50:45,340 --> 00:50:46,490
x86 是怎么做的？

1033
00:50:50,140 --> 00:50:53,340
所以 x86 ， Intel 喜欢让你的生活变得轻松，

1034
00:50:53,340 --> 00:50:54,680
而不必担心这些事情，

1035
00:50:55,210 --> 00:50:58,490
所以他们会为你做额外的读取，

1036
00:50:59,140 --> 00:50:59,955
他们想把它隐藏起来，

1037
00:50:59,955 --> 00:51:03,110
他们想要隐藏架构的所有的复杂性，

1038
00:51:03,970 --> 00:51:05,235
所以他们会做额外的工作，

1039
00:51:05,235 --> 00:51:07,010
但现在这会使你的数据库系统运行较慢，

1040
00:51:07,030 --> 00:51:08,450
因为这本来应该是，

1041
00:51:08,560 --> 00:51:11,685
一个寄存器读取或一个高速缓存行读取，

1042
00:51:11,685 --> 00:51:14,390
去获取一些东西到 CPU 寄存器中，

1043
00:51:14,950 --> 00:51:16,430
现在会是两个高速缓存行读取，

1044
00:51:19,030 --> 00:51:20,145
但是，这是没有错误的，

1045
00:51:20,145 --> 00:51:22,130
这只是 Intel 帮你处理的。

1046
00:51:23,010 --> 00:51:25,510
但并不是每个系统、每个架构都会这样做，

1047
00:51:25,890 --> 00:51:28,480
以前，在 ARM 之中，

1048
00:51:29,580 --> 00:51:31,780
他们会拒绝它，

1049
00:51:31,890 --> 00:51:35,710
它们会识别出你正在尝试执行未对齐的操作，

1050
00:51:36,240 --> 00:51:37,930
然后抛出一个错误，希望您能捕捉到，

1051
00:51:37,980 --> 00:51:40,630
现在，在较新的版本中，我认为是 ARM 7 ，

1052
00:51:40,830 --> 00:51:42,880
他们现在处理像 Intel 一样，

1053
00:51:45,240 --> 00:51:47,420
但是，它只是慢了一点。

1054
00:51:49,000 --> 00:51:50,810
这很罕见，但可能发生的情况是，

1055
00:51:51,220 --> 00:51:54,290
它将为你进行读取，

1056
00:51:55,420 --> 00:51:58,730
但不能保证位将以正确的顺序到达。

1057
00:51:59,560 --> 00:52:00,410
所以回到这里，

1058
00:52:00,850 --> 00:52:03,020
我必须进行两次读取，才能得到这个字和这个字，

1059
00:52:03,850 --> 00:52:06,950
从而将 date 属性组合在一起，

1060
00:52:06,970 --> 00:52:09,920
它可能会把后面的位放在另一个的前面，

1061
00:52:10,990 --> 00:52:11,940
这似乎是个糟糕的主意，

1062
00:52:11,940 --> 00:52:14,120
但老式的 CPU 会这么做。

1063
00:52:14,770 --> 00:52:16,845
当然，这意味着现在你的程序出现一种随机错误，

1064
00:52:16,845 --> 00:52:18,530
而且搞砸了数据，

1065
00:52:19,000 --> 00:52:20,310
人们会注意到并抱怨，

1066
00:52:20,310 --> 00:52:20,930
这是不好的。

1067
00:52:21,220 --> 00:52:23,640
这也是 Intel 试图对你隐瞒这一点的部分原因，

1068
00:52:23,640 --> 00:52:25,010
尽管它会让你的东西运行得更慢。

1069
00:52:27,170 --> 00:52:28,410
所以我们需要确保，

1070
00:52:29,180 --> 00:52:30,565
我们的 tuple 没有任何属性，

1071
00:52:30,565 --> 00:52:32,250
在我们的字节数组中，

1072
00:52:32,420 --> 00:52:34,590
因为现在，我们讨论的是带入内存的东西，

1073
00:52:35,390 --> 00:52:37,740
它们中没有一个会跨越这些界限。

1074
00:52:39,750 --> 00:52:42,880
所以，处理这个问题的两种方法是填充或重新排序。

1075
00:52:43,670 --> 00:52:47,485
所以，对于填充，基本的想法是，

1076
00:52:47,485 --> 00:52:48,330
意识到，

1077
00:52:48,800 --> 00:52:51,210
如果我要拆分 64 位字，

1078
00:52:51,590 --> 00:52:53,640
当我添加属性跨越时，

1079
00:52:54,140 --> 00:52:57,870
如果我意识到下一个属性不适合我的单个字，

1080
00:52:58,810 --> 00:53:00,720
然后我只需要在那里放一堆零，把它填满，

1081
00:53:01,580 --> 00:53:03,460
然后在内部，系统的[记录]，

1082
00:53:03,460 --> 00:53:05,605
当它解释这些字节时，

1083
00:53:05,605 --> 00:53:08,910
它知道，好的，我需要这个 id ，

1084
00:53:09,230 --> 00:53:12,835
然后是 date 属性，这将是下一个字，

1085
00:53:12,835 --> 00:53:14,970
所以忽略这 32 位就行了。

1086
00:53:20,050 --> 00:53:21,770
另一种方法是重新排序。

1087
00:53:24,080 --> 00:53:26,560
我不认为，大多数系统不会自动完成这项工作，

1088
00:53:27,270 --> 00:53:31,235
我们建立的一些学术系统，会自动完成这个，

1089
00:53:31,235 --> 00:53:33,815
但大多数系统会准确地列出你说的内容，

1090
00:53:33,815 --> 00:53:36,220
然后添加填充物，以使其更好。

1091
00:53:37,140 --> 00:53:38,170
所以这里的想法是，

1092
00:53:38,850 --> 00:53:43,720
如果我看到表的逻辑视图，

1093
00:53:43,800 --> 00:53:45,160
不管 CREATE TABLE 语句定义了什么，

1094
00:53:45,360 --> 00:53:47,260
我会告诉你东西按这个顺序排序，

1095
00:53:47,700 --> 00:53:50,200
但在幕后，我会移动东西，

1096
00:53:51,930 --> 00:53:53,200
这样我就可以更好地打包东西，

1097
00:53:53,640 --> 00:53:56,470
然后，如果需要，我会在末尾添加一些像这样的位。

1098
00:53:57,350 --> 00:53:57,750
是的。

1099
00:54:02,720 --> 00:54:04,860
这个问题是， varchar 如何处理这种情况的？

1100
00:54:07,470 --> 00:54:08,320
是的，对于填充。

1101
00:54:12,050 --> 00:54:12,395
这就是我说的，

1102
00:54:12,395 --> 00:54:17,230
所以，在执行自动重新排序的系统中，

1103
00:54:17,490 --> 00:54:19,240
你不会将 varchar 存储在一行，

1104
00:54:19,650 --> 00:54:21,760
除非它们是 64 位或更少，

1105
00:54:22,520 --> 00:54:24,550
取而代之的是，你存储一个指向其他位置的指针，

1106
00:54:25,290 --> 00:54:27,340
我们稍后会看到，

1107
00:54:27,420 --> 00:54:33,530
这些外部的，这些超大的属性表或页面是分开的，

1108
00:54:33,530 --> 00:54:34,610
所以，你可以进行这种重新排序，

1109
00:54:34,610 --> 00:54:36,790
而不必担心可变长度的事情。

1110
00:54:42,250 --> 00:54:44,520
问题是，我需要最后这个东西吗，

1111
00:54:44,520 --> 00:54:45,135
我需要这个吗，

1112
00:54:45,135 --> 00:54:45,500
不。

1113
00:54:51,000 --> 00:54:52,810
所以，我们可以在 Postgres 中看到这个，

1114
00:54:53,860 --> 00:54:56,180
Postgres 不会进行自动重新排序，

1115
00:54:56,290 --> 00:54:58,280
但会进行填充，

1116
00:55:00,130 --> 00:55:01,980
我们可以看到一些简单的事情，

1117
00:55:01,980 --> 00:55:05,230
如果我们重新排序，

1118
00:55:07,420 --> 00:55:11,120
当我们重新排序 CREATE TABLE 保存的东西或重新排序 tuple 时，

1119
00:55:11,740 --> 00:55:14,180
我们可以在更小的空间内存储东西。

1120
00:55:17,180 --> 00:55:17,580
所以。

1121
00:55:19,980 --> 00:55:21,575
所以这里是更多的 Postgres 语法，

1122
00:55:21,575 --> 00:55:24,370
Postgres 有一个很好的小函数，叫做 row ，

1123
00:55:24,990 --> 00:55:28,840
本质上它只接受你给它的逗号分隔的值列表，

1124
00:55:29,610 --> 00:55:30,820
它会做一个行，

1125
00:55:32,190 --> 00:55:33,680
然后我们可以对它转码，

1126
00:55:33,680 --> 00:55:38,710
现在我们可以在所有值的末尾加上 :: 的东西，

1127
00:55:39,510 --> 00:55:44,570
这基本上是将值转换为给定的类型，

1128
00:55:44,830 --> 00:55:48,900
所以我可以做一个小整数，一个常规整数和一个大整数，

1129
00:55:48,900 --> 00:55:53,750
所以是两个字节的整型，四个字节的整型，或者八个字节的整型。

1130
00:55:54,760 --> 00:56:00,580
现在 Postgres 有一个很好的小函数，名为 pg_column_size ，

1131
00:56:01,350 --> 00:56:06,310
它会告诉你这个记录、这个 tuple 的大小，以字节为单位。

1132
00:56:06,870 --> 00:56:07,780
所以在这个例子中，

1133
00:56:08,490 --> 00:56:10,690
它告诉我创建的行的大小，以字节为单位，

1134
00:56:10,950 --> 00:56:12,460
如果我返回到前一个，

1135
00:56:14,930 --> 00:56:15,600
并运行。

1136
00:56:21,370 --> 00:56:21,770
是的。

1137
00:56:23,490 --> 00:56:23,890
抱歉。

1138
00:56:29,760 --> 00:56:31,240
回到以前的那个行，

1139
00:56:31,590 --> 00:56:34,300
没有进行类型转换，

1140
00:56:34,920 --> 00:56:36,960
告诉我是 36 ，

1141
00:56:36,960 --> 00:56:37,575
这说得通，

1142
00:56:37,575 --> 00:56:41,405
因为，这里最后一个，

1143
00:56:41,405 --> 00:56:44,980
我把它转换成 64 位整数，

1144
00:56:45,360 --> 00:56:46,760
或者在这里是 Postgres ，

1145
00:56:46,760 --> 00:56:49,930
它将其存储为 8 字节，

1146
00:56:50,310 --> 00:56:52,720
4 字节的整数和 32 位的整数，

1147
00:56:52,950 --> 00:56:55,270
然后有一些额外的空间用于填充。

1148
00:56:57,920 --> 00:56:58,970
所以我们现在可以看到，

1149
00:56:58,970 --> 00:57:00,250
如果我们取一个，

1150
00:57:04,730 --> 00:57:06,360
让我先做一下，不要大小，

1151
00:57:07,075 --> 00:57:07,650
所以，让我们来创建一个行，

1152
00:57:10,020 --> 00:57:17,470
它有一些字符，然后是两个字节、四个字节和八个字节的整数，

1153
00:57:17,970 --> 00:57:23,290
但我把字符和整数混在一起了，

1154
00:57:24,280 --> 00:57:25,275
所以现在如果我说，

1155
00:57:25,275 --> 00:57:29,420
我想， Postgres ，这个有多大，我得到 48 字节，

1156
00:57:30,570 --> 00:57:33,110
但如果我把所有的整数放在第一位，

1157
00:57:33,110 --> 00:57:34,900
重新排序，就像我之前展示的那样，

1158
00:57:35,800 --> 00:57:37,460
然后把所有的字符都放在最后，

1159
00:57:37,840 --> 00:57:39,200
现在我只剩下 44 字节，

1160
00:57:40,490 --> 00:57:42,120
因为 Postgres 必须填充内容，

1161
00:57:42,230 --> 00:57:44,070
以确保所有内容都是 64 位对齐的。

1162
00:57:45,400 --> 00:57:47,270
但它不会自动为你做到这一点，

1163
00:57:47,290 --> 00:57:48,060
你必须这么做，

1164
00:57:48,060 --> 00:57:49,520
你必须告诉 Postgres 我想要这个，

1165
00:57:50,170 --> 00:57:52,610
再说一次，有一些系统可以自动为你做这件事。

1166
00:57:55,710 --> 00:57:56,230
能理解吗？

1167
00:57:57,120 --> 00:57:57,860
同样，我喜欢这个，

1168
00:57:57,860 --> 00:57:59,765
因为我们可以只执行 SQL 命令，

1169
00:57:59,765 --> 00:58:01,150
我们可以得到一个，

1170
00:58:01,770 --> 00:58:06,035
我们可以稍微了解一下数据库系统存储管理器的内部结构，

1171
00:58:06,035 --> 00:58:07,810
以了解它实际是如何放置的。

1172
00:58:09,110 --> 00:58:09,510
好的？

1173
00:58:14,440 --> 00:58:16,080
好的，现在让我们来讨论一下，

1174
00:58:16,790 --> 00:58:17,590
我们讨论了整数，

1175
00:58:17,590 --> 00:58:20,640
我们稍微讨论了一点 varchar ，

1176
00:58:20,930 --> 00:58:23,820
让我们讨论一个其他核心的 SQL 数据类型，

1177
00:58:23,960 --> 00:58:26,040
以及数据库系统是如何表示它们的。

1178
00:58:27,500 --> 00:58:29,010
所以对于所有的整型数据类型，

1179
00:58:29,450 --> 00:58:30,880
它们本质上是（与 C++ 中）相同的，

1180
00:58:30,880 --> 00:58:39,750
当你在 C++ 中分配一个整型变量，一个大整型，不管什么，

1181
00:58:40,280 --> 00:58:41,820
它将是相同的表示，

1182
00:58:41,990 --> 00:58:44,250
因为这是硬件所支持的，

1183
00:58:45,050 --> 00:58:46,170
硬件将会有，

1184
00:58:46,310 --> 00:58:50,670
这里有一个标准，表示，

1185
00:58:51,170 --> 00:58:53,820
对于任何 2 的补码整数是有符号的还是无符号的，

1186
00:58:54,200 --> 00:58:56,305
无论你在 C++ 中得到什么，都遵循标准，

1187
00:58:56,305 --> 00:58:57,460
这就是硬件支持的，

1188
00:58:57,460 --> 00:59:00,630
这就是你在 SQL 中得到的。

1189
00:59:02,190 --> 00:59:06,220
对于浮点数或定点数，

1190
00:59:07,020 --> 00:59:08,860
会有浮点数或实数，

1191
00:59:09,180 --> 00:59:12,095
这也是在 IEEE-754 标准中定义的，

1192
00:59:12,095 --> 00:59:16,570
它规定了硬件应该如何表示这些小数，

1193
00:59:17,250 --> 00:59:21,940
但每个数据库系统也有所谓的定点小数，即 NUMERIC 或 DECIMAL 。

1194
00:59:22,520 --> 00:59:25,480
这些实现在每个系统中都是不同的，

1195
00:59:26,820 --> 00:59:30,190
我们可以稍后会看到这两种方法的性能差异。

1196
00:59:31,350 --> 00:59:34,090
对于 VARCHAR VARBINARY TEXT 和 BLOB ，

1197
00:59:34,320 --> 00:59:38,390
这些通常存储为带有 header 的东西，

1198
00:59:38,390 --> 00:59:39,460
header 会告诉你它的长度，

1199
00:59:39,780 --> 00:59:43,690
后跟实际值的字节，

1200
00:59:44,370 --> 00:59:48,820
或者如果它太大而无法存储在页面内的 tuple 本身中，

1201
00:59:49,320 --> 00:59:55,130
这里会有一个指针指向包含这个属性所需数据的其他页面，

1202
00:59:55,780 --> 00:59:57,390
如我所说的，对于内存中系统，

1203
00:59:57,590 --> 01:00:00,840
如果它少于 64 位，

1204
01:00:01,070 --> 01:00:03,025
他们会将其存储在行中，

1205
01:00:03,025 --> 01:00:04,500
如果不是，他们将存储一个指针，

1206
01:00:05,180 --> 01:00:08,670
在基于磁盘的数据库系统中，

1207
01:00:08,840 --> 01:00:10,020
这将取决于实现情况，

1208
01:00:10,980 --> 01:00:12,310
我们将在稍后看到。

1209
01:00:12,920 --> 01:00:16,000
对于时间戳、日期和间隔等，

1210
01:00:16,290 --> 01:00:19,300
这些通常是 32 位或 64 位整数，

1211
01:00:19,500 --> 01:00:25,480
这只是从 Unix 纪元（1970年1月1日）以来的毫秒数或微秒数，

1212
01:00:27,240 --> 01:00:31,060
如果你想要使用时间戳信息来存储它，

1213
01:00:31,590 --> 01:00:37,420
通常他们会基于 UTC 时间戳（GMT 0）来存储，

1214
01:00:38,100 --> 01:00:39,620
然后他们存储额外的元数据，

1215
01:00:39,620 --> 01:00:40,780
比如你所在的时间戳，

1216
01:00:40,920 --> 01:00:42,640
他们可以根据需要进行转换，

1217
01:00:42,990 --> 01:00:44,410
系统会为你处理这一点。

1218
01:00:47,040 --> 01:00:52,750
所以对于上面这些类型，整数类型，

1219
01:00:53,010 --> 01:00:55,120
因为我们依赖硬件来存储，

1220
01:00:56,250 --> 01:00:58,420
存储数据，以硬件想要如何表示它的方式，

1221
01:00:58,980 --> 01:01:01,730
这通常意味着你不能复制文件，

1222
01:01:01,960 --> 01:01:03,980
比如你生成的原始数据库文件，

1223
01:01:04,630 --> 01:01:06,570
从一个架构到另一个架构，

1224
01:01:06,570 --> 01:01:09,750
比如，如果它是大端模式或小端模式，

1225
01:01:09,750 --> 01:01:13,850
比如 x86 是小端模式， Power 和 ARM 是大端模式，

1226
01:01:14,080 --> 01:01:17,240
你不能从数据库中提取二进制文件并将其放到另一个，

1227
01:01:17,380 --> 01:01:20,120
因为位会被翻转，它会被搞乱。

1228
01:01:21,710 --> 01:01:22,980
SQLite 避免了这个问题，

1229
01:01:23,090 --> 01:01:26,160
因为他们把所有东西都存储为 varchar 。

1230
01:01:27,190 --> 01:01:31,310
在运行时，它们根据属性中的类型进行转换，

1231
01:01:31,950 --> 01:01:34,690
因为这样他们就能得到可移植性的保证，

1232
01:01:34,830 --> 01:01:37,810
无论你把文件放在哪里，

1233
01:01:38,520 --> 01:01:40,660
他们总是会有正确的顺序。

1234
01:01:43,010 --> 01:01:45,360
所以，花一点时间讨论一下浮点数、实数和小数，

1235
01:01:45,800 --> 01:01:49,140
这是一个很好的例子，

1236
01:01:49,140 --> 01:01:51,380
说明数据库系统将在哪里做一些不同的事情，

1237
01:01:52,750 --> 01:01:57,980
你不能仅仅依靠硬件来为你做某些事情，

1238
01:01:57,980 --> 01:02:00,370
因为我们关心数据的正确性，

1239
01:02:00,750 --> 01:02:02,500
而硬件不能为我们保证这一点。

1240
01:02:05,410 --> 01:02:08,600
好的，所以对于可变精度数字，

1241
01:02:08,710 --> 01:02:10,200
就像以前的整数一样，

1242
01:02:10,200 --> 01:02:14,510
我们将依赖于 C++ 实现，

1243
01:02:14,800 --> 01:02:17,450
所以如果你在 SQL 中调用浮点、实数或双精度数，

1244
01:02:17,770 --> 01:02:21,860
你会得到和 C++ 一样的浮点数或双精度数，

1245
01:02:23,460 --> 01:02:27,005
通常情况下，这些会比定点数快，

1246
01:02:27,005 --> 01:02:27,760
我们一会儿就会看到，

1247
01:02:28,170 --> 01:02:30,040
因为硬件本身就能支持这个。

1248
01:02:33,770 --> 01:02:35,130
但问题是，

1249
01:02:35,500 --> 01:02:36,180
他们不会有，

1250
01:02:38,160 --> 01:02:40,450
它们不能保证数值的正确性，

1251
01:02:40,530 --> 01:02:41,950
当你开始进行更大的计算时，

1252
01:02:42,330 --> 01:02:43,220
因为四舍五入问题，

1253
01:02:43,220 --> 01:02:47,320
因为你不能在硬件中存储准确的小数。

1254
01:02:48,740 --> 01:02:49,705
所以每个人都可能见过，

1255
01:02:49,705 --> 01:02:52,420
像这样一个简单的测试程序，

1256
01:02:52,420 --> 01:02:54,000
当你第一次学习 C 或 C++ 时，

1257
01:02:54,710 --> 01:02:57,210
我有两个浮点数， 32 位浮点数，

1258
01:02:57,500 --> 01:02:59,550
我有 0.1 和 0.2 ，

1259
01:02:59,840 --> 01:03:02,760
然后我将它们相加，看看输出是什么，

1260
01:03:03,710 --> 01:03:04,450
所以在第一个版本中，

1261
01:03:04,450 --> 01:03:09,430
我只是调用 printf 来计算 x+y ，

1262
01:03:09,480 --> 01:03:13,600
我会得到一个应该是 0.3 的值，

1263
01:03:14,690 --> 01:03:18,480
当我运行它的时候，它看起来是好的，

1264
01:03:19,190 --> 01:03:24,870
但是实际上，如果我增加位数，

1265
01:03:25,220 --> 01:03:27,660
在我的 printf 语句中输出的（位数），

1266
01:03:28,190 --> 01:03:31,330
现在我得到的东西看起来像这样。

1267
01:03:33,190 --> 01:03:35,810
因为，硬件并不能准确地表示 0.3 ，

1268
01:03:36,130 --> 01:03:38,180
它会在此基础上有一些近似值。

1269
01:03:39,130 --> 01:03:42,750
所以，好的，如果我做一个简单的程序，像之前一样，

1270
01:03:42,750 --> 01:03:44,000
我只做 x+y ，

1271
01:03:44,110 --> 01:03:45,530
然后我把它打印出来给一个人，

1272
01:03:45,820 --> 01:03:47,780
是的，当然，也许这没什么大不了的，

1273
01:03:48,100 --> 01:03:50,325
但如果我在做复杂的计算，

1274
01:03:50,325 --> 01:03:51,710
因为我想在月球上着陆，

1275
01:03:52,150 --> 01:03:53,865
或者把卫星放到太空，

1276
01:03:53,865 --> 01:03:56,000
或者如果这是你的银行账户，你在计算利息，

1277
01:03:56,740 --> 01:03:59,130
那么这个舍入误差实际上很重要，

1278
01:03:59,720 --> 01:04:00,570
人们会注意到并抱怨。

1279
01:04:02,940 --> 01:04:07,360
所以，数据库系统也将提供这些固定精度的定点小数，

1280
01:04:07,710 --> 01:04:11,270
数据库系统将做更多额外的工作，

1281
01:04:11,270 --> 01:04:14,050
以确保你不会有这些舍入误差，

1282
01:04:14,400 --> 01:04:16,930
你可以在 Java 中使用 BigDecimal 获得这个，

1283
01:04:17,070 --> 01:04:21,130
你可以在 Python 中使用 Decimal 得到它，

1284
01:04:21,810 --> 01:04:24,860
基本上所有不同的系统都会做一些略有不同的事情，

1285
01:04:24,860 --> 01:04:25,640
但在更高的级别上，

1286
01:04:25,640 --> 01:04:27,610
从本质上讲，它们将存储一个，

1287
01:04:28,580 --> 01:04:31,890
非常类似于你试图表示的数字的表示，

1288
01:04:32,600 --> 01:04:35,170
然后，附加的元数据会告诉你小数点的位置，

1289
01:04:35,170 --> 01:04:36,610
或者它是有符号的还是无符号的，

1290
01:04:36,610 --> 01:04:37,225
或者是否是负数，

1291
01:04:37,225 --> 01:04:38,850
或者不是数字等等。

1292
01:04:40,370 --> 01:04:41,680
我们必须做这项额外的工作，

1293
01:04:41,680 --> 01:04:43,320
因为硬件不能为我们保证这个。

1294
01:04:45,320 --> 01:04:46,410
所以，这是 Postgres 所做的，

1295
01:04:46,610 --> 01:04:48,145
这是 Postgres 中的 numeric 类型，

1296
01:04:48,145 --> 01:04:49,530
这实际上来自源代码本身，

1297
01:04:49,970 --> 01:04:51,115
你可以看到，

1298
01:04:51,115 --> 01:04:54,300
它们将把数字的类型表示为某种结构，

1299
01:04:54,770 --> 01:04:58,200
带有一堆关于数字实际是什么的附加元数据，

1300
01:04:58,910 --> 01:05:03,300
但他们内部存储的核心内容与元数据一起，

1301
01:05:03,320 --> 01:05:04,890
这里是如何存储实际数字本身，

1302
01:05:05,240 --> 01:05:08,130
是这里这个 NumericDigit 数组，

1303
01:05:08,420 --> 01:05:10,810
这只是上面一个无符号字符的类型转换，

1304
01:05:10,810 --> 01:05:14,990
所以他们真的在存储你的小数作为字符串值，

1305
01:05:15,940 --> 01:05:17,850
然后他们使用这些元数据来找出，

1306
01:05:18,810 --> 01:05:21,850
如何将这个字符串解释为正确的形式。

1307
01:05:24,320 --> 01:05:26,230
再说一次，硬件对此一无所知，

1308
01:05:26,230 --> 01:05:28,020
这是数据库系统实现的，

1309
01:05:28,370 --> 01:05:31,410
所以我们不能只做 x+y ，在 C++ 中，

1310
01:05:31,850 --> 01:05:34,050
我们必须做更复杂的算术，

1311
01:05:34,160 --> 01:05:38,640
你想要开始计算，或者在查询中使用这些数字类型，

1312
01:05:39,170 --> 01:05:44,340
所以，这是两个 Postgres 中 numeric 的加法函数的一个简短片段，

1313
01:05:44,810 --> 01:05:45,625
正如你所看到的，

1314
01:05:45,625 --> 01:05:47,340
对于这个结构，有一堆检查，

1315
01:05:48,200 --> 01:05:51,300
看它是零还是负的，或者是有符号的，或者别的什么，

1316
01:05:51,680 --> 01:05:53,280
这只是将两个数字相加，

1317
01:05:54,210 --> 01:05:59,830
这显然比在 CPU 中调用单个指令 x+y 要昂贵得多，

1318
01:06:02,330 --> 01:06:08,070
我不想让人觉得我在羞辱 Postgres ，

1319
01:06:08,420 --> 01:06:10,230
MySQL 也有同样的问题，

1320
01:06:10,550 --> 01:06:11,440
他们在做同样的事情，

1321
01:06:11,440 --> 01:06:15,095
他们会把他们的，将他们的数字设置为 varchar ，

1322
01:06:15,095 --> 01:06:16,810
可以将其存储为 32 位整数，

1323
01:06:16,830 --> 01:06:22,060
但同样，他们有额外的元数据来跟踪实际的 numeric 类型，

1324
01:06:22,260 --> 01:06:24,130
就像 Postgres ，他们有，

1325
01:06:25,020 --> 01:06:30,320
他们自己的实现做额外检查。

1326
01:06:32,900 --> 01:06:35,340
这并不性感，但你确实需要它，

1327
01:06:37,610 --> 01:06:38,550
所以，为了节省时间，

1328
01:06:38,600 --> 01:06:39,385
如果我们最后有时间，

1329
01:06:39,385 --> 01:06:41,940
最后我们可以做一个 demo 向你展示性能差异，

1330
01:06:42,200 --> 01:06:44,400
但这是大约是 2x ，

1331
01:06:44,660 --> 01:06:50,410
数据库实现的这些 decimal 的版本，

1332
01:06:50,410 --> 01:06:53,630
它将大约比硬件版本慢 2x 倍。

1333
01:06:57,690 --> 01:07:01,400
好的，对于空值，最常见的方法是，

1334
01:07:01,400 --> 01:07:02,620
对于每一个 tuple ，

1335
01:07:03,090 --> 01:07:05,240
在 header 中都会有一个位图，

1336
01:07:05,240 --> 01:07:10,720
跟踪给定的 tuple 的哪些属性被设置为空值，

1337
01:07:11,520 --> 01:07:18,080
同样， header 这个位图的大小将根据你拥有的属性的数量而变化，

1338
01:07:18,340 --> 01:07:20,850
我们知道它是否可能为空，

1339
01:07:20,850 --> 01:07:23,730
因为它在 CREATE TABLE 语句中，

1340
01:07:23,870 --> 01:07:27,690
使用模式而不是存储 Json 在那里的优点，

1341
01:07:27,920 --> 01:07:28,690
我们有一个模式，

1342
01:07:28,690 --> 01:07:31,770
我们知道一个列是否被定义为非空，

1343
01:07:32,000 --> 01:07:36,490
因此，如果它被声明为非空，

1344
01:07:36,490 --> 01:07:37,770
我们不需要存储这个位图，

1345
01:07:38,360 --> 01:07:40,110
或者你不存储它的条目。

1346
01:07:40,710 --> 01:07:42,010
所以这是最常见的方法，

1347
01:07:42,330 --> 01:07:44,225
这确实意味着有一些开销，

1348
01:07:44,225 --> 01:07:45,695
对于每个单独的 tuple ，

1349
01:07:45,695 --> 01:07:49,090
在 header 中，我们都必须有这个位图。

1350
01:07:51,240 --> 01:07:53,440
不太常见，但另一种方法是，

1351
01:07:54,540 --> 01:07:55,480
设置特殊的值，

1352
01:07:56,190 --> 01:08:00,850
你可以说在每种类型的值范围内有一些值，

1353
01:08:01,320 --> 01:08:02,585
如果我有那个值，

1354
01:08:02,585 --> 01:08:05,410
那么我会假设它是空值。

1355
01:08:06,430 --> 01:08:10,250
所以如果我想知道一个 32 位的整数是不是空值，

1356
01:08:10,540 --> 01:08:14,810
我会说 32 位的最小值可以有的是，不管是什么负值，

1357
01:08:15,700 --> 01:08:18,170
如果我的值是那个，那么我会认为它是空值。

1358
01:08:19,120 --> 01:08:21,050
所以它少了一个我可以潜在存储的价值，

1359
01:08:21,220 --> 01:08:22,770
现在有一堆额外的事情，

1360
01:08:22,770 --> 01:08:24,710
我必须在我的系统的其余部分中做，

1361
01:08:25,000 --> 01:08:28,820
来跟踪，好的，如果我看的是 32 位整数，

1362
01:08:28,930 --> 01:08:31,340
如果它是最小值，我知道它是空值，

1363
01:08:31,390 --> 01:08:33,770
不让人们随意插入它。

1364
01:08:35,960 --> 01:08:36,930
最糟糕的选择，

1365
01:08:37,400 --> 01:08:39,960
我没有截图，

1366
01:08:41,330 --> 01:08:45,150
我所见过的只有一个系统做的最糟糕的选择是，

1367
01:08:45,920 --> 01:08:47,730
对于每个单独的 tuple ，

1368
01:08:47,750 --> 01:08:49,440
抱歉， tuple 中的每个单独的属性，

1369
01:08:49,520 --> 01:08:52,140
在它前面都有一个小的标志，告诉你它是否为空，

1370
01:08:54,770 --> 01:08:56,635
这很糟糕的原因是，

1371
01:08:56,635 --> 01:09:01,105
当我们谈到对齐时，

1372
01:09:01,105 --> 01:09:08,170
我不能有一个 32 位的整数，然后在它前面放一位，

1373
01:09:08,170 --> 01:09:09,510
来表示，这个东西是不是空的，

1374
01:09:09,680 --> 01:09:10,830
我必须存储另一个字节，

1375
01:09:11,710 --> 01:09:13,070
所以现在我所有的 32 位整数，

1376
01:09:13,330 --> 01:09:14,820
如果我想成为 64 位的行，

1377
01:09:14,820 --> 01:09:15,960
可能必须存储双倍大小，

1378
01:09:15,960 --> 01:09:19,170
所以为了存储 32 位整数，为了跟踪这个空值，

1379
01:09:19,170 --> 01:09:20,415
如果我把这个标志放在它前面，

1380
01:09:20,415 --> 01:09:21,780
他们必须存储另外 32 位，

1381
01:09:21,780 --> 01:09:23,600
只需要有一位来判断它是否为空值。

1382
01:09:26,060 --> 01:09:27,300
我有截图吗，让我看看，

1383
01:09:27,320 --> 01:09:32,130
我所知道的唯一做这个的系统是 MemSQL ，

1384
01:09:32,600 --> 01:09:37,660
它是 SingleStore 的早期名称，

1385
01:09:38,010 --> 01:09:40,450
尽管他们赞助了课程，

1386
01:09:41,280 --> 01:09:42,575
我没有截图在这里，

1387
01:09:42,575 --> 01:09:43,270
我会放在 Slack 上，

1388
01:09:44,490 --> 01:09:47,470
这是我见过的最烂的想法之一，

1389
01:09:49,370 --> 01:09:50,190
但他们去掉了它，

1390
01:09:50,600 --> 01:09:51,505
因为它非常浪费，

1391
01:09:51,505 --> 01:09:53,190
他们现在做了列 header。

1392
01:09:57,370 --> 01:10:00,650
对于非常大的值，可变长度的值，

1393
01:10:01,780 --> 01:10:07,325
这些数据库系统不会让你直接将它们存储在页面本身中，

1394
01:10:07,325 --> 01:10:11,200
同样，页面大小是由数据库系统定义的，

1395
01:10:11,490 --> 01:10:17,500
表中的每一页必须具有相同的页面大小，

1396
01:10:18,000 --> 01:10:20,030
在德国有一个实验系统，

1397
01:10:20,030 --> 01:10:21,700
他们可以支持可变长度的页面，

1398
01:10:21,960 --> 01:10:23,800
我们可以忽略这个，其他人都不会这么做，

1399
01:10:25,380 --> 01:10:26,340
但这意味着，

1400
01:10:26,340 --> 01:10:27,470
在某个时刻，我需要决定，

1401
01:10:27,490 --> 01:10:32,570
我是否应该在我的 tuple 页面中存储这个很大的 varchar 字符串，

1402
01:10:33,790 --> 01:10:34,740
对于这个，

1403
01:10:34,740 --> 01:10:35,630
如果它超过了，

1404
01:10:36,100 --> 01:10:38,360
对于所有东西，他们将有不同的门槛，

1405
01:10:38,530 --> 01:10:39,780
什么时候不能存放它，

1406
01:10:39,780 --> 01:10:41,870
我们需要把它放到所谓的溢出页面中。

1407
01:10:42,490 --> 01:10:44,280
在 Postgres 中，他们称之为 TOAST ，

1408
01:10:44,280 --> 01:10:45,530
我忘了它实际上代表的是什么，

1409
01:10:45,670 --> 01:10:47,780
但任何大于 2 千字节的属性，

1410
01:10:47,890 --> 01:10:49,040
它们都会将其存储为单独的页面，

1411
01:10:49,420 --> 01:10:50,900
然后在实际的 tuple 本身中，

1412
01:10:51,370 --> 01:10:54,110
它们将只有一个指针或一个 record ID 和一个偏移量，

1413
01:10:54,220 --> 01:10:58,030
然后指向要查找的实际值的位置。

1414
01:10:58,350 --> 01:11:00,050
你作为 SQL 程序员，

1415
01:11:00,050 --> 01:11:01,270
你不知道这个，也不关心，

1416
01:11:01,410 --> 01:11:02,890
你在查询上调用 SELECT * ，

1417
01:11:03,090 --> 01:11:08,380
数据库系统负责读取基础 tuple ，

1418
01:11:08,610 --> 01:11:10,750
识别出它指向溢出页面，

1419
01:11:11,070 --> 01:11:14,090
去获取数据，然后将其复制到缓冲区中，

1420
01:11:14,090 --> 01:11:15,550
然后为你生成输出。

1421
01:11:15,940 --> 01:11:18,330
所以它隐藏在下面，为你做了这个。

1422
01:11:19,650 --> 01:11:21,940
好的，所以 Postgres 是 2 千字节，

1423
01:11:22,020 --> 01:11:23,560
它们最多 8 千字节，

1424
01:11:23,850 --> 01:11:24,695
我认为你可以调整这个，

1425
01:11:24,695 --> 01:11:27,280
但很明显，你不能超过 8 千字节。

1426
01:11:27,570 --> 01:11:31,120
在 MySQL 中，溢出大小是当前页面大小的一半。

1427
01:11:31,650 --> 01:11:33,010
然后在 SQL Server 中，

1428
01:11:33,690 --> 01:11:35,020
意外地，你可以设置，

1429
01:11:35,100 --> 01:11:39,700
默认是，如果它超过页面大小，它将溢出，

1430
01:11:39,990 --> 01:11:42,460
所以，尝试存储的数据大小，

1431
01:11:42,480 --> 01:11:45,490
这个超大属性中的数据加上常规数据，

1432
01:11:45,900 --> 01:11:47,980
这个组合超过页面的大小，

1433
01:11:48,210 --> 01:11:52,640
把超大的数据放到另一个页面，

1434
01:11:53,380 --> 01:11:54,915
你可以把这些东西链在一起，

1435
01:11:54,915 --> 01:11:59,330
假设你出于任何原因，想要存储 1G 或10G的视频，

1436
01:11:59,800 --> 01:12:02,240
你的数据库系统不允许你这样做，

1437
01:12:02,680 --> 01:12:04,185
然后这个溢出页面，

1438
01:12:04,185 --> 01:12:06,290
因为它们都必须是相同的固定长度大小，

1439
01:12:06,820 --> 01:12:08,475
它可以有一个指针来说，

1440
01:12:08,475 --> 01:12:11,625
好的，这是这个属性的数据范围的数据，

1441
01:12:11,625 --> 01:12:13,820
但是，顺便说一句，这里有一个指向下一页的指针，

1442
01:12:14,020 --> 01:12:15,740
你必须沿着该链表，

1443
01:12:15,880 --> 01:12:17,480
去拿所有的数据，然后把它们放在一起。

1444
01:12:22,430 --> 01:12:25,830
你可以做的最后一件事称为外部值存储，

1445
01:12:26,510 --> 01:12:27,390
这就是，

1446
01:12:28,250 --> 01:12:32,620
数据库系统不会存储大数据，

1447
01:12:32,620 --> 01:12:36,360
它管理的页面中的大属性，

1448
01:12:36,740 --> 01:12:39,000
它会将其写出到你的本地文件系统，

1449
01:12:39,620 --> 01:12:43,890
然后在内部存储该数据所在位置的 URI 或 URL ，

1450
01:12:44,540 --> 01:12:46,480
所以，当你对表进行查询，

1451
01:12:47,130 --> 01:12:48,880
并获取该属性时，

1452
01:12:48,930 --> 01:12:51,550
它会转到操作系统并获取数据，

1453
01:12:51,810 --> 01:12:54,310
将其复制到缓冲区中，然后将交回给你。

1454
01:12:55,560 --> 01:13:00,940
我认为只有 Oracle 和 SQL Server 能做到这个，

1455
01:13:01,380 --> 01:13:03,370
在 Oracle 中，他们称为 BFILE ，

1456
01:13:03,390 --> 01:13:05,260
在 Microsoft 中，被称为 FILESTREAM ，

1457
01:13:05,520 --> 01:13:08,450
它只是磁盘上一些数据的 URI ，

1458
01:13:08,450 --> 01:13:12,910
它执行系统调用从操作系统获取它。

1459
01:13:13,380 --> 01:13:15,280
在 Postgres 中，你可以做这个，

1460
01:13:16,200 --> 01:13:17,560
它们称为外部数据包装器，

1461
01:13:18,240 --> 01:13:22,850
这是额外的机制来存储数据和云存储，

1462
01:13:22,870 --> 01:13:25,485
然后，现在在单个 SQL 界面中，

1463
01:13:25,485 --> 01:13:26,450
我可以获取数据，

1464
01:13:26,650 --> 01:13:30,230
并使其看起来就像在表本身中一样。

1465
01:13:31,590 --> 01:13:34,120
所以，当我们将内容写入这些外部文件时，

1466
01:13:34,470 --> 01:13:39,130
数据系统不能对其进行任何更改，

1467
01:13:39,360 --> 01:13:41,465
就像你写到了文件系统一样，

1468
01:13:41,465 --> 01:13:43,385
我不会去做原地更新，

1469
01:13:43,385 --> 01:13:44,165
我无法更新它，

1470
01:13:44,165 --> 01:13:45,215
我只能读入它，

1471
01:13:45,215 --> 01:13:49,690
如果我删除指向这个文件的 tuple ，

1472
01:13:50,100 --> 01:13:52,630
这里有机制决定，我是否也想删除该文件。

1473
01:13:54,400 --> 01:13:57,105
所以，可能这样做的原因是，

1474
01:13:57,105 --> 01:13:58,425
因为，正如我所说的，

1475
01:13:58,425 --> 01:14:01,190
你不想在数据库系统中存储 10GB 的文件，

1476
01:14:02,770 --> 01:14:05,060
出于管理原因，

1477
01:14:05,080 --> 01:14:08,420
因为日志记录变得昂贵，

1478
01:14:08,530 --> 01:14:13,460
但通常情况下，数据库管理系统存储在更高端的硬件上，

1479
01:14:14,370 --> 01:14:16,060
这会使存储空间变得昂贵，

1480
01:14:16,290 --> 01:14:18,430
如果你使用亚马逊 RDS ，

1481
01:14:19,360 --> 01:14:22,680
我想他们会多收比 EBS 贵 4 倍的存储费用，

1482
01:14:23,120 --> 01:14:26,280
当然 EBS 比你有一个本地连接的磁盘更高，

1483
01:14:27,470 --> 01:14:29,095
所以，你不希望存储这些大文件，

1484
01:14:29,095 --> 01:14:32,980
也不希望你的[只读]存储直接被管理，

1485
01:14:32,980 --> 01:14:35,790
文件被数据库系统管理，

1486
01:14:36,140 --> 01:14:38,790
让操作系统在一些更便宜的存储设备上为你处理这个。

1487
01:14:41,080 --> 01:14:45,330
有一篇来自 15 年前的论文，来自 Jim Gray ，

1488
01:14:45,330 --> 01:14:48,860
他是 90 年代数据库图灵奖的获得者之一，

1489
01:14:49,000 --> 01:14:51,050
他发明了很多我们这学期讨论的东西，

1490
01:14:51,280 --> 01:14:55,140
他有一篇几年前在微软写的论文，

1491
01:14:55,140 --> 01:14:59,630
讨论了是否应该在数据库系统内存储大数据，

1492
01:14:59,950 --> 01:15:01,485
我认为对于他们的建议，

1493
01:15:01,485 --> 01:15:05,530
他们说的是任何大于 200 千字节的内容存储在外部。

1494
01:15:07,110 --> 01:15:08,195
这是不久前的事，

1495
01:15:08,195 --> 01:15:11,050
我不再建议这样做了，

1496
01:15:11,730 --> 01:15:13,490
实际上我们有一个发明了 SQLite 的人，

1497
01:15:13,490 --> 01:15:16,530
他五年前来到 CMU ，做了一次演讲，

1498
01:15:16,530 --> 01:15:18,020
他提到了，

1499
01:15:19,100 --> 01:15:22,410
根据他的经验，最好将东西存储在 SQLite 中，

1500
01:15:22,730 --> 01:15:24,600
如果你运行一个手机应用程序，

1501
01:15:24,740 --> 01:15:26,850
如果您的应用程序有一堆缩略图图像，

1502
01:15:27,350 --> 01:15:29,040
最好将其存储在数据库系统中，

1503
01:15:29,060 --> 01:15:31,530
因为现在当你检索它们时，

1504
01:15:32,090 --> 01:15:34,870
你的应用程序已经必须处理数据库系统的打开，

1505
01:15:34,870 --> 01:15:36,300
文件已经打开，

1506
01:15:36,380 --> 01:15:40,140
所以直接从数据库系统读取这些缩略图要快的多，

1507
01:15:40,400 --> 01:15:44,220
比起对磁盘上的一堆文件进行一系列 fopen 和 fread 。

1508
01:15:45,810 --> 01:15:48,280
所以我会说，我的意思是，这纯粹是猜测，

1509
01:15:49,180 --> 01:15:50,760
50 兆或更少可能是可以的，

1510
01:15:50,760 --> 01:15:52,730
除此之外，你都希望使用外部存储，

1511
01:15:53,700 --> 01:15:56,855
像 Django 和其他应用程序框架这样的 ORM ，

1512
01:15:56,855 --> 01:15:58,870
他们有为你处理这一问题的机制。

1513
01:15:59,880 --> 01:16:00,280
好的？

1514
01:16:03,240 --> 01:16:05,480
所以下一节课，

1515
01:16:05,480 --> 01:16:07,270
我们将继续讨论存储，

1516
01:16:07,530 --> 01:16:08,405
谈论存储模型，

1517
01:16:08,405 --> 01:16:12,670
然后是列和行存储，

1518
01:16:12,960 --> 01:16:16,840
这将再次向你们解释为什么 DuckDB 比 SQLite 快，

1519
01:16:17,070 --> 01:16:20,080
在那个[笔记]上， DuckDB 会寄给我贴纸，

1520
01:16:20,640 --> 01:16:22,690
如果你想要一个，来拿一个，

1521
01:16:23,070 --> 01:16:24,040
我也有别针。

