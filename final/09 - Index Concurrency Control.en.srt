1
00:00:31,750 --> 00:00:34,700
How's life?

2
00:00:42,320 --> 00:00:45,875
I mean, yeah, all the Wu-Tang Clan pretty young.

3
00:00:51,930 --> 00:00:54,640
that was kind of [], Wu-Tang.

4
00:00:55,990 --> 00:00:58,010
There's no Wu-Tang questions on the exam this year,

5
00:00:58,150 --> 00:00:59,085
previous year have been,

6
00:00:59,085 --> 00:01:01,005
so don't feel like you need to know these things.

7
00:01:01,005 --> 00:01:03,830
All right, again awesome, 2PL.

8
00:01:05,530 --> 00:01:07,130
You guys, lot to go over,

9
00:01:07,540 --> 00:01:08,450
the list is getting longer.

10
00:01:08,620 --> 00:01:11,930
So project #1 is due this Sunday at midnight,

11
00:01:12,220 --> 00:01:16,160
again, we're having special office hours on, on Saturday, that's in person,

12
00:01:17,110 --> 00:01:18,135
they announced it on Piazza,

13
00:01:18,135 --> 00:01:19,190
I think it's on the fifth floor

14
00:01:20,230 --> 00:01:21,320
and one to make [].

15
00:01:21,460 --> 00:01:25,640
Homework #2, it's been bumped out to October 4th, so Wednesday,

16
00:01:26,470 --> 00:01:29,660
make sure made not have be the same due date as project #1.

17
00:01:30,130 --> 00:01:31,640
Homework #3 will be out this week,

18
00:01:31,690 --> 00:01:33,170
that's will due four days later.

19
00:01:33,810 --> 00:01:34,985
And again, that kind of sucks,

20
00:01:34,985 --> 00:01:36,095
that it kind of cram it so quickly,

21
00:01:36,095 --> 00:01:38,180
but because the midterm exam,

22
00:01:38,180 --> 00:01:43,570
which will cover things, will cover things that in in homework #3,

23
00:01:43,770 --> 00:01:46,690
we want to get that back to you guys and graded,

24
00:01:47,460 --> 00:01:49,910
before the the midterm exam on on Wednesday.

25
00:01:50,260 --> 00:01:54,480
So midterm, midterm it be in class here on October 11th,

26
00:01:54,480 --> 00:01:56,840
it's a wednesday and during the regular class time,

27
00:01:57,730 --> 00:01:59,840
if you need accommodations, please email us

28
00:01:59,860 --> 00:02:04,245
and so we can start organizing and taking care of the logistics,

29
00:02:04,245 --> 00:02:05,000
don't post on Piazza.

30
00:02:08,860 --> 00:02:10,130
We're trying to get homework #3 out now,

31
00:02:10,660 --> 00:02:11,610
it should be out today,

32
00:02:11,610 --> 00:02:12,500
I don't know if it be out today.

33
00:02:13,000 --> 00:02:14,120
Yes, that's the plan,

34
00:02:14,710 --> 00:02:16,260
but the trouble is like, it doesn't cover things,

35
00:02:16,260 --> 00:02:18,255
it's doesn't cover sorting and Joins,

36
00:02:18,255 --> 00:02:19,400
which I'll cover next week.

37
00:02:21,660 --> 00:02:23,500
Any questions about any of these things?

38
00:02:24,720 --> 00:02:25,120
Yes.

39
00:02:30,450 --> 00:02:33,940
Whatever it says on the website now is the current plan, yes.

40
00:02:34,970 --> 00:02:35,370
Yes.

41
00:02:41,580 --> 00:02:42,640
At the end of fall break,

42
00:02:43,290 --> 00:02:45,880
we double check that,

43
00:02:46,140 --> 00:02:47,050
I thought we moved it,

44
00:02:47,070 --> 00:02:49,360
so we didn't have to do fall break,

45
00:02:49,620 --> 00:02:50,500
we will take care of that.

46
00:02:51,650 --> 00:02:52,260
Other questions?

47
00:02:55,420 --> 00:02:56,120
All right, cool.

48
00:02:57,140 --> 00:02:57,870
All right, so,

49
00:02:58,680 --> 00:03:01,395
the the last two classes we've talked about data structures,

50
00:03:01,395 --> 00:03:02,390
we talked about hash tables

51
00:03:02,410 --> 00:03:03,650
and then we talked about B+ trees,

52
00:03:03,970 --> 00:03:07,040
and I prefaced our conversation

53
00:03:07,210 --> 00:03:09,705
going into discussing the hash table B+ trees stuff,

54
00:03:09,705 --> 00:03:13,670
to say that to simplify the discussion

55
00:03:13,720 --> 00:03:17,730
and, and the, the explanation of these data structures and the algorithms,

56
00:03:17,730 --> 00:03:21,140
that are used to to manipulate them or work with them,

57
00:03:21,670 --> 00:03:23,120
we're going to assume that it's single threaded,

58
00:03:23,740 --> 00:03:25,400
because that just makes your life easier,

59
00:03:25,900 --> 00:03:28,490
but of course, in any modern system,

60
00:03:29,140 --> 00:03:31,100
in today's hardware,

61
00:03:31,480 --> 00:03:34,820
you need to support multiple threads or multiple workers running at the same time,

62
00:03:35,170 --> 00:03:36,440
again, I'm going to try to use the word workers,

63
00:03:36,580 --> 00:03:38,330
because that can mean either a thread or process,

64
00:03:38,740 --> 00:03:40,550
Postgres is not multi thread, it's multi process,

65
00:03:41,080 --> 00:03:42,810
most modern systems are multi threaded,

66
00:03:42,810 --> 00:03:43,730
but the idea is the same.

67
00:03:44,140 --> 00:03:48,345
But still again we want to be able to have multiple workers running at the same time

68
00:03:48,345 --> 00:03:49,910
be able to access these data structures,

69
00:03:50,710 --> 00:03:53,390
so that if one of them has to stall,

70
00:03:53,530 --> 00:03:54,885
because they're going to disk,

71
00:03:54,885 --> 00:03:57,060
we can have other workers run at the same time

72
00:03:57,060 --> 00:03:59,290
and do useful things, right.

73
00:03:59,820 --> 00:04:01,325
System will look very unresponsive,

74
00:04:01,325 --> 00:04:02,650
if you only have a single worker,

75
00:04:03,240 --> 00:04:04,420
again, assume it's a thread

76
00:04:04,620 --> 00:04:07,540
and then I'm going to go run some query,

77
00:04:07,680 --> 00:04:09,590
and then as soon as I have to go my page table,

78
00:04:09,590 --> 00:04:10,660
and the thing I don't need is,

79
00:04:10,830 --> 00:04:11,980
the page I need isn't there,

80
00:04:12,120 --> 00:04:12,815
I have to stall,

81
00:04:12,815 --> 00:04:14,050
because I got to go to disk and get it.

82
00:04:14,640 --> 00:04:16,230
While, while we're stalled,

83
00:04:16,230 --> 00:04:17,385
the CPU essentially stalled,

84
00:04:17,385 --> 00:04:19,580
we can have other threads, other workers do useful things.

85
00:04:20,020 --> 00:04:22,440
So that's the goal of of what we're going to talk about today

86
00:04:22,440 --> 00:04:25,640
is how do we actually make these data structures thread safe.

87
00:04:26,590 --> 00:04:27,770
And so what I'll say is that,

88
00:04:27,940 --> 00:04:30,050
this is how most systems are going to be implemented,

89
00:04:30,520 --> 00:04:33,500
most systems will try to take advantage of multiple threads,

90
00:04:34,450 --> 00:04:36,555
there, there's sort of category systems,

91
00:04:36,555 --> 00:04:38,720
that actually don't do any of the things we're talking about today,

92
00:04:39,490 --> 00:04:41,000
and the most famous one is Redis,

93
00:04:41,260 --> 00:04:43,250
that it's a single process, single thread,

94
00:04:43,510 --> 00:04:45,350
so all the latching stuff we're going to talk about today,

95
00:04:45,400 --> 00:04:46,310
they don't have to do,

96
00:04:47,020 --> 00:04:49,170
because they know no other threads running at the same time.

97
00:04:50,390 --> 00:04:51,990
There'll be other systems they have,

98
00:04:53,060 --> 00:04:54,310
they'll still be multi threaded,

99
00:04:54,310 --> 00:04:56,940
but they'll maybe have only one writer thread,

100
00:04:56,960 --> 00:04:58,945
but multiple reader threads running at the same time,

101
00:04:58,945 --> 00:05:00,240
and that simplifies a bunch of things,

102
00:05:00,470 --> 00:05:03,180
but you still need the latching protections that we're going to talk about today.

103
00:05:06,300 --> 00:05:08,830
So that the, the thing that we're going to use

104
00:05:08,880 --> 00:05:14,170
to, to enforce the threads or workers to behave a certain way,

105
00:05:14,730 --> 00:05:18,790
so that we don't end up with corrupted data and invalid data structures

106
00:05:19,200 --> 00:05:21,040
is going to be called a concurrent control protocol.

107
00:05:21,950 --> 00:05:23,140
And again, for today's class,

108
00:05:23,140 --> 00:05:24,900
we're going to see how we do this for workers,

109
00:05:25,550 --> 00:05:26,290
after the midterm,

110
00:05:26,290 --> 00:05:30,300
we'll discuss how we use concurrcncy control to, to coordinate transactions.

111
00:05:31,770 --> 00:05:32,840
And so you can sort of think of this,

112
00:05:32,840 --> 00:05:35,560
this concurrency control protocol is like the traffic cop of the system,

113
00:05:35,970 --> 00:05:38,950
that allows you to tell, tell different workers,

114
00:05:39,390 --> 00:05:43,670
who's allowed to do what at what given time, right.

115
00:05:44,200 --> 00:05:44,865
And the idea is that,

116
00:05:44,865 --> 00:05:47,130
they're going to be operating on some shared object or some critical section,

117
00:05:47,130 --> 00:05:49,610
and we don't want to have them interfere with each other and cause problems.

118
00:05:50,760 --> 00:05:55,280
And the, the two types of problems you could have are logical correctness and physical correctness,

119
00:05:55,280 --> 00:05:58,150
and I think I mentioned this last week as well.

120
00:05:58,500 --> 00:06:00,580
So the logical correctness, the idea is that,

121
00:06:01,110 --> 00:06:04,235
if I insert a key into my B+ tree,

122
00:06:04,235 --> 00:06:05,260
I insert key 5

123
00:06:05,820 --> 00:06:08,050
and then if I come back and I try to look for key 5,

124
00:06:08,340 --> 00:06:09,340
I should see it.

125
00:06:10,160 --> 00:06:11,280
Well, the other example I said was,

126
00:06:11,960 --> 00:06:13,200
if I delete key 5

127
00:06:13,490 --> 00:06:14,890
and I come back and try to look for key 5,

128
00:06:14,890 --> 00:06:16,750
again, I shouldn't see it, right.

129
00:06:16,750 --> 00:06:17,830
So, at a logical level,

130
00:06:17,830 --> 00:06:19,135
that we want to make sure that,

131
00:06:19,135 --> 00:06:21,750
we're seeing the things we should see in our data structures.

132
00:06:22,590 --> 00:06:25,750
The thing that we care about in today's class is the physical correctness,

133
00:06:26,040 --> 00:06:28,030
meaning how do we ensure that,

134
00:06:28,530 --> 00:06:32,140
if we're walking through a hash table or traversing the B+ tree

135
00:06:32,460 --> 00:06:34,295
and at some point, we've got to follow a pointer,

136
00:06:34,295 --> 00:06:35,180
like like a page ID

137
00:06:35,180 --> 00:06:36,130
to take us somewhere else,

138
00:06:36,390 --> 00:06:38,195
that page ID is is correct,

139
00:06:38,195 --> 00:06:42,490
like it's not going to take us to, you know, a table page that has a bunch of garbage in it.

140
00:06:43,890 --> 00:06:45,790
Because what happens if if you go follow a page

141
00:06:45,930 --> 00:06:49,300
and you start looking at data, that doesn't look like you expect to look like,

142
00:06:49,590 --> 00:06:50,570
you're going to have a seg fault,

143
00:06:50,570 --> 00:06:52,235
because you're going to try to read past some buffer

144
00:06:52,235 --> 00:06:53,990
or things, things are gonna, things are to break

145
00:06:53,990 --> 00:06:54,790
or you get corrupted data.

146
00:06:55,660 --> 00:06:57,980
So again, logical correctness, we'll worry about later, after midterm,

147
00:06:58,060 --> 00:06:59,780
today's class is really about physical correctness.

148
00:07:01,490 --> 00:07:02,520
So I first want to describe,

149
00:07:03,380 --> 00:07:06,570
go over quickly of what latches are again

150
00:07:06,590 --> 00:07:09,060
and how do you actually implement them inside of our database system.

151
00:07:09,380 --> 00:07:10,620
And again, the takeaway here is that,

152
00:07:11,660 --> 00:07:13,740
ideally we don't want to rely on what the operating system

153
00:07:14,390 --> 00:07:15,780
gives us in terms of latches.

154
00:07:16,310 --> 00:07:18,270
Then we'll see a simplified example of

155
00:07:18,470 --> 00:07:20,250
of how to do hash table latching,

156
00:07:20,570 --> 00:07:22,890
let's say most our time doing B+ tree latching,

157
00:07:23,060 --> 00:07:26,490
and we'll see a basic version and an optimized version,

158
00:07:26,900 --> 00:07:30,330
and then we'll finish off talking how to handle leaf node scans.

159
00:07:31,290 --> 00:07:31,690
Okay?

160
00:07:34,670 --> 00:07:36,460
All right, so I think I showed this slide before

161
00:07:36,460 --> 00:07:37,980
and again I just want to revisited again

162
00:07:39,260 --> 00:07:41,700
this [] between locks and latches.

163
00:07:41,990 --> 00:07:44,820
And again, if you're coming from the OS world or distributed world,

164
00:07:45,080 --> 00:07:47,310
they, they might mean,

165
00:07:47,900 --> 00:07:50,420
when I say latch, they might think lock, right.

166
00:07:50,420 --> 00:07:51,010
But in database,

167
00:07:51,120 --> 00:07:54,970
that's what we care about mostly my life in, in this course,

168
00:07:55,140 --> 00:07:56,075
so we need to make sure,

169
00:07:56,075 --> 00:07:57,020
we understand what we're talking about

170
00:07:57,020 --> 00:07:58,300
when we say lock versus the latch.

171
00:07:59,330 --> 00:08:03,235
So a lock is going to be this high level, primitive, protection primitive,

172
00:08:03,235 --> 00:08:07,560
that allows us to protect the logical contents of our database,

173
00:08:08,120 --> 00:08:12,010
like a tuple, a database, a table, right,

174
00:08:12,690 --> 00:08:13,900
and the,

175
00:08:14,990 --> 00:08:17,190
when we acquire one of these locks,

176
00:08:17,420 --> 00:08:21,330
the transaction will hold that lock for the duration of that transaction,

177
00:08:22,300 --> 00:08:23,200
it's not always true,

178
00:08:23,200 --> 00:08:25,380
we'll see examples where we can release locks, maybe early,

179
00:08:25,880 --> 00:08:27,000
but for our purposes today,

180
00:08:27,020 --> 00:08:28,020
we'll assume that's the case.

181
00:08:29,050 --> 00:08:33,410
And then there'll be some higher level mechanism within our,concurrency protocol,

182
00:08:33,640 --> 00:08:36,200
that's going to ensure that we don't have any deadlocks,

183
00:08:36,800 --> 00:08:38,380
and then if a deadlock does arise,

184
00:08:38,820 --> 00:08:42,010
then the the databases will have a mechanism

185
00:08:42,090 --> 00:08:45,040
to be able to roll back the changes that the transaction made

186
00:08:45,210 --> 00:08:47,795
to make it look as if, you know, it didn't make any changes,

187
00:08:47,795 --> 00:08:49,360
so we don't, we don't have any partial updates.

188
00:08:51,310 --> 00:08:52,635
Today we're focused on latches

189
00:08:52,635 --> 00:08:55,035
and so the latches are going to be the low level primitives,

190
00:08:55,035 --> 00:08:58,130
that we used to protect critical sections in our, in our data structures,

191
00:08:58,630 --> 00:09:01,370
from one worker, you know, against, against another.

192
00:09:02,170 --> 00:09:06,500
And so the, the duration of the lifetime, that we're going to hold a latch is going to be very short,

193
00:09:06,850 --> 00:09:08,325
like go like think a critical section,

194
00:09:08,325 --> 00:09:10,130
I'm going to go take a latch on a page,

195
00:09:10,360 --> 00:09:11,130
make some change,

196
00:09:11,130 --> 00:09:12,410
and then release that latch immediately.

197
00:09:13,930 --> 00:09:17,385
And, because it's going to be very simple,

198
00:09:17,385 --> 00:09:20,750
we minimize amount of bookkeeping, we're taking for these latches,

199
00:09:21,130 --> 00:09:22,820
we don't want to have, we don't,

200
00:09:22,960 --> 00:09:25,880
the database system is not going to automatically roll back any changes for us,

201
00:09:26,540 --> 00:09:27,665
we don't avoid deadlocks

202
00:09:27,665 --> 00:09:29,200
and try to not make any changes

203
00:09:29,250 --> 00:09:30,550
unless we acquire the latch for something,

204
00:09:31,310 --> 00:09:32,700
so that we don't have to roll things back,

205
00:09:32,810 --> 00:09:34,180
we would have minimal coordination

206
00:09:34,180 --> 00:09:37,050
between the, between the different workers running at the same time.

207
00:09:38,080 --> 00:09:39,675
Whereas in the lock case I,

208
00:09:39,675 --> 00:09:40,605
I'm jumping ahead,

209
00:09:40,605 --> 00:09:43,310
but there will be a table literally internally called a lock table,

210
00:09:43,570 --> 00:09:44,445
and you go look in there,

211
00:09:44,445 --> 00:09:47,150
you can see who holds locks for different objects,

212
00:09:47,590 --> 00:09:49,455
in latches, we don't want to maintain any of that,

213
00:09:49,455 --> 00:09:50,330
because that's so expensive,

214
00:09:51,040 --> 00:09:52,650
relative to the amount of work we want to do

215
00:09:52,650 --> 00:09:54,410
within a critical section in our data structures.

216
00:09:56,720 --> 00:09:58,495
So there's this, there's this table,

217
00:09:58,495 --> 00:10:00,805
I also, like from the the book I recommended last time,

218
00:10:00,805 --> 00:10:02,550
from this guy, the B tree book,

219
00:10:03,560 --> 00:10:06,420
when again he shows this change between the locks versus latches

220
00:10:06,650 --> 00:10:08,640
and the way to sort to read this table is,

221
00:10:08,720 --> 00:10:10,720
within a column you read down

222
00:10:10,720 --> 00:10:12,925
and say, you know what the thing is protecting,

223
00:10:12,925 --> 00:10:13,690
how is protecting it

224
00:10:13,690 --> 00:10:15,360
and the different ways it's protecting things.

225
00:10:15,650 --> 00:10:16,225
So for example,

226
00:10:16,225 --> 00:10:18,300
a lock is going to separate transactions from each other

227
00:10:19,010 --> 00:10:21,370
and it's going to protect the logical database contents

228
00:10:21,370 --> 00:10:24,510
pages or sorry, tuples, tables, databases,

229
00:10:25,020 --> 00:10:27,290
and we can hold them for the entire length of the transaction,

230
00:10:28,090 --> 00:10:29,445
we'll talk about modes in a second,

231
00:10:29,445 --> 00:10:32,000
we can take a lock for an object in different modes,

232
00:10:32,230 --> 00:10:35,325
like exclusive, shared, intention, updates,

233
00:10:35,325 --> 00:10:36,200
we'll get, we'll get there later,

234
00:10:36,730 --> 00:10:40,640
and that the database system provide either deadlock detection or deadlock prevention mechanisms

235
00:10:41,240 --> 00:10:42,550
built in to avoid these problems,

236
00:10:43,170 --> 00:10:45,070
and then again, these are the mechanisms to do this.

237
00:10:45,300 --> 00:10:47,810
And then the information that we're to keep track of, what locks are being held

238
00:10:47,810 --> 00:10:52,180
is being kept in a lock manager, a centralized data structure.

239
00:10:53,630 --> 00:10:55,950
Today, again, we're focused on latches,

240
00:10:56,120 --> 00:10:58,320
so latch, latches are going to protect workers from each other,

241
00:10:58,670 --> 00:11:00,570
this will be only for in memory data structures,

242
00:11:01,250 --> 00:11:04,380
so like this is literally for the, you know, B+ trees in memory,

243
00:11:04,760 --> 00:11:10,450
but once, you know if if if a page within our B+ tree gets flushed out the disk,

244
00:11:10,450 --> 00:11:12,625
I wouldn't hold the latch for that thing,

245
00:11:12,625 --> 00:11:13,495
when it goes out to disk,

246
00:11:13,495 --> 00:11:14,580
because it's meaningless.

247
00:11:15,970 --> 00:11:17,240
It's protecting the critical sections,

248
00:11:17,590 --> 00:11:18,795
there's only be two modes,

249
00:11:18,795 --> 00:11:20,180
we can hold our latches in, read and write,

250
00:11:21,430 --> 00:11:24,650
and the way we're going to handle deadlocks is through coding discipline,

251
00:11:24,940 --> 00:11:26,300
us as the system developers

252
00:11:26,350 --> 00:11:28,430
have to write good code to make sure there's no deadlocks.

253
00:11:28,920 --> 00:11:29,970
Easier said than done sure,

254
00:11:29,970 --> 00:11:33,465
but like there's not going to be something, some other part of the system,

255
00:11:33,465 --> 00:11:34,490
that's going to bail us out.

256
00:11:35,480 --> 00:11:38,410
And we're going to keep the information about these latches

257
00:11:38,410 --> 00:11:40,710
are actually embedded in the data structure itself,

258
00:11:41,440 --> 00:11:43,770
so there won't be a centralized, centralized thing.

259
00:11:45,180 --> 00:11:46,115
Again, this makes more sense,

260
00:11:46,115 --> 00:11:48,310
when we start walking through the different data structure types,

261
00:11:48,810 --> 00:11:49,715
and so the lock stuff,

262
00:11:49,715 --> 00:11:51,880
we'll cover after midterm in lecture 15.

263
00:11:55,150 --> 00:11:57,350
So our latches only have two modes,

264
00:11:57,880 --> 00:11:59,870
it can be read mode or a write mode.

265
00:12:00,040 --> 00:12:02,570
So read mode, there are commutative operations,

266
00:12:02,620 --> 00:12:07,200
where you can have multiple workers take a latch in read mode at the same time,

267
00:12:07,200 --> 00:12:08,510
because, you know whatever they're doing

268
00:12:08,530 --> 00:12:12,945
isn't going to, you know, isn't going to break whatever the data structure is,

269
00:12:12,945 --> 00:12:15,290
it calls, calls any conflicts, right.

270
00:12:16,520 --> 00:12:19,680
If I need, if two workers need to read the same page,

271
00:12:19,910 --> 00:12:21,300
and I can take that in read mode,

272
00:12:22,020 --> 00:12:23,730
well, that that doesn't, they're not do any right,

273
00:12:23,730 --> 00:12:24,650
it doesn't break anything,

274
00:12:24,850 --> 00:12:27,500
so I can go ahead and have them both run at the same time.

275
00:12:28,730 --> 00:12:30,310
Write mode or exclusive mode is,

276
00:12:30,310 --> 00:12:35,250
when you know one thread is wants to access the object and actually make changes to it,

277
00:12:35,510 --> 00:12:40,290
and I don't want any other threads to run the same to operate on my object at the same time,

278
00:12:40,880 --> 00:12:45,030
so only one, only one worker can hold the latch in write mode

279
00:12:45,080 --> 00:12:48,080
and that blocks everyone else else out, right.

280
00:12:48,610 --> 00:12:50,990
And a really simple compatibility matrix will look like this.

281
00:12:51,130 --> 00:12:52,640
If I have a read mode,

282
00:12:52,720 --> 00:12:53,870
if I have a latch in read mode,

283
00:12:53,890 --> 00:12:55,580
if someone wants to get a latch in read mode,

284
00:12:55,780 --> 00:12:56,960
I can do that, that's allowed,

285
00:12:57,130 --> 00:12:58,460
but any other combination,

286
00:12:58,540 --> 00:13:01,280
where at least one of the latches either holds it in write mode

287
00:13:01,330 --> 00:13:02,780
or wants to get it in write mode,

288
00:13:03,340 --> 00:13:04,460
I have to deny that.

289
00:13:06,540 --> 00:13:09,280
So again, going back to what I say before about coding discipline,

290
00:13:09,690 --> 00:13:12,680
like the stupidest thing to do is to take every latch in write mode,

291
00:13:12,680 --> 00:13:13,870
even though you're only going to read it,

292
00:13:14,040 --> 00:13:15,580
it'll protect all your data structures,

293
00:13:15,750 --> 00:13:20,050
but like, you know, basically going to get relegated to a single thread system,

294
00:13:20,790 --> 00:13:23,110
and likewise, if I take my latch in read mode,

295
00:13:23,190 --> 00:13:25,720
but I start making changes to whatever it's protecting,

296
00:13:25,920 --> 00:13:27,970
then that's, that's our fault, that's the programmer's fault,

297
00:13:28,170 --> 00:13:29,710
and the system crashes, that's on us.

298
00:13:33,530 --> 00:13:34,350
And there isn't any,

299
00:13:36,080 --> 00:13:38,970
without getting into verifiable languages,

300
00:13:39,290 --> 00:13:42,310
there isn't really any mechanism in C++ or Rust,

301
00:13:42,310 --> 00:13:44,800
that's going to protect us for these things, right,

302
00:13:46,010 --> 00:13:47,670
because the compiler can't know.

303
00:13:50,650 --> 00:13:52,260
So let's look how you want to implement latches.

304
00:13:53,380 --> 00:13:57,760
So, ideally, we want a latch that has small memory footprint,

305
00:13:57,760 --> 00:14:01,345
because we don't want to store a lot of additional metadata for our latch,

306
00:14:01,345 --> 00:14:03,900
because we're these be embedded in the data structure itself

307
00:14:05,390 --> 00:14:06,810
and ideally we want to have it be,

308
00:14:07,740 --> 00:14:09,320
when there's no contention in the system,

309
00:14:09,430 --> 00:14:12,860
meaning there's no two threads or workers trying to acquire latch at the same time,

310
00:14:13,300 --> 00:14:16,280
we want to go as fast as possible with minimal overhead,

311
00:14:16,660 --> 00:14:18,380
I acquire the latch and do my thing right away.

312
00:14:19,410 --> 00:14:20,980
If we have to,

313
00:14:21,300 --> 00:14:22,570
we can't get the latch we need,

314
00:14:22,890 --> 00:14:24,260
then we have to make a decision

315
00:14:24,260 --> 00:14:25,595
of how long we should wait

316
00:14:25,595 --> 00:14:26,500
and how we want to wait,

317
00:14:27,400 --> 00:14:30,020
and we'll see different scenarios of how we want to do this.

318
00:14:32,390 --> 00:14:38,880
And ideally, also too, we, we, we don't want to have a bunch of metadata per latch

319
00:14:39,170 --> 00:14:40,740
about who's waiting for this latch,

320
00:14:41,060 --> 00:14:44,800
because that's now basically a cue for every single latch,

321
00:14:44,800 --> 00:14:45,670
you could have in your data structure,

322
00:14:45,670 --> 00:14:48,690
and I think of like a giant B+ tree with a billion entries,

323
00:14:49,190 --> 00:14:50,860
how many, how many pages you're going to have in there,

324
00:14:50,860 --> 00:14:55,350
each of those could have now their own priority queue, right.

325
00:14:56,580 --> 00:14:58,850
So again, coming from the database world,

326
00:14:58,850 --> 00:14:59,860
we say we don't,

327
00:15:00,030 --> 00:15:01,690
we don't want to rely on the OS to do any of these things,

328
00:15:02,100 --> 00:15:03,340
but then the OS people say,

329
00:15:03,480 --> 00:15:04,955
the database system don't know know what they're doing

330
00:15:04,955 --> 00:15:06,640
and they should not be implementing their own latches,

331
00:15:07,170 --> 00:15:09,335
and you can see this in the the Linux mailing list,

332
00:15:09,335 --> 00:15:12,680
so here's a post from Linus saying,

333
00:15:12,680 --> 00:15:17,225
like oh yeah, like you don't, you should not be writing your own latching thing,

334
00:15:17,225 --> 00:15:18,005
and it basically says here,

335
00:15:18,005 --> 00:15:19,160
like you should not use spinlocks,

336
00:15:19,160 --> 00:15:20,410
that I'll explain that is in a second,

337
00:15:20,490 --> 00:15:21,880
in user space, that's us,

338
00:15:21,990 --> 00:15:23,530
where the database system running a user space,

339
00:15:24,050 --> 00:15:26,215
says you should not be using spinlocks, so you roll yourself,

340
00:15:26,215 --> 00:15:26,920
unless you know what you're doing

341
00:15:26,920 --> 00:15:29,010
and the chances are you know what you're doing is low.

342
00:15:30,395 --> 00:15:32,770
He's wrong, despite being Linus.

343
00:15:34,480 --> 00:15:37,080
All right, so I'm going to go through three basic implementations

344
00:15:37,790 --> 00:15:39,720
of of how to implement latches.

345
00:15:39,920 --> 00:15:41,830
There's more advanced ones,

346
00:15:41,830 --> 00:15:43,350
like the ParkingLot stuff from Apple,

347
00:15:43,370 --> 00:15:45,180
this is probably the best one to use right now,

348
00:15:45,740 --> 00:15:47,250
and then there MCS Locks,

349
00:15:48,020 --> 00:15:49,530
which is a queuing thing,

350
00:15:50,660 --> 00:15:52,090
we'll cover in in the advanced class,

351
00:15:52,090 --> 00:15:52,960
but for our purposes here,

352
00:15:52,960 --> 00:15:53,815
we don't need to know this,

353
00:15:53,815 --> 00:15:57,600
but we need to understand the basic implementation of what latches are actually doing,

354
00:15:57,860 --> 00:15:59,910
so that when you start sprinkling them in your code,

355
00:16:00,050 --> 00:16:01,710
you understand the ramifications of them.

356
00:16:06,580 --> 00:16:07,640
You mean pthread mutex,

357
00:16:07,960 --> 00:16:09,210
we'll get to that in a second, yes.

358
00:16:09,210 --> 00:16:09,830
Her question is,

359
00:16:09,910 --> 00:16:11,150
what's wrong with C++ mutex.

360
00:16:11,800 --> 00:16:13,215
So if you call mutex at C++,

361
00:16:13,215 --> 00:16:13,940
what do you actually get?

362
00:16:18,400 --> 00:16:20,210
Yeah, but who's implementing that?

363
00:16:21,700 --> 00:16:24,230
Pthread, but how does a pthread work?

364
00:16:25,840 --> 00:16:26,990
Two more slides, okay.

365
00:16:33,670 --> 00:16:36,080
All right, so, maybe this the slide.

366
00:16:36,310 --> 00:16:37,850
All right, so the most basic,

367
00:16:38,680 --> 00:16:40,275
take it back, this is database world,

368
00:16:40,275 --> 00:16:41,390
we'll talk OS one next.

369
00:16:41,710 --> 00:16:45,405
So the most basic latch you implement is

370
00:16:45,405 --> 00:16:49,110
called a test-and-set, test-and-set spin lock,

371
00:16:49,110 --> 00:16:49,590
sorry, a spin lock,

372
00:16:49,590 --> 00:16:51,830
and I realize I'm calling spin lock when really latches.

373
00:16:53,400 --> 00:16:55,485
But this is the most simplest way to implement this is,

374
00:16:55,485 --> 00:16:59,450
because it literally is a 64 bit memory address,

375
00:16:59,920 --> 00:17:03,020
that you're just going to do atomic compare and swap on

376
00:17:03,130 --> 00:17:04,320
to see whether you can set it,

377
00:17:04,320 --> 00:17:05,190
and if you can't set it,

378
00:17:05,190 --> 00:17:07,250
then you spin and keep trying to set it over and over again,

379
00:17:07,330 --> 00:17:09,140
like the code literally look like this,

380
00:17:09,460 --> 00:17:11,540
I declare a an atomic boolean,

381
00:17:11,650 --> 00:17:15,050
this is just a syntactic sugar for declaring something that's atomic,

382
00:17:15,340 --> 00:17:17,720
and then now I have this, my latch here

383
00:17:17,770 --> 00:17:18,825
and I call it test-and-set

384
00:17:18,825 --> 00:17:20,985
and literally just trying to set a check

385
00:17:20,985 --> 00:17:22,880
to see whether it's current value 0,

386
00:17:23,680 --> 00:17:26,970
if, if if, if yes, then I can set the 1

387
00:17:27,170 --> 00:17:29,610
and I can do that in a single, single instruction atomically,

388
00:17:29,630 --> 00:17:31,330
so it's not like if, then this, then that,

389
00:17:31,330 --> 00:17:35,340
somebody else can come swoop in and change it before I before I can,

390
00:17:35,480 --> 00:17:37,980
it literally one instruction to go apply this change,

391
00:17:38,180 --> 00:17:39,930
and if I can't get it, then I just spin,

392
00:17:40,590 --> 00:17:43,660
because we're doing this in the database, database level at user space,

393
00:17:43,830 --> 00:17:45,760
we can decide whether, how many times we want to retry,

394
00:17:46,020 --> 00:17:47,890
whether we want to yield the thread to the OS

395
00:17:48,120 --> 00:17:49,630
or abort ourselves and restart.

396
00:17:50,970 --> 00:17:53,980
All right, why is this bad?

397
00:17:56,860 --> 00:18:01,910
What's that, wait, you said, busy wait.

398
00:18:02,170 --> 00:18:04,700
So you're basically spinning the cycle, spinning the CPU,

399
00:18:04,870 --> 00:18:06,200
check, check, check, over and over again.

400
00:18:06,970 --> 00:18:08,030
I could put maybe like,

401
00:18:08,660 --> 00:18:11,795
I could put a exponential back off to say,

402
00:18:11,795 --> 00:18:12,365
okay, I tried to get,

403
00:18:12,365 --> 00:18:15,520
I couldn't get it, wait one millisecond, two milliseconds, four milliseconds, right.

404
00:18:18,210 --> 00:18:20,350
Actually, the, so that's a challenge,

405
00:18:20,520 --> 00:18:22,210
that you're just spinning over and over again,

406
00:18:22,380 --> 00:18:24,995
another problem is going to be cache coherence traffic, right.

407
00:18:24,995 --> 00:18:27,250
So again, assuming I have a two socket CPU,

408
00:18:27,630 --> 00:18:31,750
the latch I'm trying to acquire is over here on this this NUMA region,

409
00:18:32,370 --> 00:18:35,850
know what NUMA is, Non Uniform Memory Access,

410
00:18:35,850 --> 00:18:37,730
basically like if I have two sockets in my,

411
00:18:37,780 --> 00:18:40,310
two, two sockets or two or more sockets on my motherboard,

412
00:18:40,810 --> 00:18:44,240
each CPU sockets is going to have DRAM that's close to it

413
00:18:44,500 --> 00:18:46,130
and it's really fast to talk to that,

414
00:18:46,680 --> 00:18:50,780
but I can also talk to memory that's over on another socket,

415
00:18:50,950 --> 00:18:52,280
and it's call it a NUMA region,

416
00:18:52,480 --> 00:18:54,285
but that that traffic is much slower,

417
00:18:54,285 --> 00:18:57,620
because I got to go over this interconnect between one socket to the other, right,

418
00:18:58,260 --> 00:19:00,120
And so Intel, they do a lot of work

419
00:19:00,120 --> 00:19:01,580
to make sure when you write programs

420
00:19:01,600 --> 00:19:06,710
you don't know and and don't technically have to know where memory actually is physically located,

421
00:19:07,030 --> 00:19:10,935
but of course, now you could have your program access something that's on another socket

422
00:19:10,935 --> 00:19:12,020
and it gets really slow

423
00:19:12,130 --> 00:19:14,430
and the hardware tries to play games and move things around for you

424
00:19:14,430 --> 00:19:15,170
try to speed things up,

425
00:19:15,400 --> 00:19:16,485
we can ignore that for now,

426
00:19:16,485 --> 00:19:17,745
and for this class, we don't have to worry about NUMA,

427
00:19:17,745 --> 00:19:19,130
I just want to explain that.

428
00:19:19,750 --> 00:19:23,810
This, this, a worker running on this, this CPU over here

429
00:19:24,070 --> 00:19:27,800
wants to acquire the latch in this other socket CPU memory,

430
00:19:28,930 --> 00:19:30,330
so it's going to keep spinning and over it again,

431
00:19:30,330 --> 00:19:32,900
but now it's all this traffic over this interconnect

432
00:19:33,970 --> 00:19:36,440
that's going to slow my entire database system down.

433
00:19:37,630 --> 00:19:38,445
So this is inefficient,

434
00:19:38,445 --> 00:19:39,015
because I'm spinning,

435
00:19:39,015 --> 00:19:42,500
but also like the traffic on the actual hardware itself is expensive.

436
00:19:44,830 --> 00:19:45,950
So now her question is,

437
00:19:46,180 --> 00:19:47,445
you know why, what's wrong

438
00:19:47,445 --> 00:19:50,870
or how does actually the C++ mutex actually work?

439
00:19:51,410 --> 00:19:53,280
So this is called a blocking mutex,

440
00:19:53,480 --> 00:19:54,720
it's the easiest thing to use,

441
00:19:54,740 --> 00:19:56,370
because it's built in C++,

442
00:19:59,670 --> 00:20:01,090
basically, you acquire and release,

443
00:20:01,530 --> 00:20:03,160
there's not a lot of mechanisms in it

444
00:20:04,140 --> 00:20:05,680
and the way you use it, it's sort of like this,

445
00:20:05,820 --> 00:20:06,940
you lock it and unlock,

446
00:20:07,200 --> 00:20:08,230
do whatever you want in the middle.

447
00:20:09,280 --> 00:20:12,330
So I asked her, how is this thing actually implemented,

448
00:20:12,330 --> 00:20:13,010
is anybody know,

449
00:20:14,660 --> 00:20:15,955
so if you call std::mutex,

450
00:20:15,955 --> 00:20:16,980
what do you get in C++,

451
00:20:20,340 --> 00:20:21,160
pthread_mutex,

452
00:20:22,350 --> 00:20:23,710
how is pthread_mutex implemented,

453
00:20:26,570 --> 00:20:28,350
it's called futex it's in Linux,

454
00:20:29,480 --> 00:20:30,360
everybody heard futex before,

455
00:20:31,670 --> 00:20:33,120
fast userspace mutex.

456
00:20:33,530 --> 00:20:34,770
So the way it works is.

457
00:20:35,660 --> 00:20:37,850
It has the spin lock that I just showed in the last slide,

458
00:20:37,850 --> 00:20:41,080
in user space, they'll have their own little test and set thing you can do,

459
00:20:41,460 --> 00:20:44,020
but if you can't, if you try to acquire it and you can't,

460
00:20:45,180 --> 00:20:49,060
then you fall back to a heavy heavyweight mutex inside the kernel,

461
00:20:49,740 --> 00:20:54,100
so, so if if no one holds a latch with a futex, I try to acquire it,

462
00:20:54,120 --> 00:20:55,025
If no one holds it,

463
00:20:55,025 --> 00:20:58,300
then I just do a compare and swap real real fast in user space,

464
00:20:58,350 --> 00:20:58,940
and I'm done,

465
00:20:58,940 --> 00:21:01,150
and my program, my thread keeps running,

466
00:21:01,320 --> 00:21:02,555
if I can't get it,

467
00:21:02,555 --> 00:21:04,825
then the OS takes control of us

468
00:21:04,825 --> 00:21:06,720
and we go down now into the kernel

469
00:21:06,980 --> 00:21:08,335
and then we get descheduled,

470
00:21:08,335 --> 00:21:09,925
because it knows that I can't run

471
00:21:09,925 --> 00:21:11,820
until the thing I'm waiting for is available.

472
00:21:12,925 --> 00:21:13,705
But what's down in the kernel,

473
00:21:13,705 --> 00:21:14,910
How they keep track of threads,

474
00:21:16,890 --> 00:21:17,410
what's that.

475
00:21:18,590 --> 00:21:19,230
Sorry, say that again,

476
00:21:20,020 --> 00:21:21,390
blocking queue, but like, what,

477
00:21:22,510 --> 00:21:23,040
there's also,

478
00:21:24,560 --> 00:21:26,995
there's the scheduler has its own hash table

479
00:21:26,995 --> 00:21:28,410
to keep track of what threads are running,

480
00:21:28,880 --> 00:21:31,920
so they use their own latches to protect that data structure.

481
00:21:32,150 --> 00:21:33,730
So if I can't acquire this,

482
00:21:33,730 --> 00:21:34,750
I go down in the kernel

483
00:21:34,750 --> 00:21:35,545
and I get descheduled

484
00:21:35,545 --> 00:21:36,415
and that's very, very expensive,

485
00:21:36,415 --> 00:21:37,240
syscalls are expensive,

486
00:21:37,240 --> 00:21:38,850
we want to avoid them, right.

487
00:21:39,710 --> 00:21:41,580
All right, so this is just the diagram like this.

488
00:21:41,720 --> 00:21:44,700
So again, I have my two, two workers running different sockets,

489
00:21:45,020 --> 00:21:46,290
they both try to [] at the same time,

490
00:21:46,520 --> 00:21:48,090
one of them will get the userspace latch,

491
00:21:48,230 --> 00:21:49,870
the other guy tries to go down and get the OS latch

492
00:21:49,870 --> 00:21:51,600
and they get, they get descheduled, right.

493
00:21:52,830 --> 00:21:54,320
And again, this is, this is slow,

494
00:21:54,320 --> 00:21:56,440
because anytime you involve the OS, this is bad.

495
00:22:00,040 --> 00:22:02,850
So the last two, first two latches I showed you,

496
00:22:02,850 --> 00:22:04,035
they didn't really have modes,

497
00:22:04,035 --> 00:22:05,300
it was just all or nothing,

498
00:22:05,980 --> 00:22:08,240
and so the way you implement this in a,

499
00:22:09,790 --> 00:22:12,230
in in in plus with the reader-writer latch,

500
00:22:12,460 --> 00:22:13,605
you can use shared_mutex,

501
00:22:13,605 --> 00:22:17,240
I think we we do the read write lock in in BusTub,

502
00:22:17,530 --> 00:22:19,340
which is just pthread read-write lock.

503
00:22:19,870 --> 00:22:21,825
And the way this basically works is that,

504
00:22:21,825 --> 00:22:24,320
the latch itself is going to have its own priority queues,

505
00:22:24,370 --> 00:22:26,660
its own counterters, keep track of like how many threads are waiting,

506
00:22:27,040 --> 00:22:33,080
you actually can find the scheduling policy for the the, the, the the latch itself.

507
00:22:33,610 --> 00:22:34,880
So the idea here is that,

508
00:22:35,200 --> 00:22:38,480
if I have a, a reader thread comes along

509
00:22:38,770 --> 00:22:39,830
and once acquire the latch,

510
00:22:40,030 --> 00:22:42,720
I go check to see whether anybody waiting for the read latch

511
00:22:42,720 --> 00:22:45,170
or the latch in read mode or write mode,

512
00:22:46,090 --> 00:22:46,820
if it's available,

513
00:22:46,930 --> 00:22:48,075
then I increment my counter

514
00:22:48,075 --> 00:22:50,400
to say somebody's holding the the read latch now

515
00:22:50,400 --> 00:22:51,950
and I go ahead and do whatever I want.

516
00:22:52,360 --> 00:22:53,605
And now if anybody else comes along,

517
00:22:53,605 --> 00:22:54,870
also wants acquire the read mode,

518
00:22:55,010 --> 00:22:56,080
the system knows I'm,

519
00:22:56,080 --> 00:22:58,710
the the latch knows I'm in read mode right now,

520
00:22:58,850 --> 00:23:00,810
so it can let the other guy run as well.

521
00:23:01,220 --> 00:23:04,140
But now if if a write latch write worker comes along,

522
00:23:04,400 --> 00:23:05,340
tries acquire the latch,

523
00:23:05,690 --> 00:23:09,390
we have two read, read workers already holding the latch in read mode,

524
00:23:09,590 --> 00:23:10,615
so it's going to have to stall

525
00:23:10,615 --> 00:23:12,880
and they maintain an internal priority queue

526
00:23:12,880 --> 00:23:14,700
to keep track of what threads are waiting for this.

527
00:23:15,290 --> 00:23:16,585
So then, depending on the policy,

528
00:23:16,585 --> 00:23:17,850
you can configure in the latch,

529
00:23:18,140 --> 00:23:19,470
if another thread comes along,

530
00:23:19,760 --> 00:23:20,850
then once again in read mode

531
00:23:20,990 --> 00:23:23,310
and in theory I could, I could acquire it,

532
00:23:23,510 --> 00:23:27,180
because it's commutative with all the other latches or the workers that hold it in read mode,

533
00:23:27,410 --> 00:23:28,560
I could it query right away,

534
00:23:28,700 --> 00:23:29,905
but you can set the policy,

535
00:23:29,905 --> 00:23:32,730
to say I know another thread is waiting for it in write mode,

536
00:23:32,930 --> 00:23:36,690
so let me go ahead and put it to sleep, right.

537
00:23:37,510 --> 00:23:38,340
And in C++,

538
00:23:38,340 --> 00:23:40,485
I think they're doing this all in in userspace,

539
00:23:40,485 --> 00:23:41,565
not, not down in the kernel,

540
00:23:41,565 --> 00:23:45,855
but, but when you have to then block and wait for the require the latch you're looking for,

541
00:23:45,855 --> 00:23:48,230
then that's going to be an OS kernel, OS mutex,

542
00:23:48,520 --> 00:23:49,430
which we don't want to do.

543
00:23:50,970 --> 00:23:54,125
So the, again, I just showing you a high level overview

544
00:23:54,125 --> 00:23:56,705
of the the the test-and-set operation, compare-and-swap,

545
00:23:56,705 --> 00:24:02,190
is the basing building block that you used to build more complicated latch primitives,

546
00:24:03,470 --> 00:24:04,120
And depending on that,

547
00:24:04,120 --> 00:24:05,520
whether you want the OS to do it or not,

548
00:24:07,260 --> 00:24:08,350
most systems, most,

549
00:24:10,710 --> 00:24:13,040
most bigger database systems, the enterprise ones,

550
00:24:13,040 --> 00:24:14,710
will not rely on the OS for anything,

551
00:24:15,060 --> 00:24:16,600
and it's a combination for portability,

552
00:24:16,650 --> 00:24:19,420
and also it's just faster to avoid the OS

553
00:24:19,800 --> 00:24:20,800
and Linus goes wrong.

554
00:24:24,390 --> 00:24:25,330
Alright, so now let's,

555
00:24:25,680 --> 00:24:26,075
yes.

556
00:24:26,075 --> 00:24:26,915
I just want to clarify,

557
00:24:26,915 --> 00:24:29,500
is the blocking mutex also built on test-and-set?

558
00:24:30,100 --> 00:24:32,810
The question is, is blocking mutex [] that build on test-and-set,

559
00:24:32,920 --> 00:24:33,830
all of them are, yes,

560
00:24:34,000 --> 00:24:35,085
yeah, like that's the,

561
00:24:35,085 --> 00:24:36,350
you ever know what compare-and-swap is?

562
00:24:38,400 --> 00:24:43,240
No, okay, I have slides, one slide.

563
00:24:43,650 --> 00:24:46,550
All right, so compare-and-swap is this atomic instruction,

564
00:24:46,550 --> 00:24:48,730
that, that modern CPUs provide,

565
00:24:48,960 --> 00:24:50,920
that allow you to check a memory location

566
00:24:51,210 --> 00:24:52,450
to see whether it's a current,

567
00:24:52,560 --> 00:24:56,650
whether the current value of that memory address is what you expected it to be,

568
00:24:56,970 --> 00:24:59,390
and if it is, then I can go ahead

569
00:24:59,390 --> 00:25:00,910
and overwrite it with my new value

570
00:25:01,500 --> 00:25:02,710
in, in a single instruction,

571
00:25:03,540 --> 00:25:05,075
if you had to do this in C++ code

572
00:25:05,075 --> 00:25:07,150
to be like if the value equals this,

573
00:25:07,790 --> 00:25:09,390
then set it to that,

574
00:25:09,740 --> 00:25:12,490
but again, if that was just the actual instructions to do that,

575
00:25:12,490 --> 00:25:13,525
that would be multiple instructions,

576
00:25:13,525 --> 00:25:15,870
and by the time you go check to see whether that value is,

577
00:25:16,040 --> 00:25:18,000
you know, is the flag set to true,

578
00:25:18,470 --> 00:25:20,050
by the time you go and then go update it,

579
00:25:20,050 --> 00:25:23,820
somebody else might have [] in and sneaked in before you did and update before before.

580
00:25:24,520 --> 00:25:25,750
And so on modern CPUs,

581
00:25:25,750 --> 00:25:27,040
you can do this in a single instruction,

582
00:25:27,040 --> 00:25:28,560
that's atomic, to guarantee that,

583
00:25:28,700 --> 00:25:30,450
by when you check it and set it,

584
00:25:30,470 --> 00:25:32,040
no one else can get in before you do.

585
00:25:32,560 --> 00:25:35,280
And then that's the basic primitive, allows us to do more complicated things.

586
00:25:36,220 --> 00:25:39,780
So there's a bunch of different intrinsics in, in, in C and C++

587
00:25:39,780 --> 00:25:41,180
you can use for this, right,

588
00:25:41,590 --> 00:25:42,690
they have different versions of this,

589
00:25:42,690 --> 00:25:47,390
like some like if you, if the test-and-set can succeed or the compare-and-swap succeed,

590
00:25:47,530 --> 00:25:50,240
they'll return back the old value or the new value or true and false,

591
00:25:50,380 --> 00:25:51,980
but they're all basically doing the same thing,

592
00:25:52,420 --> 00:25:53,660
so let's say in this case here,

593
00:25:53,860 --> 00:25:54,660
for this intrinsic,

594
00:25:54,660 --> 00:25:56,150
I'm saying here's the address I want to check

595
00:25:56,260 --> 00:25:57,830
and assume it's a 64 bit integer,

596
00:25:58,000 --> 00:26:01,280
here's the value that I want to see whether is currently set to,

597
00:26:01,450 --> 00:26:04,250
and then if it is, here's the value I want to set it to right now.

598
00:26:04,630 --> 00:26:06,105
So we jump to this memory address here,

599
00:26:06,105 --> 00:26:09,050
it's 20, 20 equals 20, yes,

600
00:26:09,340 --> 00:26:11,120
then I go ahead and overwrite with 30.

601
00:26:13,010 --> 00:26:13,620
Pretty simple,

602
00:26:14,540 --> 00:26:16,770
but that's again, that's the building block, we need to have all,

603
00:26:16,850 --> 00:26:19,050
you know, to build all our more complicated latches.

604
00:26:21,290 --> 00:26:23,635
I don't know when this compare-and-swap stuff was added,

605
00:26:23,635 --> 00:26:24,810
I think it was like the late 90s,

606
00:26:25,310 --> 00:26:26,430
at least in 1986.

607
00:26:28,600 --> 00:26:29,150
So we good.

608
00:26:29,760 --> 00:26:31,070
Okay, cool, all right.

609
00:26:32,880 --> 00:26:34,810
So let's see how we can do this for hash tables now,

610
00:26:34,860 --> 00:26:36,100
or use latch on hash tables.

611
00:26:37,120 --> 00:26:39,435
So hash table is going to be easy to support,

612
00:26:39,435 --> 00:26:42,890
because assuming linear probe hashing is that,

613
00:26:43,270 --> 00:26:45,980
there's only certain many ways you can actually access the hash table,

614
00:26:46,930 --> 00:26:49,610
I hash, assuming it's linear, linear, linear probe hashing,

615
00:26:49,720 --> 00:26:53,505
I hash to some location into my hash hash array or a hash table

616
00:26:53,505 --> 00:26:56,210
and I then I scan down from top to down

617
00:26:56,560 --> 00:26:59,120
to looking for the entries, I'm looking, you know, that I need, right.

618
00:27:00,520 --> 00:27:01,515
And in this case here,

619
00:27:01,515 --> 00:27:03,380
because the threads are all moving in the same direction,

620
00:27:03,790 --> 00:27:04,980
like going top down,

621
00:27:04,980 --> 00:27:07,490
even though they may start at different locations in the hash table,

622
00:27:07,990 --> 00:27:09,470
I can't have any deadlocks,

623
00:27:10,030 --> 00:27:14,690
because there isn't one thread going top down, another thread going bottom up, right.

624
00:27:15,860 --> 00:27:18,310
So, the question is going to be to,

625
00:27:18,310 --> 00:27:19,810
what granularity do we do,

626
00:27:19,810 --> 00:27:21,660
we want to have our latch to protect our data structure,

627
00:27:21,950 --> 00:27:25,380
because that's going to determine the amount of parallelism we'll be able to support.

628
00:27:26,440 --> 00:27:27,320
For this lecture,

629
00:27:27,400 --> 00:27:29,780
we're going to ignore how to handle resizing the table,

630
00:27:30,400 --> 00:27:32,115
the way, the simplest way to handle that is,

631
00:27:32,115 --> 00:27:38,930
you have sort of a write latch that protects the, the access to the data structure itself,

632
00:27:39,220 --> 00:27:42,110
so if if I get full and I need to double the size of it,

633
00:27:42,220 --> 00:27:44,000
I just switch that latch into write mode

634
00:27:44,200 --> 00:27:45,770
and then do my, my resizing

635
00:27:45,880 --> 00:27:48,170
and that prevents everybody else from coming in,

636
00:27:48,760 --> 00:27:49,970
that's the easiest way to do this.

637
00:27:51,960 --> 00:27:56,030
So the scopes of our latches can either be within a page or slot,

638
00:27:56,030 --> 00:27:57,910
and again, this is going to determine amount of parallelism we have,

639
00:27:58,350 --> 00:28:02,890
so obviously when a page latch is going to protect the entire page itself with a latch,

640
00:28:03,360 --> 00:28:06,820
and no matter whether you want to read one entry or all the entries in the page,

641
00:28:07,080 --> 00:28:08,980
you would, you would hold a latch on the entire thing.

642
00:28:09,750 --> 00:28:13,780
The alternative would be, you would have a latch for every single slot in a page,

643
00:28:14,540 --> 00:28:16,340
and this is going to allow more fine-grain access,

644
00:28:16,340 --> 00:28:18,340
but again, now the challenge is that,

645
00:28:18,720 --> 00:28:19,715
I'm going to take more space,

646
00:28:19,715 --> 00:28:21,820
because every single, every single slot needs to have a latch,

647
00:28:22,290 --> 00:28:25,330
and now, as I'm scanning through my my hash table,

648
00:28:25,470 --> 00:28:28,510
I got to acquire the latch for every single slot as I'm going along.

649
00:28:29,350 --> 00:28:32,600
So again, there's no free lunch in, in, in systems or in computer science,

650
00:28:32,860 --> 00:28:35,450
it's either I have a single latch per page,

651
00:28:35,680 --> 00:28:37,580
which I only acquire, once for the page,

652
00:28:38,290 --> 00:28:39,285
and it doesn't take a lot of space,

653
00:28:39,285 --> 00:28:41,390
but then it blocks everyone else out from a the entire page

654
00:28:41,710 --> 00:28:44,120
or I have it for every single slot.

655
00:28:46,620 --> 00:28:48,730
So say hash table like this,

656
00:28:50,340 --> 00:28:51,430
T1 wants to come along,

657
00:28:51,600 --> 00:28:53,230
thread 1 wants come along and find D,

658
00:28:53,370 --> 00:28:55,210
we hash D, we landed this location here,

659
00:28:55,410 --> 00:28:58,930
we get the entire page in in in write mode,

660
00:28:59,340 --> 00:29:02,260
look, try to find the entries that we're looking for by just scanning down,

661
00:29:02,430 --> 00:29:04,460
but at the same time, another thread wants to come along,

662
00:29:04,460 --> 00:29:05,440
wants to insert E,

663
00:29:05,880 --> 00:29:07,205
same thing, I hashed to this page,

664
00:29:07,205 --> 00:29:10,840
but the latch is already, the page is already latched in in read mode

665
00:29:10,980 --> 00:29:14,170
and that's not commutative with, the write mode latch and needs to do the insert,

666
00:29:14,620 --> 00:29:16,680
so we have to stall thread 2,

667
00:29:17,490 --> 00:29:20,890
and again, whether it's spinning in userspace or got rescheduled by the kernel,

668
00:29:21,000 --> 00:29:22,330
that depends on your latch implementation.

669
00:29:23,730 --> 00:29:28,570
So now when the when thread 1 is done scanning this page,

670
00:29:28,830 --> 00:29:30,130
it can jump to the next page,

671
00:29:30,360 --> 00:29:33,110
it still holds the latch to the page it started at,

672
00:29:33,110 --> 00:29:36,710
because it needs to know how to, where to look at next, right,

673
00:29:36,710 --> 00:29:38,380
to make sure nobody's moving things around.

674
00:29:39,060 --> 00:29:42,340
And so we we can then release the latch on page number 1,

675
00:29:42,930 --> 00:29:44,225
acquire the latch on page number 2,

676
00:29:44,225 --> 00:29:46,690
and then now thread 2 can start running

677
00:29:46,740 --> 00:29:48,760
and try to figure out where wants to insert.

678
00:29:50,240 --> 00:29:52,860
The same thing once once come down here to do the write,

679
00:29:53,270 --> 00:29:56,520
the the read latch is not commutative with the write, write latch,

680
00:29:56,990 --> 00:29:58,230
so therefore it has to wait,

681
00:29:58,580 --> 00:29:59,820
then once thread 1 is done,

682
00:30:00,860 --> 00:30:03,990
thread 2 can then acquire the latch and do the update to insert its entry.

683
00:30:08,730 --> 00:30:09,340
Yes, question.

684
00:30:21,740 --> 00:30:22,360
Your question is,

685
00:30:22,360 --> 00:30:24,840
if I hold, if I hold the, I have a read latch,

686
00:30:27,540 --> 00:30:28,955
say there again, sorry.

687
00:30:39,610 --> 00:30:42,030
So going back to like the very beginning here?

688
00:30:51,500 --> 00:30:54,600
So again, say this scenario here,

689
00:30:54,680 --> 00:30:56,550
say T2 shows up before T1,

690
00:30:58,350 --> 00:31:00,880
and what the race condition you trying to deal with?

691
00:31:12,160 --> 00:31:13,670
Alright, so what you say read, write,

692
00:31:13,780 --> 00:31:15,080
read and then write and then read,

693
00:31:15,340 --> 00:31:19,640
like that second read, is that like another find a key?

694
00:31:30,030 --> 00:31:30,760
But is it wrong?

695
00:31:39,430 --> 00:31:41,480
Yeah, so, so.

696
00:31:46,670 --> 00:31:49,110
So yeah, so there's,

697
00:31:50,820 --> 00:31:53,530
there, this is the logical correctness thing, right.

698
00:31:55,630 --> 00:31:57,980
If say I I I do a SELECT,

699
00:31:58,150 --> 00:32:00,440
I run a little SELECT query,

700
00:32:00,610 --> 00:32:01,830
that does look up in this hash table

701
00:32:01,830 --> 00:32:03,980
and I find D right

702
00:32:04,330 --> 00:32:05,480
and, and I get back the answer,

703
00:32:06,370 --> 00:32:11,175
now some other transaction, another thread comes along and deletes D, right,

704
00:32:11,175 --> 00:32:12,200
and [] in the hash table,

705
00:32:12,430 --> 00:32:15,735
then, then the first thread again now runs another SELECT query that finds D

706
00:32:15,735 --> 00:32:17,240
and it doesn't come back with it, right.

707
00:32:17,350 --> 00:32:19,550
From the data structure perspective,

708
00:32:19,900 --> 00:32:21,860
that's fine for what we're talking about today.

709
00:32:22,670 --> 00:32:24,030
When we talk about after the midterm,

710
00:32:24,320 --> 00:32:29,820
that's, that's, that's an anomaly of inconsistent reads.

711
00:32:30,460 --> 00:32:34,320
And that's something that the mechanism for the system will handle in transaction level,

712
00:32:34,610 --> 00:32:36,840
at the low level level of the data structure, we don't care,

713
00:32:37,610 --> 00:32:38,250
it's correct,

714
00:32:38,450 --> 00:32:43,170
who decides what in the order what, what writes we should see or not see,

715
00:32:43,490 --> 00:32:44,880
that's a higher level thing that comes later.

716
00:32:45,480 --> 00:32:45,770
Yes,

717
00:32:46,060 --> 00:32:49,070
and the great thing about databases or these transactions is like,

718
00:32:49,240 --> 00:32:52,370
there's multiple answers that are all technically correct, potentially,

719
00:32:54,110 --> 00:32:55,350
but we'll get that later.

720
00:32:58,470 --> 00:33:00,740
No, well, in the specification of SQL,

721
00:33:00,740 --> 00:33:06,995
there's, there's a, there's a, there's a description about what is considered correct or not correct at different isolation levels,

722
00:33:06,995 --> 00:33:08,870
which we haven't covered yet, right,

723
00:33:09,100 --> 00:33:14,920
and the, the easiest, the most strictest correctness level would be, isolation level be,

724
00:33:15,150 --> 00:33:18,130
called strict serializable or strong serializable,

725
00:33:18,180 --> 00:33:19,150
basically means that like,

726
00:33:20,140 --> 00:33:22,260
whoever comes first should should see

727
00:33:22,260 --> 00:33:24,830
the system as if it was running by itself

728
00:33:25,060 --> 00:33:28,130
and its changes get applied first, right,

729
00:33:28,570 --> 00:33:30,140
and then everything else comes after that.

730
00:33:30,280 --> 00:33:34,050
But getting way, way ahead of ourselves, from the database perspective,

731
00:33:34,050 --> 00:33:37,010
I don't care that your thread came in and and deleted D,

732
00:33:37,300 --> 00:33:39,105
look for D, then D got deleted

733
00:33:39,105 --> 00:33:40,400
and you go to look for it again, it's missing,

734
00:33:40,840 --> 00:33:42,260
that's not the data structures problem,

735
00:33:42,910 --> 00:33:43,880
that's somebody else's problem,

736
00:33:44,260 --> 00:33:46,460
it's our problem, but like, not, not today's lecture.

737
00:33:49,825 --> 00:33:50,640
And it's really hard, yeah.

738
00:33:53,100 --> 00:33:55,445
Oh, it's why all the NoSQL guys didn't use transactions in the beginning,

739
00:33:55,445 --> 00:33:56,890
because this is hard, right?

740
00:33:59,300 --> 00:34:00,190
All right, we'll come to that later.

741
00:34:01,410 --> 00:34:02,890
A lot of things they didn't do, because it's hard,

742
00:34:03,480 --> 00:34:04,960
and then they had to do it later.

743
00:34:06,690 --> 00:34:08,590
Alright, again, let me just show you how to do slot latches.

744
00:34:10,520 --> 00:34:12,505
Again, now I have a latch on every single slot itself

745
00:34:12,505 --> 00:34:13,140
and my hash table.

746
00:34:13,520 --> 00:34:14,910
So now when I do a find D,

747
00:34:14,960 --> 00:34:18,120
I get the latch, on the read latch on the slot itself,

748
00:34:18,680 --> 00:34:20,370
I can go ahead and read what I'm looking for

749
00:34:20,450 --> 00:34:22,230
and say this guy now wants to jump to this page,

750
00:34:22,400 --> 00:34:27,420
he wants to get the write latch on, on C,

751
00:34:27,980 --> 00:34:28,945
ignore how he found that,

752
00:34:28,945 --> 00:34:30,000
because he hash there.

753
00:34:31,440 --> 00:34:35,620
The now when the the first thread tries to get the read latch on the next slot,

754
00:34:35,670 --> 00:34:36,455
he can't,

755
00:34:36,455 --> 00:34:38,590
because the other thread has the latch,

756
00:34:38,760 --> 00:34:39,730
so he has a stall,

757
00:34:40,140 --> 00:34:40,930
but at this point,

758
00:34:41,760 --> 00:34:43,150
even though he's going to stall and wait,

759
00:34:43,320 --> 00:34:46,210
it's safe for him to release the latch on the previous previous slot,

760
00:34:46,620 --> 00:34:49,920
because, he has his,

761
00:34:50,690 --> 00:34:52,120
there's, there's no issue,

762
00:34:52,120 --> 00:34:55,780
there's no reason for him to keep holding holding this this latch, right,

763
00:34:55,780 --> 00:34:57,600
because he's just going to spin and wait for this thing here

764
00:34:57,710 --> 00:35:00,420
and everything's still [] there.

765
00:35:00,950 --> 00:35:04,800
I mentioned the reorganization of the, of, of the hash table itself,

766
00:35:05,180 --> 00:35:06,420
like, if you have to resize it,

767
00:35:06,740 --> 00:35:10,050
assume that there's some other latch protecting the entire thing that's in read mode,

768
00:35:10,130 --> 00:35:11,070
so that's okay,

769
00:35:11,520 --> 00:35:12,800
we only set that to write mode,

770
00:35:12,800 --> 00:35:14,030
if we have to resize the whole thing,

771
00:35:14,030 --> 00:35:16,270
so, so the global latch for,

772
00:35:16,740 --> 00:35:18,790
T2 would have the global latch in read mode.

773
00:35:19,890 --> 00:35:20,290
Yes.

774
00:35:20,700 --> 00:35:24,710
No, this is,

775
00:35:25,420 --> 00:35:28,620
just think like it's some offset in some page for our hash table,

776
00:35:28,700 --> 00:35:29,700
so it's all fixed length.

777
00:35:30,600 --> 00:35:31,000
Yeah.

778
00:35:32,070 --> 00:35:32,645
So like this.

779
00:35:32,645 --> 00:35:35,680
up the page into more Yeah, correct, yes, yeah,

780
00:35:36,480 --> 00:35:39,260
basically, do you want fine, fine-grain latches or coarse-grain latches,

781
00:35:39,260 --> 00:35:39,850
that's all it is.

782
00:35:41,550 --> 00:35:41,950
Okay.

783
00:35:43,150 --> 00:35:44,510
So this should be pretty straightforward.

784
00:35:45,330 --> 00:35:45,730
Okay.

785
00:35:46,360 --> 00:35:47,155
Let's get to B+ trees,

786
00:35:47,155 --> 00:35:49,410
because this is harder and and more fun.

787
00:35:51,230 --> 00:35:52,350
So again, just like before,

788
00:35:52,850 --> 00:35:54,175
in our hash table and B+ tree,

789
00:35:54,175 --> 00:35:55,800
want to have multiple threads read at the same time.

790
00:35:57,380 --> 00:35:58,920
The challenge here is now,

791
00:35:59,210 --> 00:36:01,590
in the hash table, with linear probing,

792
00:36:01,910 --> 00:36:03,540
the the number of pages was fixed,

793
00:36:04,290 --> 00:36:07,090
and the organization of the data structure was fixed,

794
00:36:07,970 --> 00:36:09,265
meaning like, you know, matter,

795
00:36:09,265 --> 00:36:11,490
if I, if I create my hash table

796
00:36:11,630 --> 00:36:13,680
and I have say a million slots,

797
00:36:13,970 --> 00:36:14,635
it doesn't matter,

798
00:36:14,635 --> 00:36:16,705
whether I have a thousand threads going at it

799
00:36:16,705 --> 00:36:17,935
or one thread going at it,

800
00:36:17,935 --> 00:36:19,140
I'm always going to have a million slots,

801
00:36:19,340 --> 00:36:19,855
and as a matter,

802
00:36:19,855 --> 00:36:22,020
if I have, you know, have a million keys in it or not,

803
00:36:22,220 --> 00:36:23,700
the data structure is always the same.

804
00:36:24,570 --> 00:36:25,655
In a B+ tree,

805
00:36:25,655 --> 00:36:29,500
says the data structure is, is is self organize or self balancing,

806
00:36:29,730 --> 00:36:31,450
as I insert things into it,

807
00:36:31,680 --> 00:36:33,130
oh sorry, deleting things from it,

808
00:36:33,450 --> 00:36:35,560
It's going to start reorganizing itself.

809
00:36:36,530 --> 00:36:37,465
So I need to make sure that,

810
00:36:37,465 --> 00:36:39,730
as I'm reorganizing things, the splits, emerges,

811
00:36:39,730 --> 00:36:42,055
I make sure that, I have to make sure that,

812
00:36:42,055 --> 00:36:43,200
the data structure is correct.

813
00:36:45,230 --> 00:36:46,530
All right, so let's see how things can go bad.

814
00:36:46,880 --> 00:36:48,090
Say we have a thread here

815
00:36:48,290 --> 00:36:51,210
and they want to delete key 44 at the bottom,

816
00:36:51,740 --> 00:36:52,500
so what do I do,

817
00:36:52,640 --> 00:36:55,255
I traverse down and I look at the guidepost markers

818
00:36:55,255 --> 00:36:56,965
to figure out whether I want to go left and right

819
00:36:56,965 --> 00:37:00,750
and I reach down to my my leaf node here

820
00:37:01,010 --> 00:37:02,160
and I go ahead and delete it.

821
00:37:02,570 --> 00:37:03,685
But now I have to rebalance,

822
00:37:03,685 --> 00:37:04,450
I have to do a merge,

823
00:37:04,450 --> 00:37:08,340
because this leaf node is is less than half full,

824
00:37:08,450 --> 00:37:12,535
so maybe I'll steal an entry from my sibling,

825
00:37:12,535 --> 00:37:14,520
gonna move 41 over, right,

826
00:37:14,780 --> 00:37:16,410
but before I can do that,

827
00:37:17,410 --> 00:37:19,665
my thread gets descheduleded, right,

828
00:37:19,665 --> 00:37:20,280
for whatever reason,

829
00:37:20,280 --> 00:37:22,215
the OS decided to do something, [] came down,

830
00:37:22,215 --> 00:37:23,360
it doesn't matter, right,

831
00:37:23,740 --> 00:37:24,950
my thread's not running anymore.

832
00:37:25,840 --> 00:37:28,580
So now, while while thread 1 is asleep,

833
00:37:28,630 --> 00:37:29,475
thread 2 comes along

834
00:37:29,475 --> 00:37:30,680
and they want to find 41

835
00:37:31,090 --> 00:37:34,130
and they start traversing down just like before and they get here, right,

836
00:37:34,480 --> 00:37:35,955
and again, now they look at the guidepost,

837
00:37:35,955 --> 00:37:37,310
they follow the the,

838
00:37:37,450 --> 00:37:40,940
they realize they want to go down to the, to the right to node H,

839
00:37:41,680 --> 00:37:43,980
but now it gets descheduled for whatever reason.

840
00:37:44,670 --> 00:37:48,370
And then thread 1 wakes up, moves 41,

841
00:37:49,250 --> 00:37:51,030
T1, T2, thread 2 wakes up,

842
00:37:51,170 --> 00:37:53,490
goes down to the node, thought it was need of the go to,

843
00:37:53,720 --> 00:37:55,050
and now the key's not there.

844
00:37:57,490 --> 00:37:58,280
Best case scenario,

845
00:37:58,330 --> 00:37:59,570
you get a false negative here,

846
00:37:59,950 --> 00:38:00,740
worst case scenario,

847
00:38:00,790 --> 00:38:01,370
you crash,

848
00:38:02,200 --> 00:38:05,160
and the system fails, and you could corrupt your data.

849
00:38:07,550 --> 00:38:09,120
So we need latches to protect this thing.

850
00:38:10,820 --> 00:38:13,765
And so the technique we're going to use is called latch crabbing or latch coupling,

851
00:38:13,765 --> 00:38:15,355
I think the textbook calls it latch coupling,

852
00:38:15,355 --> 00:38:18,270
I think the Wikipedia calls it latch latch coupling, right,

853
00:38:18,770 --> 00:38:22,320
but it's basically the protocol we're going to use to decide

854
00:38:23,510 --> 00:38:25,290
as we traverse down our tree,

855
00:38:26,020 --> 00:38:28,500
what latches we want to take

856
00:38:28,940 --> 00:38:31,920
and then when can we release the latches up above us.

857
00:38:32,710 --> 00:38:35,310
Because again, the easiest way to protect this entire data structure is

858
00:38:35,310 --> 00:38:37,130
put a giant latch on top, the whole thing,

859
00:38:37,420 --> 00:38:39,045
and then everyone has to get gatekeep through,

860
00:38:39,045 --> 00:38:41,030
but then that becomes a bottleneck.

861
00:38:41,480 --> 00:38:42,640
So we want to be more clever

862
00:38:42,690 --> 00:38:45,760
and selectively release our latches as we go down,

863
00:38:46,020 --> 00:38:47,110
when we know it's okay.

864
00:38:48,280 --> 00:38:49,370
So the basic protocol is,

865
00:38:49,600 --> 00:38:51,770
in order for me to go into B+ tree,

866
00:38:51,940 --> 00:38:54,720
you always set to latch the root,

867
00:38:54,720 --> 00:38:56,960
but, but once I'm in my my root

868
00:38:57,130 --> 00:38:59,510
and I I figure out whether I want to go left and right

869
00:38:59,860 --> 00:39:01,670
and then I acquire the latch of my child,

870
00:39:01,750 --> 00:39:03,410
that I'm going to go down from the current parent I'm at

871
00:39:03,700 --> 00:39:05,180
and then once I'm know I'm okay

872
00:39:05,440 --> 00:39:06,620
and I'm able to go there,

873
00:39:06,700 --> 00:39:09,890
I can release my parent latch for that current node I'm at

874
00:39:10,210 --> 00:39:11,510
if if I know it's safe.

875
00:39:12,910 --> 00:39:14,810
And the definition of safe is going to be that,

876
00:39:15,130 --> 00:39:19,430
we know that based on the operation we're trying to do, insert or delete,

877
00:39:20,140 --> 00:39:21,750
if it's an insert,

878
00:39:21,920 --> 00:39:24,150
we know that the child isn't full

879
00:39:24,350 --> 00:39:28,290
and therefore if I, if I had to do a split,

880
00:39:30,140 --> 00:39:31,050
sorry, when I insert my key,

881
00:39:31,160 --> 00:39:33,565
it's not going to cause to do a split at that child node,

882
00:39:33,565 --> 00:39:35,220
which may get propagated up to the parent.

883
00:39:35,870 --> 00:39:37,020
If I'm going to do a delete,

884
00:39:37,670 --> 00:39:39,130
if I know that it's more than half full,

885
00:39:39,130 --> 00:39:40,345
then again, if I remove a key,

886
00:39:40,345 --> 00:39:41,785
I know I'm not going to do a merge,

887
00:39:41,785 --> 00:39:46,330
which again, we propagate things up to my parent node here, right.

888
00:39:47,810 --> 00:39:48,955
So again, the basic protocol is,

889
00:39:48,955 --> 00:39:50,130
I started the root traverse down,

890
00:39:50,450 --> 00:39:52,000
acquire read latches on every child,

891
00:39:52,000 --> 00:39:52,765
as I'm going down,

892
00:39:52,765 --> 00:39:54,420
because again, I'm doing a read operation,

893
00:39:54,500 --> 00:39:55,590
I'm not doing updates,

894
00:39:56,030 --> 00:39:57,360
and then I just unlatch my parent,

895
00:39:58,010 --> 00:39:59,770
for doing insert or delete,

896
00:39:59,770 --> 00:40:00,505
I start at root,

897
00:40:00,505 --> 00:40:02,130
taking write latches as I go down

898
00:40:02,510 --> 00:40:05,095
and then once I have my child,

899
00:40:05,095 --> 00:40:07,170
know that I'm going to move to in write mode,

900
00:40:07,820 --> 00:40:09,280
then I go check to see whether it's safe

901
00:40:09,570 --> 00:40:10,520
and if it is safe

902
00:40:10,520 --> 00:40:12,760
and I can go release any latches I have up above me.

903
00:40:15,200 --> 00:40:16,470
So let's go back to our example here.

904
00:40:16,640 --> 00:40:18,060
So I want to find key 38,

905
00:40:18,650 --> 00:40:19,620
I start the root,

906
00:40:19,760 --> 00:40:23,970
take the root in, in root node in write latch mode,

907
00:40:25,190 --> 00:40:26,230
I get down to,

908
00:40:26,230 --> 00:40:29,220
sorry, then I acquire the the read latch on B,

909
00:40:29,450 --> 00:40:30,240
then I move down

910
00:40:30,470 --> 00:40:31,405
and at this point here,

911
00:40:31,405 --> 00:40:34,350
it's safe for me to release the latch on, on A,

912
00:40:34,790 --> 00:40:36,360
because again, it's doing a read operation,

913
00:40:36,710 --> 00:40:37,915
I've already arrived at B,

914
00:40:37,915 --> 00:40:38,545
where I need to go,

915
00:40:38,545 --> 00:40:39,480
so I'm going to go there,

916
00:40:39,740 --> 00:40:41,460
so I can go ahead and release the latch on B,

917
00:40:42,030 --> 00:40:43,840
get the latch, read latch on D,

918
00:40:43,980 --> 00:40:45,890
same thing, it's safe for me to release the latch on B,

919
00:40:45,890 --> 00:40:46,660
so I'll go ahead and do that

920
00:40:46,980 --> 00:40:48,755
and I get down to H and so forth

921
00:40:48,755 --> 00:40:49,910
and I finally get the key I'm looking for,

922
00:40:49,910 --> 00:40:50,410
and I'm done.

923
00:40:55,040 --> 00:40:55,840
Alright, it's delete 38 now.

924
00:40:56,400 --> 00:40:57,200
Again, started the root,

925
00:40:57,200 --> 00:41:01,150
I get the root in, in root latch, the root node in write mode latch,

926
00:41:02,480 --> 00:41:05,190
I get a write latch on B, move down here,

927
00:41:05,920 --> 00:41:07,500
and again, at this point here,

928
00:41:08,840 --> 00:41:10,260
if I, if I do,

929
00:41:10,310 --> 00:41:12,450
I don't know what's going to happen below me in the tree, below B

930
00:41:12,950 --> 00:41:17,610
and because if I know if I have to delete a key from the node I'm currently at, at B,

931
00:41:17,930 --> 00:41:19,560
I'm gonna have to do a merge,

932
00:41:19,760 --> 00:41:22,950
so therefore I can't release the latch on my parent A,

933
00:41:23,510 --> 00:41:26,280
because I, I may have to go make changes to A of above,

934
00:41:26,850 --> 00:41:29,950
so I'm going to hold the write latch on on on B and A,

935
00:41:30,210 --> 00:41:31,150
get down to D,

936
00:41:31,680 --> 00:41:33,080
now at D, I see that,

937
00:41:33,080 --> 00:41:35,950
no matter what happens to me below in the tree,

938
00:41:36,870 --> 00:41:38,600
if I had to remove a key from D,

939
00:41:38,600 --> 00:41:40,780
D, it's not going to do do do a merge,

940
00:41:41,260 --> 00:41:43,320
and therefore, it's not going to make any changes up above it,

941
00:41:43,670 --> 00:41:47,880
so it's safe for me to go ahead and release the latches on A and B.

942
00:41:49,890 --> 00:41:50,800
Does the order matter?

943
00:41:50,880 --> 00:41:51,460
Sorry, question.

944
00:41:52,170 --> 00:41:56,200
Whatever you're at now, whatever the,

945
00:41:57,280 --> 00:41:59,220
so if I, if I'm at B,

946
00:42:00,120 --> 00:42:02,290
I get the and I need to go to D,

947
00:42:02,610 --> 00:42:04,870
so I get, I get it in write, I get the latch in write mode,

948
00:42:05,600 --> 00:42:06,815
and then now I have write mode,

949
00:42:06,815 --> 00:42:08,140
then I check, am I safe.

950
00:42:15,510 --> 00:42:22,300
This question is,

951
00:42:22,300 --> 00:42:26,280
is is it being half full, the only check to see whether it's safe

952
00:42:26,720 --> 00:42:31,950
and what else, what else would cause a merge in case of a delete.

953
00:42:34,790 --> 00:42:37,150
That's the thing we only care about, like splits emerges,

954
00:42:37,150 --> 00:42:39,060
we're trying to make sure that we don't screw ourselves with that.

955
00:42:43,330 --> 00:42:43,970
All right, so,

956
00:42:45,860 --> 00:42:47,370
so at this one here at D,

957
00:42:47,840 --> 00:42:49,590
we had to release the latches on A and B,

958
00:42:50,360 --> 00:42:51,630
because, again, D is safe.

959
00:42:52,420 --> 00:42:54,450
Does the order in which we release those latches matter?

960
00:43:01,300 --> 00:43:04,305
He says it makes more sense going from the bottom to the top

961
00:43:04,305 --> 00:43:06,320
by releasing B, followed by A, why?

962
00:43:18,000 --> 00:43:21,850
So if I release B and someone waiting for A.

963
00:43:25,040 --> 00:43:25,440
Yes.

964
00:43:30,840 --> 00:43:34,680
So, he says, if you release B, then it does,

965
00:43:35,480 --> 00:43:37,230
sorry, the other thread, waiting for B or A, sorry.

966
00:43:38,600 --> 00:43:39,660
Yeah, has on the same [path].

967
00:43:43,970 --> 00:43:47,130
A latch, but yes, yeah, okay.

968
00:43:48,020 --> 00:43:49,045
But if I release it on B,

969
00:43:49,045 --> 00:43:49,950
it still waiting for A.

970
00:43:52,870 --> 00:43:55,785
Also, too, what if I have a thread that's waiting for A,

971
00:43:55,785 --> 00:43:57,530
but I want to go down this side of the tree,

972
00:43:58,430 --> 00:43:59,550
but I release B,

973
00:44:00,390 --> 00:44:00,950
it's still blocked.

974
00:44:02,470 --> 00:44:03,740
So from a correctness reason,

975
00:44:04,000 --> 00:44:05,090
from a correctness standpoint,

976
00:44:05,140 --> 00:44:06,080
it doesn't actually matter.

977
00:44:06,780 --> 00:44:09,345
Like the system, the the data structure will still be correct,

978
00:44:09,345 --> 00:44:12,170
whether you go from the bottom to the top, top of the bottom.

979
00:44:12,490 --> 00:44:13,545
For performance reasons,

980
00:44:13,545 --> 00:44:14,660
we want to go top down,

981
00:44:15,490 --> 00:44:16,370
because we want to release,

982
00:44:16,570 --> 00:44:17,760
like you way to think about it is

983
00:44:17,760 --> 00:44:20,120
the latch is protecting everything below it,

984
00:44:20,320 --> 00:44:22,190
so if I hold a write latch on the root,

985
00:44:22,210 --> 00:44:25,410
I'm protecting the entire data structure in write mode, right.

986
00:44:28,860 --> 00:44:32,620
Now, there may be a bunch of read threads and other threads doing stuff over here,

987
00:44:33,030 --> 00:44:35,110
but that's okay, because it would have,

988
00:44:35,690 --> 00:44:39,630
if their modifications would have caused us to do a split or merge,

989
00:44:39,770 --> 00:44:41,790
then up the entire to the root,

990
00:44:41,900 --> 00:44:44,040
they would have to still hold the write latch on this.

991
00:44:45,450 --> 00:44:47,765
So again, the main takeaway is that,

992
00:44:47,765 --> 00:44:49,210
we want to release latches as soon as possible,

993
00:44:49,740 --> 00:44:51,320
so, and we want to release latches

994
00:44:51,320 --> 00:44:52,510
that will have the most,

995
00:44:52,770 --> 00:44:57,820
that would free up the most, most of our workers in our data structure,

996
00:44:58,110 --> 00:45:00,040
so we always want to release from the top going down.

997
00:45:03,660 --> 00:45:04,715
All right, so then we get down here

998
00:45:04,715 --> 00:45:06,550
and we get the write latch on H,

999
00:45:06,900 --> 00:45:09,790
go ahead and do our delete and we're done.

1000
00:45:12,710 --> 00:45:13,950
All right, so let's look at another example,

1001
00:45:13,970 --> 00:45:15,090
I'm going to insert 45,

1002
00:45:15,110 --> 00:45:15,750
same idea,

1003
00:45:15,920 --> 00:45:18,030
I get the write latch on the root, on A

1004
00:45:18,290 --> 00:45:19,110
go down to B,

1005
00:45:19,340 --> 00:45:20,260
at this point here,

1006
00:45:20,260 --> 00:45:23,310
I know that if, if,

1007
00:45:23,600 --> 00:45:25,200
whatever is below me in the tree,

1008
00:45:25,430 --> 00:45:26,610
if it has to do a split,

1009
00:45:26,780 --> 00:45:30,120
I have room in B to accommodate another key,

1010
00:45:30,440 --> 00:45:32,970
so it's okay for me to go release the latch on A,

1011
00:45:33,870 --> 00:45:35,170
get down here on D,

1012
00:45:35,430 --> 00:45:37,060
now, D is completely full,

1013
00:45:37,320 --> 00:45:39,040
I don't know what's below me in the tree,

1014
00:45:39,120 --> 00:45:40,210
because I haven't gone there yet,

1015
00:45:40,890 --> 00:45:43,360
so this point here, it's not safe to release,

1016
00:45:43,380 --> 00:45:44,540
to release the latch on D

1017
00:45:44,540 --> 00:45:45,190
until I go down,

1018
00:45:45,420 --> 00:45:46,840
and now I can see that,

1019
00:45:48,270 --> 00:45:51,520
inserting to I, would not cause a split on node I,

1020
00:45:51,690 --> 00:45:54,400
so I can go ahead and release the latches on B and D

1021
00:45:55,020 --> 00:45:55,840
going top down,

1022
00:45:57,600 --> 00:45:58,510
and I can insert my key.

1023
00:46:02,060 --> 00:46:04,630
All right, let's look one where there is a split, right.

1024
00:46:05,070 --> 00:46:07,570
For simplicity, we we could ignore sibling pointers,

1025
00:46:07,860 --> 00:46:11,915
so I'm doing insert 25, B is safe,

1026
00:46:11,915 --> 00:46:13,550
I'm going to release the latch on A,

1027
00:46:13,550 --> 00:46:15,110
I get down to C, C is safe,

1028
00:46:15,110 --> 00:46:16,450
release the latch on B,

1029
00:46:17,100 --> 00:46:19,100
then I get down to F, F is not safe,

1030
00:46:20,340 --> 00:46:23,510
so I can't release the latch on, on C,

1031
00:46:24,130 --> 00:46:25,310
and now I need to do a split

1032
00:46:25,720 --> 00:46:30,290
and that split's going to cause me to insert a new entry up into node C,

1033
00:46:31,500 --> 00:46:32,530
so I'll go ahead and do that,

1034
00:46:32,910 --> 00:46:36,320
add my new, add my new node J,

1035
00:46:36,320 --> 00:46:37,750
I'm out of space because this PowerPoint,

1036
00:46:38,010 --> 00:46:40,060
again, we're ignoring sibling pointers for now,

1037
00:46:40,470 --> 00:46:42,860
go ahead and now do the update to the C,

1038
00:46:42,860 --> 00:46:44,320
could now include this pointer,

1039
00:46:44,900 --> 00:46:47,840
and then once, once I apply all these changes,

1040
00:46:47,840 --> 00:46:49,750
then I release the latches going top down.

1041
00:46:53,150 --> 00:46:54,370
So I've already given this answer before,

1042
00:46:54,370 --> 00:46:56,635
but what was the very first thing I did for all these scenarios,

1043
00:46:56,635 --> 00:46:58,165
when I want to do updates and inserts and deletes,

1044
00:46:58,165 --> 00:46:59,490
what's the very first thing you have to do?

1045
00:47:01,700 --> 00:47:06,900
Get a latch on the, yeah, get a latch on the root node, right.

1046
00:47:08,500 --> 00:47:09,990
And like, yeah, that's correct,

1047
00:47:09,990 --> 00:47:11,250
but this is a bottleneck now,

1048
00:47:11,250 --> 00:47:14,060
because it basically becomes almost a single threaded data structure,

1049
00:47:14,380 --> 00:47:16,100
that everybody has to go into the system,

1050
00:47:16,970 --> 00:47:18,240
sorry, going to our data structure,

1051
00:47:18,320 --> 00:47:19,800
the first thing get to do is is,

1052
00:47:20,270 --> 00:47:22,790
acquire the latch in write mode, in the root,

1053
00:47:23,140 --> 00:47:25,140
if you're doing reads, that's not gonna be compatible,

1054
00:47:25,140 --> 00:47:26,420
so it'll block all the readers too.

1055
00:47:28,630 --> 00:47:29,415
Again, it's correct,

1056
00:47:29,415 --> 00:47:30,435
but for my performance reasons,

1057
00:47:30,435 --> 00:47:32,860
it's, it's not ideal.

1058
00:47:33,830 --> 00:47:37,020
And so the, the common technique everyone uses is,

1059
00:47:37,550 --> 00:47:40,530
this optimistic latching scheme I'll talk about now,

1060
00:47:41,480 --> 00:47:42,805
I don't think the algorithm has a name,

1061
00:47:42,805 --> 00:47:43,600
it's from this paper,

1062
00:47:43,600 --> 00:47:46,375
from, I think it's from, from the 70s,

1063
00:47:46,375 --> 00:47:47,220
is there date on that,

1064
00:47:48,570 --> 00:47:49,900
7, it says 77, yeah,

1065
00:47:49,980 --> 00:47:51,860
from these guys at IBM Bayer and Schkolnick,

1066
00:47:51,860 --> 00:47:53,435
sometimes it's called the Bayer-Schkolnick algorithm,

1067
00:47:53,435 --> 00:47:54,910
which is kind of cumbersome to say,

1068
00:47:54,960 --> 00:47:57,330
but, it's based on this observation,

1069
00:47:57,410 --> 00:48:00,210
that you know that most of your threads, most of your workers,

1070
00:48:00,260 --> 00:48:06,870
their operations are, are are not going to cause a split or merge into to your, your B+ tree nodes,

1071
00:48:07,220 --> 00:48:08,545
again, my example here,

1072
00:48:08,545 --> 00:48:10,375
I'm showing nodes with two keys in it,

1073
00:48:10,375 --> 00:48:11,490
because that's a fit of the PowerPoint,

1074
00:48:11,690 --> 00:48:13,050
but in a real system,

1075
00:48:13,670 --> 00:48:16,195
you know the the size of a node is going to be the page size to your database,

1076
00:48:16,195 --> 00:48:18,030
so like 8 kilobytes, 16 kilobytes

1077
00:48:18,350 --> 00:48:19,435
and you can store a lot of keys,

1078
00:48:19,435 --> 00:48:21,085
the most of the times you do a bunch of inserts

1079
00:48:21,085 --> 00:48:23,460
and that's not not going cause any, any splits,

1080
00:48:23,960 --> 00:48:25,060
and likewise for deletes.

1081
00:48:26,110 --> 00:48:29,300
So if you assume that splits merges will be rare,

1082
00:48:29,920 --> 00:48:33,290
then instead of taking write latches all the way down,

1083
00:48:33,820 --> 00:48:36,920
even if you're doing the the the latch, the latch coupling scheme,

1084
00:48:37,865 --> 00:48:39,490
you're going to take read latches -} all the way down,

1085
00:48:40,550 --> 00:48:44,220
until you get to a leaf node, right above the leaf node,

1086
00:48:44,300 --> 00:48:45,745
and then now you check to see

1087
00:48:45,745 --> 00:48:48,780
whether that assumption that you're not going to do a split or merge is correct,

1088
00:48:49,690 --> 00:48:50,660
and if it is,

1089
00:48:51,460 --> 00:48:53,660
then you go ahead and acquire the leaf node in write mode

1090
00:48:53,860 --> 00:48:55,250
and, and then do your change,

1091
00:48:55,600 --> 00:48:56,360
but if you're wrong,

1092
00:48:56,830 --> 00:48:59,625
you just restart and then do the pessimistic approach,

1093
00:48:59,625 --> 00:49:01,100
you just taking write latches all the way down.

1094
00:49:02,480 --> 00:49:04,180
So this would be a common theme, you see,

1095
00:49:04,180 --> 00:49:06,780
not just in databases and a bunch of different systems in general,

1096
00:49:07,310 --> 00:49:09,205
this is sort of optimistic scheme,

1097
00:49:09,205 --> 00:49:11,610
where you assume that there're not going to be any issues, not any problems,

1098
00:49:12,050 --> 00:49:13,980
and you do the sort of the fast way

1099
00:49:14,210 --> 00:49:17,610
of, of, of making some change or doing something in your system,

1100
00:49:18,260 --> 00:49:18,860
and then if you're wrong,

1101
00:49:18,860 --> 00:49:21,160
you just roll it back and take care of it.

1102
00:49:22,760 --> 00:49:25,750
Intel actually had this, it was called TSX,

1103
00:49:25,750 --> 00:49:28,800
we actually had this in the, in the CPU itself,

1104
00:49:28,820 --> 00:49:29,340
I think,

1105
00:49:29,960 --> 00:49:31,265
it was a bug and I think they turned it off,

1106
00:49:31,265 --> 00:49:32,330
it might have got turned back on,

1107
00:49:32,330 --> 00:49:34,715
but it was like this optimistic memory stuff,

1108
00:49:34,715 --> 00:49:36,910
where you could have a critical section,

1109
00:49:36,930 --> 00:49:42,340
where you would assume you're not going to have any conflicts in some critical section

1110
00:49:42,840 --> 00:49:45,335
and then when you went to go apply the change,

1111
00:49:45,335 --> 00:49:46,370
then you just just check

1112
00:49:46,370 --> 00:49:49,640
to see whether that, that that, that assumption was correct

1113
00:49:49,810 --> 00:49:51,560
and if not, it would roll you back automatically.

1114
00:49:52,900 --> 00:49:54,315
But again, we'll see this,

1115
00:49:54,315 --> 00:49:55,880
when we do talk about [] for transactions,

1116
00:49:56,320 --> 00:49:57,440
this is a very common technique,

1117
00:49:57,550 --> 00:49:58,545
you do the fast thing,

1118
00:49:58,545 --> 00:50:00,380
because that most of the times there won't be any issues

1119
00:50:00,760 --> 00:50:01,440
and if you're wrong,

1120
00:50:01,440 --> 00:50:03,890
then you have to roll back and try again.

1121
00:50:05,430 --> 00:50:07,685
All right, so with this better latching scheme,

1122
00:50:07,685 --> 00:50:10,510
for, for doing lookup and finds, that's the same as before,

1123
00:50:10,950 --> 00:50:12,130
for inserts and deletes,

1124
00:50:12,330 --> 00:50:16,235
again, we take we, we basically do the search,

1125
00:50:16,235 --> 00:50:18,700
taking write latches, sorry, read latches all the way down

1126
00:50:19,260 --> 00:50:22,090
until we're one level above the the leaf node,

1127
00:50:22,550 --> 00:50:25,450
I mean, we know where we're in the, in the, in the, the data structure,

1128
00:50:25,450 --> 00:50:29,340
because, you know, we can keep track of how many levels down we are

1129
00:50:30,770 --> 00:50:33,000
either in the page or a simple counter would work too.

1130
00:50:34,650 --> 00:50:38,210
You go acquire the the level right above the leaf node,

1131
00:50:38,210 --> 00:50:40,330
you acquire the leaf node in in write mode,

1132
00:50:40,860 --> 00:50:42,220
then you check to see whether it's safe,

1133
00:50:42,540 --> 00:50:43,325
if it is safe,

1134
00:50:43,325 --> 00:50:45,790
then you release all your read latches that you took from before,

1135
00:50:47,260 --> 00:50:48,440
apply your change and you're done,

1136
00:50:48,640 --> 00:50:49,430
if you're wrong,

1137
00:50:49,570 --> 00:50:51,270
then you just release all your latches

1138
00:50:51,270 --> 00:50:53,420
and go back and take write latches all the way down.

1139
00:50:54,100 --> 00:50:56,150
You could take, you know, do the optimistic scheme again,

1140
00:50:56,230 --> 00:50:57,920
because you assume next time you come back around,

1141
00:50:58,060 --> 00:50:58,820
things will be safe,

1142
00:50:59,110 --> 00:51:00,050
it depends on the implementation.

1143
00:51:00,920 --> 00:51:03,080
And so this works really well in low contention environments,

1144
00:51:03,080 --> 00:51:06,520
because you obviously assume there won't be any conflicts

1145
00:51:06,540 --> 00:51:07,810
and most of the time you're correct,

1146
00:51:07,830 --> 00:51:09,130
and so things run faster.

1147
00:51:11,570 --> 00:51:12,900
So let's go back, for example before,

1148
00:51:13,010 --> 00:51:14,580
let's delete key 38,

1149
00:51:15,260 --> 00:51:19,980
again, instead of taking the root node in, in, in a write latch mode,

1150
00:51:20,600 --> 00:51:22,590
taking a read mode, keep going down,

1151
00:51:22,880 --> 00:51:24,000
so I get down to D,

1152
00:51:24,440 --> 00:51:27,840
now D recognizes that it's one level above the leaf node,

1153
00:51:27,980 --> 00:51:32,520
so I want to delete key 38 from, from node H,

1154
00:51:32,750 --> 00:51:34,470
so I take the H into write mode,

1155
00:51:34,730 --> 00:51:35,760
check to see it's safe,

1156
00:51:36,050 --> 00:51:37,980
it is, I can go delete it,

1157
00:51:38,630 --> 00:51:40,320
and I know I'm not going to do any,

1158
00:51:41,000 --> 00:51:42,840
I'm not going to do any merges, right.

1159
00:51:43,880 --> 00:51:44,910
So again, best case scenario,

1160
00:51:45,110 --> 00:51:46,770
I I traversed the data structure

1161
00:51:46,880 --> 00:51:49,590
almost as if I was doing a read,

1162
00:51:50,440 --> 00:51:52,770
and therefore, I can have a maximum amount of parallelism,

1163
00:51:52,970 --> 00:51:54,235
but only at the bottom,

1164
00:51:54,235 --> 00:51:56,340
do I check to see whether that assumption was correct.

1165
00:51:58,790 --> 00:52:00,750
See how to do insert, insert 25,

1166
00:52:01,100 --> 00:52:03,210
again, take the root in in read mode,

1167
00:52:03,350 --> 00:52:04,380
take B in read mode,

1168
00:52:04,610 --> 00:52:07,590
do the latch coupling, as I release latches go down,

1169
00:52:07,970 --> 00:52:09,750
now I get down here into F,

1170
00:52:10,130 --> 00:52:10,920
in case of F,

1171
00:52:11,450 --> 00:52:12,720
because we're trying to do an insert,

1172
00:52:12,980 --> 00:52:14,850
F doesn't have any more room, so it's not safe,

1173
00:52:15,290 --> 00:52:17,280
so we're going have to restart the whole operation

1174
00:52:17,660 --> 00:52:19,650
and then just take write latches on the way down.

1175
00:52:24,050 --> 00:52:24,810
Neat trick, right?

1176
00:52:27,720 --> 00:52:28,120
Okay.

1177
00:52:30,810 --> 00:52:34,280
So, in all these examples I've shown so far,

1178
00:52:34,960 --> 00:52:36,540
we were only going in one direction,

1179
00:52:38,100 --> 00:52:39,490
we were only going top to the bottom,

1180
00:52:40,220 --> 00:52:42,430
as I said, there weren't any deadlocks,

1181
00:52:42,430 --> 00:52:44,610
because nobody, you know, everyone's going to the top,

1182
00:52:44,750 --> 00:52:46,530
they're always starting the same point and they're going down,

1183
00:52:46,940 --> 00:52:48,625
there's no, you know, as I said last class,

1184
00:52:48,625 --> 00:52:50,100
there's no pointers to your parent,

1185
00:52:50,760 --> 00:52:51,950
you can't go back up

1186
00:52:52,240 --> 00:52:54,200
and because that's where you could have conflicts.

1187
00:52:55,270 --> 00:52:56,990
Again, because we're a B+ tree,

1188
00:52:57,820 --> 00:52:59,210
we could have sibling pointers.

1189
00:53:00,090 --> 00:53:01,220
And now we have a challenge,

1190
00:53:01,220 --> 00:53:05,240
where we could have one thread going one way

1191
00:53:05,240 --> 00:53:06,430
and another thread going another way,

1192
00:53:06,540 --> 00:53:11,610
and they both hold latches for what the other person wants, what the other thread wants, right.

1193
00:53:12,730 --> 00:53:14,390
So now we've got to deal with that scenario,

1194
00:53:15,610 --> 00:53:17,450
the original B+ tree paper, this wasn't an issue,

1195
00:53:18,600 --> 00:53:20,585
but the B-link stuff that came from CMU,

1196
00:53:20,585 --> 00:53:21,755
that's where they added sibling pointers,

1197
00:53:21,755 --> 00:53:22,930
and that's where you can have deadlocks.

1198
00:53:24,710 --> 00:53:25,840
So let's look at a simple example here.

1199
00:53:26,970 --> 00:53:28,480
So I want thread 1,

1200
00:53:28,710 --> 00:53:30,460
they want to find all keys less than 4,

1201
00:53:31,350 --> 00:53:33,820
so I'm going to get the root in read mode

1202
00:53:34,260 --> 00:53:36,100
and then get the C in read mode

1203
00:53:36,540 --> 00:53:37,510
and then let's say,

1204
00:53:39,600 --> 00:53:41,650
and then once the scan, scan across,

1205
00:53:41,700 --> 00:53:43,330
so it's going to follow the sibling pointers,

1206
00:53:43,530 --> 00:53:45,310
so just like before, I hold,

1207
00:53:45,390 --> 00:53:46,480
whatever node I'm at now,

1208
00:53:46,650 --> 00:53:49,420
I hold that in the current latch mode, I have it,

1209
00:53:50,130 --> 00:53:54,100
and then I, then try to acquire the latch to where I want to go to,

1210
00:53:54,420 --> 00:53:55,310
so in this case here,

1211
00:53:55,310 --> 00:53:57,730
again to C, go from C to B,

1212
00:53:58,080 --> 00:53:59,380
so I hold the latch on C,

1213
00:53:59,610 --> 00:54:00,610
get the latch on B,

1214
00:54:00,960 --> 00:54:02,900
move over here and then I can release the latch on C

1215
00:54:02,900 --> 00:54:06,330
and then do whatever it is that I need to do, right.

1216
00:54:07,040 --> 00:54:08,435
So the protocol is basically the same thing,

1217
00:54:08,435 --> 00:54:12,580
even though we're now moving horizontally instead of vertically.

1218
00:54:13,630 --> 00:54:14,030
Yes.

1219
00:54:14,200 --> 00:54:25,170
We'll get that in a second, yes,

1220
00:54:25,220 --> 00:54:26,070
same schedule, yes.

1221
00:54:27,260 --> 00:54:29,910
So again, the read modes are [] commutative,

1222
00:54:29,960 --> 00:54:32,070
so I can have two threads I'm going to read at the same time,

1223
00:54:32,510 --> 00:54:35,740
I, first I goes down, or thread goes down, goes down to C,

1224
00:54:35,740 --> 00:54:36,750
second, thread goes down to B

1225
00:54:36,920 --> 00:54:38,220
and they want to go across each other,

1226
00:54:38,450 --> 00:54:39,430
and in this case here,

1227
00:54:39,430 --> 00:54:42,390
the the two latches they're holding are commutative,

1228
00:54:43,180 --> 00:54:46,850
so therefore, they can both do whatever they need to do, right.

1229
00:54:49,335 --> 00:54:49,670
That's fine.

1230
00:54:51,710 --> 00:54:52,525
So let's now do,

1231
00:54:52,525 --> 00:54:53,460
when we have a,

1232
00:54:55,170 --> 00:54:57,160
one of them wants to do a write, one wants to do a read.

1233
00:54:57,860 --> 00:54:59,820
So T1 wants to delete the key 4

1234
00:54:59,990 --> 00:55:02,010
and T2 wants to find all keys greater than 1.

1235
00:55:02,870 --> 00:55:04,200
So they both start at the same time

1236
00:55:04,430 --> 00:55:06,625
and assume we're doing the optimistic lock coupling,

1237
00:55:06,625 --> 00:55:08,430
I just talked about latch coupling,

1238
00:55:08,510 --> 00:55:16,120
where they started the root, both, both in, in read mode, right,

1239
00:55:16,410 --> 00:55:19,270
thread 2 goes down, takes B into read mode,

1240
00:55:19,500 --> 00:55:22,930
thread C goes down and takes, takes,

1241
00:55:23,280 --> 00:55:26,920
sorry, thread 1 goes down, takes node C in write mode,

1242
00:55:27,240 --> 00:55:29,540
and that's the key that it wants to delete, right.

1243
00:55:30,010 --> 00:55:33,710
But now thread 2, scanning across leaf nodes

1244
00:55:34,120 --> 00:55:37,700
and it wants to acquire the latch C in read mode,

1245
00:55:38,020 --> 00:55:38,930
but it can't,

1246
00:55:39,220 --> 00:55:42,260
because T1 holds that in write mode,

1247
00:55:44,270 --> 00:55:46,950
so we have to decide what we want to do here, right.

1248
00:55:48,000 --> 00:55:50,740
And T2 doesn't know anything about T1,

1249
00:55:51,620 --> 00:55:53,995
because I said, there's no centralized data structure that says,

1250
00:55:53,995 --> 00:55:54,955
here's the threads that are running,

1251
00:55:54,955 --> 00:55:56,490
here's, you know, here's what they're doing,

1252
00:55:56,900 --> 00:55:58,780
all that sees, all it knows is that,

1253
00:55:58,780 --> 00:56:01,380
there's a latch on this other node that I want to go to,

1254
00:56:01,580 --> 00:56:02,665
and it's currently in write mode

1255
00:56:02,665 --> 00:56:04,440
and that's not compatible with the mode I want to put it in,

1256
00:56:04,880 --> 00:56:06,000
so you have to do something.

1257
00:56:08,070 --> 00:56:09,640
So what can T2 do here?

1258
00:56:13,160 --> 00:56:14,730
The wait, that one option, what else?

1259
00:56:17,940 --> 00:56:18,230
What's that?

1260
00:56:19,375 --> 00:56:26,190
Kill Ourself, are you reading the slides, okay,

1261
00:56:26,190 --> 00:56:26,780
what's the third option?

1262
00:56:30,180 --> 00:56:33,010
and [go street] on the other thread and try to kill, kill it

1263
00:56:34,410 --> 00:56:35,470
and take the latch from it.

1264
00:56:37,870 --> 00:56:39,290
So what do you think is a good idea here?

1265
00:56:40,540 --> 00:56:42,470
What's that, says wait, for how long?

1266
00:56:48,740 --> 00:56:49,410
Yeah, forever,

1267
00:56:52,820 --> 00:56:53,370
how long,

1268
00:56:54,000 --> 00:56:54,665
but how do you know.

1269
00:56:58,940 --> 00:56:59,840
But that just waiting, right,

1270
00:56:59,840 --> 00:57:02,570
it just spinning until the latch is available, but like,,

1271
00:57:06,030 --> 00:57:06,670
how to say this?

1272
00:57:08,030 --> 00:57:11,850
Do you know what T T1 is, you know what T1 is doing,

1273
00:57:13,130 --> 00:57:15,070
no, we don't know anything, right.

1274
00:57:20,390 --> 00:57:20,970
Do you,

1275
00:57:21,350 --> 00:57:23,130
well, you know it's in right mode,

1276
00:57:23,270 --> 00:57:24,150
but how long is it going to take?

1277
00:57:32,130 --> 00:57:32,530
How?

1278
00:57:34,240 --> 00:57:34,680
Which one,

1279
00:57:34,680 --> 00:57:35,925
like, do you kill yourself from your schedule,

1280
00:57:35,925 --> 00:57:36,960
do you kill the other guy in your schedule,

1281
00:57:36,960 --> 00:57:37,580
what do you want to do,

1282
00:57:39,390 --> 00:57:40,990
she says kill ourself, fantastic, right,

1283
00:57:41,970 --> 00:57:42,730
how do you do that,

1284
00:57:45,580 --> 00:57:46,100
what's that?

1285
00:57:55,220 --> 00:57:55,645
What do you mean,

1286
00:57:55,645 --> 00:57:56,760
keep a log everything you done in the past.

1287
00:58:08,990 --> 00:58:10,590
Yeah, that sounds expensive,

1288
00:58:14,660 --> 00:58:15,750
what is a normal amount of time?

1289
00:58:20,520 --> 00:58:22,750
He says, wait for the average time for a write to happen.

1290
00:58:26,680 --> 00:58:29,180
But like you don't say,

1291
00:58:29,350 --> 00:58:30,840
in my simple example here,

1292
00:58:30,840 --> 00:58:32,000
because the [] and PowerPoint,

1293
00:58:32,410 --> 00:58:33,890
there's two nodes in the leaf, right,

1294
00:58:34,680 --> 00:58:37,270
what if there was a bunch of leaf nodes all over here,

1295
00:58:37,980 --> 00:58:41,405
I got to hold all these guys in everything in write mode, right,

1296
00:58:41,405 --> 00:58:42,820
because I want my change to happen atomically,

1297
00:58:42,900 --> 00:58:45,670
so I don't know whether this other thread keep going in the other direction,

1298
00:58:45,990 --> 00:58:47,830
I don't like what is a normal time, you don't know.

1299
00:58:53,320 --> 00:58:55,410
He says give up your write lock and let the other guy read,

1300
00:58:56,460 --> 00:58:57,245
but how do you know,

1301
00:58:57,245 --> 00:58:58,420
how do you know they're waiting for you,

1302
00:58:59,040 --> 00:59:00,140
like, if you're T1,

1303
00:59:00,490 --> 00:59:02,420
how do you know somebody else is trying to get your latch.

1304
00:59:04,340 --> 00:59:04,740
Yes.

1305
00:59:11,270 --> 00:59:12,030
Bingo, there you go, excellent.

1306
00:59:12,980 --> 00:59:17,035
So you should kill yourself, right, right,

1307
00:59:17,035 --> 00:59:18,865
so killing other thread is hard,

1308
00:59:18,865 --> 00:59:20,820
because how would you implement that,

1309
00:59:20,840 --> 00:59:22,855
can you send interrupt, interrupt [],

1310
00:59:22,855 --> 00:59:24,360
that's expensive, right, that's a syscall,

1311
00:59:25,730 --> 00:59:26,965
is there like a flag,

1312
00:59:26,965 --> 00:59:28,590
you say, should I kill myself,

1313
00:59:28,910 --> 00:59:30,250
and you have to check that every so often,

1314
00:59:30,250 --> 00:59:30,960
how would that work,

1315
00:59:32,840 --> 00:59:34,860
checking some other memory location, right,

1316
00:59:34,860 --> 00:59:35,985
and, and what do you get,

1317
00:59:35,985 --> 00:59:36,500
you get the,

1318
00:59:36,520 --> 00:59:40,250
you know, you don't know how much work the other thread, the other thread is done

1319
00:59:40,570 --> 00:59:45,165
and therefore you don't know whether him aborting and rolling back is

1320
00:59:45,165 --> 00:59:47,930
was way more expensive than than than you abort yourself,

1321
00:59:48,540 --> 00:59:50,630
you know nothing at this point, right.

1322
00:59:51,390 --> 00:59:55,690
So the best thing to do is just kill yourself,

1323
00:59:56,940 --> 00:59:59,660
and then you maybe you also could wait a little bit in the beginning

1324
00:59:59,660 --> 01:00:01,000
and then give up right away,

1325
01:00:01,380 --> 01:00:04,070
depending on what you know you need to do, right.

1326
01:00:05,430 --> 01:00:07,115
And so this is the simplest thing to do,

1327
01:00:07,115 --> 01:00:09,070
and it turns out to be the best thing to do

1328
01:00:09,210 --> 01:00:11,195
in most scenarios, all scenarios,

1329
01:00:11,195 --> 01:00:14,030
because again, you don't know anything about the thread,

1330
01:00:14,030 --> 01:00:16,150
you can't communicate with the other thread, because that's expensive,

1331
01:00:17,365 --> 01:00:19,530
and you're just better off aborting and starting over again.

1332
01:00:20,870 --> 01:00:21,270
Yes.

1333
01:00:31,870 --> 01:00:32,660
So his statement is,

1334
01:00:34,790 --> 01:00:37,360
you would have to wait also too or kill itself too,

1335
01:00:37,360 --> 01:00:40,470
like when you're doing the traversal of the tree going top down,

1336
01:00:40,700 --> 01:00:43,885
if I try to acquire a latch on somebody else on the next node,

1337
01:00:43,885 --> 01:00:45,660
but that's already being held, what I do,

1338
01:00:45,770 --> 01:00:47,130
it's the same scenario here,

1339
01:00:47,690 --> 01:00:49,800
that same scenario, but in that case, you're not,

1340
01:00:52,070 --> 01:00:53,230
you won't deadlock though, right.

1341
01:00:54,160 --> 01:00:54,700
The problem is,

1342
01:00:54,700 --> 01:00:57,870
like again, if if T2 wants to get the latch on on,

1343
01:00:58,460 --> 01:00:59,850
T1 wants to get the latch on B,

1344
01:01:00,110 --> 01:01:02,160
and T2 wants to latch on C,

1345
01:01:02,840 --> 01:01:03,720
that's a deadlock,

1346
01:01:03,890 --> 01:01:09,455
you don't know, that it's a deadlock or just contention acquiring some latch, right,

1347
01:01:09,455 --> 01:01:13,060
so the best thing to do is immediately give up.

1348
01:01:13,640 --> 01:01:14,860
And that means you could have a scenario,

1349
01:01:14,860 --> 01:01:16,840
where you hold the latch and I hold the latch

1350
01:01:16,840 --> 01:01:18,025
and one of us should only give up,

1351
01:01:18,025 --> 01:01:20,430
but we end up both giving up and killing ourselves, right.

1352
01:01:21,100 --> 01:01:28,530
But again, the cost of maintaining metadata about who's waiting for what in what way,

1353
01:01:28,940 --> 01:01:33,060
that's more expensive to do in the regular case where you assume there isn't contention.

1354
01:01:42,300 --> 01:01:43,750
Yeah, so it was this one here, right,

1355
01:01:43,890 --> 01:01:45,140
so they're both doing reads,

1356
01:01:45,140 --> 01:01:47,150
but assume they're both doing writes, right,

1357
01:01:47,150 --> 01:01:51,510
I need, I need to update all keys greater than 1 or something

1358
01:01:51,680 --> 01:01:53,700
he needs to update keys less than 4, right,

1359
01:01:53,750 --> 01:01:55,410
I'm going this way, he's gone that way,

1360
01:01:55,940 --> 01:01:57,480
we have that's a deadlock.

1361
01:01:57,980 --> 01:02:03,415
Think in terms of latches,

1362
01:02:03,415 --> 01:02:05,620
I'm trying to acquire latch on this direction,

1363
01:02:05,620 --> 01:02:07,110
trying to that direction

1364
01:02:07,340 --> 01:02:08,160
and we're deadlocked.

1365
01:02:11,500 --> 01:02:13,280
Your question is how to prevent both of them killing themselves.

1366
01:02:14,130 --> 01:02:16,240
So, like, you can't,

1367
01:02:17,050 --> 01:02:18,435
because I don't know, I don't know you exist,

1368
01:02:18,435 --> 01:02:19,610
I don't know what you're doing, right,

1369
01:02:22,100 --> 01:02:25,000
yeah, and you know, if you just think of computers in general,

1370
01:02:25,000 --> 01:02:26,845
like it's very unlikely that,

1371
01:02:26,845 --> 01:02:29,220
you and I gonna be exact lockstep in our threads

1372
01:02:29,420 --> 01:02:31,945
and the exact same like number of cycles,

1373
01:02:31,945 --> 01:02:35,230
we're both going to try to acquire a latch together that then would deadlock,

1374
01:02:35,230 --> 01:02:35,970
we go kill each other,

1375
01:02:36,170 --> 01:02:37,885
it's, it's a, it's a race condition,

1376
01:02:37,885 --> 01:02:39,235
but it's, it's, it's rare,

1377
01:02:39,235 --> 01:02:40,140
but you can't prevent it,

1378
01:02:40,190 --> 01:02:42,600
because the cost of preventing it is so expensive.

1379
01:02:48,610 --> 01:02:49,370
The statement is,

1380
01:02:50,200 --> 01:02:51,530
from a philosophical standpoint,

1381
01:02:52,060 --> 01:02:53,595
it would be more efficient to kill the other one,

1382
01:02:53,595 --> 01:02:54,290
would that be better?

1383
01:02:57,010 --> 01:02:58,125
It's not really philosophical question,

1384
01:02:58,125 --> 01:02:59,210
it's just like, straight up, is it better,

1385
01:03:00,850 --> 01:03:04,010
like you take their wallet, whatever you like.

1386
01:03:06,260 --> 01:03:07,480
Like, this is a toy example,

1387
01:03:07,480 --> 01:03:08,665
where like it's only one node,

1388
01:03:08,665 --> 01:03:09,840
like if you think about,

1389
01:03:10,370 --> 01:03:13,390
I don't know what the, I don't know what work you've done,

1390
01:03:13,390 --> 01:03:14,770
I don't, you don't know what I've done,

1391
01:03:14,770 --> 01:03:16,410
if we can sort of keep track of that,

1392
01:03:16,940 --> 01:03:18,940
then we may maybe decide,

1393
01:03:18,940 --> 01:03:22,020
okay, well you hold five latches, I hold one,

1394
01:03:22,280 --> 01:03:23,460
it's better to kill me,

1395
01:03:23,780 --> 01:03:26,190
because you did, you had to wait a bunch of time to get those five latches,

1396
01:03:26,390 --> 01:03:30,240
so that's sort of a high level, what we'll do when we do transactions,

1397
01:03:31,010 --> 01:03:32,980
they'll figure out who who gets priority or others

1398
01:03:32,980 --> 01:03:34,710
based on how much work they've done so far,

1399
01:03:34,880 --> 01:03:35,815
at this lowest level,

1400
01:03:35,815 --> 01:03:38,470
the latches are meant to be, so like fine-grainained and short,

1401
01:03:38,470 --> 01:03:39,810
it's better just to kill yourself.

1402
01:03:40,290 --> 01:03:40,780
All right.

1403
01:03:58,690 --> 01:03:59,220
It is possible,

1404
01:03:59,220 --> 01:03:59,900
so the question is,

1405
01:04:00,100 --> 01:04:02,600
could you basically have, could you starve a thread,

1406
01:04:03,070 --> 01:04:04,095
is the term you want to use,

1407
01:04:04,095 --> 01:04:05,055
could you starve a thread,

1408
01:04:05,055 --> 01:04:06,320
because every single time you try to get something,

1409
01:04:06,730 --> 01:04:08,010
it, it can't,

1410
01:04:08,010 --> 01:04:08,670
because someone else is in there,

1411
01:04:08,670 --> 01:04:09,530
could you strave that, yes.

1412
01:04:10,680 --> 01:04:11,080
So,

1413
01:04:12,580 --> 01:04:13,910
I think I have a slide on this.

1414
01:04:16,060 --> 01:04:16,820
Yeah, so,

1415
01:04:19,300 --> 01:04:19,910
there's,

1416
01:04:20,080 --> 01:04:22,785
I'll answer your question in a second,

1417
01:04:22,785 --> 01:04:26,990
like the the latches, the latches aren't gonna have anything to handle deadlocks for us,

1418
01:04:27,160 --> 01:04:30,530
and it's not gonna have anything that can prevent starvation,

1419
01:04:31,210 --> 01:04:32,780
in the read write latches,

1420
01:04:33,160 --> 01:04:35,580
you can set priorities, like writers or readers

1421
01:04:35,580 --> 01:04:38,210
or you want to do FIFO or round robin scheduling,

1422
01:04:39,190 --> 01:04:42,140
but there's a high level construct scheduler inside,

1423
01:04:42,370 --> 01:04:46,820
oh, this, this, this worker is trying to run this query,

1424
01:04:47,230 --> 01:04:48,830
trying to touch this data structure

1425
01:04:49,120 --> 01:04:50,190
and it keeps getting aborted,

1426
01:04:50,190 --> 01:04:51,500
and I know it's getting aborted,

1427
01:04:52,870 --> 01:04:55,400
because you know it's coming back with a retry message,

1428
01:04:55,840 --> 01:04:59,535
and therefore, maybe I wanna dechedule other workers running at the same time

1429
01:04:59,535 --> 01:05:00,710
to make sure I always get through,

1430
01:05:01,510 --> 01:05:03,080
that's had a way to basically handle that,

1431
01:05:04,410 --> 01:05:06,670
most systems basically let you know,

1432
01:05:07,530 --> 01:05:09,425
let Jesus take the wheel, whatever the phrase you want to use

1433
01:05:09,425 --> 01:05:11,800
and let it go at it, right,

1434
01:05:12,780 --> 01:05:16,220
because eventually you should get through.

1435
01:05:16,220 --> 01:05:17,680
Now, again, if I have a,

1436
01:05:18,630 --> 01:05:22,130
you know, a thousand queries trying to run at the same time

1437
01:05:22,130 --> 01:05:23,620
trying to all update the same key,

1438
01:05:23,940 --> 01:05:26,620
there's no magic scheduler that's gonna be able to handle that,

1439
01:05:27,060 --> 01:05:28,390
everything's sort of get contention,

1440
01:05:28,590 --> 01:05:30,490
end up being a single thread system.

1441
01:05:31,380 --> 01:05:33,890
So we want to optimize for the case,

1442
01:05:33,890 --> 01:05:39,210
where we assume that the, we assume contention is gonna be low

1443
01:05:39,860 --> 01:05:43,045
and we want to sort of fast, fail fast, no wait policy,

1444
01:05:43,045 --> 01:05:44,515
we just check, can I do it,

1445
01:05:44,515 --> 01:05:45,870
no, okay, let me retry again,

1446
01:05:46,280 --> 01:05:48,420
because by the time, you know, when I go, go retry,

1447
01:05:49,190 --> 01:05:51,120
then then I'll be able to do what I need to do.

1448
01:05:55,240 --> 01:05:55,970
His question is,

1449
01:05:56,170 --> 01:05:56,790
while you're killing yourself,

1450
01:05:56,790 --> 01:05:58,370
so do you have to roll back any changes that you do,

1451
01:05:58,750 --> 01:05:59,660
yes, in the code.

1452
01:06:00,730 --> 01:06:04,755
So again, going back to the writer example here,

1453
01:06:04,755 --> 01:06:09,280
like if, if this thread that kills itself,

1454
01:06:09,280 --> 01:06:10,440
they had updated a bunch of things,

1455
01:06:10,520 --> 01:06:12,840
is where you hold the write latches for those things, you updated,

1456
01:06:12,950 --> 01:06:14,460
so you can go back and reverse those changes.

1457
01:06:19,650 --> 01:06:20,620
It's possible deadlock,

1458
01:06:20,730 --> 01:06:21,575
no, why would you get deadlock,

1459
01:06:21,575 --> 01:06:22,520
if you already hold the latch,

1460
01:06:22,520 --> 01:06:23,410
why would you get deadlocked.

1461
01:06:41,460 --> 01:06:42,095
So his question is,

1462
01:06:42,095 --> 01:06:44,870
in what in what scenario do you need the backwards pointer in the sibling,

1463
01:06:44,870 --> 01:06:47,380
because, because it seems like it's causing problems for us, right.

1464
01:06:47,940 --> 01:06:49,250
Your query is this, right,

1465
01:06:49,250 --> 01:06:51,040
find keys less than 4, find keys is greater than 1.

1466
01:06:58,440 --> 01:07:01,000
Same as you could start at 1 and go until you find 4,

1467
01:07:05,220 --> 01:07:07,770
I have a billion keys, right,

1468
01:07:07,770 --> 01:07:09,740
like and I.

1469
01:07:11,410 --> 01:07:12,405
Yeah, that's just way more expensive,

1470
01:07:12,405 --> 01:07:13,640
nobody does that, yeah.

1471
01:07:17,680 --> 01:07:19,725
Yeah, so, so we didn't talk about skip list,

1472
01:07:19,725 --> 01:07:21,680
there was a actually,

1473
01:07:22,150 --> 01:07:24,560
SingleStore, before it was SingleStore was MemSQL,

1474
01:07:24,820 --> 01:07:27,200
they had these skip list and skip list only have,

1475
01:07:27,490 --> 01:07:29,760
because they it's a, it's a lot free data structure,

1476
01:07:29,760 --> 01:07:30,465
which is a bad idea,

1477
01:07:30,465 --> 01:07:31,440
it's another, another topic,

1478
01:07:31,440 --> 01:07:35,460
but like they, they had their skip list can only go in one direction,

1479
01:07:35,960 --> 01:07:37,540
so they had to do a bunch of tricks

1480
01:07:37,540 --> 01:07:40,080
of like having ways to jump into the data structure

1481
01:07:40,460 --> 01:07:41,740
to, to like try to do reverse

1482
01:07:41,740 --> 01:07:43,110
and then sort it and reverse,

1483
01:07:43,670 --> 01:07:45,210
after you know, after, after you get it out,

1484
01:07:45,500 --> 01:07:46,500
it just makes life harder,

1485
01:07:47,120 --> 01:07:50,520
you can do it and avoids this deadlock issue.

1486
01:07:54,400 --> 01:07:55,820
But it's still an example,

1487
01:07:56,080 --> 01:07:57,170
if you're traversing down,

1488
01:07:57,430 --> 01:07:59,460
if I can't acquire the latch as I'm going down,

1489
01:07:59,460 --> 01:08:00,225
it's not a deadlock,

1490
01:08:00,225 --> 01:08:02,510
I still want to kill myself potentially usually.

1491
01:08:06,270 --> 01:08:06,850
It still.

1492
01:08:08,250 --> 01:08:11,630
Yeah, so you still,

1493
01:08:11,630 --> 01:08:12,620
you won't have deadlocks,

1494
01:08:12,620 --> 01:08:13,990
if you do what you're proposing,

1495
01:08:14,070 --> 01:08:15,530
but you still could have latch contention,

1496
01:08:15,530 --> 01:08:16,450
where I can't get the latch,

1497
01:08:17,070 --> 01:08:18,190
because somebody else holds it.

1498
01:08:18,660 --> 01:08:19,650
And in that case, again,

1499
01:08:19,650 --> 01:08:22,070
usually you want to spin for a little bit and then kill yourself.

1500
01:08:23,270 --> 01:08:24,510
Yeah, you still want to kill yourself,

1501
01:08:25,100 --> 01:08:26,110
that sounds weird, but you know what I mean.

1502
01:08:28,430 --> 01:08:28,830
Yes.

1503
01:08:41,880 --> 01:08:44,810
. Yeah, so he's right,

1504
01:08:45,190 --> 01:08:45,830
repeat what he said,

1505
01:08:45,880 --> 01:08:46,820
so he basically said,

1506
01:08:48,520 --> 01:08:50,180
we know how much work we've done

1507
01:08:50,650 --> 01:08:52,785
and we did a lot of updates,

1508
01:08:52,785 --> 01:08:54,500
we know they were expensive to do,

1509
01:08:55,810 --> 01:08:58,065
so could we have a heuristic that says,

1510
01:08:58,065 --> 01:08:59,370
when we, we spin,

1511
01:08:59,370 --> 01:09:00,620
determine how long we want to wait

1512
01:09:00,910 --> 01:09:02,060
based on how much work we've done,

1513
01:09:02,350 --> 01:09:03,380
yes, you could do that,

1514
01:09:03,800 --> 01:09:07,200
I don't think Postgres MySQL actually do that,

1515
01:09:07,200 --> 01:09:08,000
I might be wrong.

1516
01:09:08,170 --> 01:09:15,560
Would it be?

1517
01:09:15,640 --> 01:09:16,370
I mean, you can imagine,

1518
01:09:16,510 --> 01:09:17,540
really simple heuristic,

1519
01:09:18,160 --> 01:09:18,660
a counter,

1520
01:09:18,950 --> 01:09:21,640
I have a counter in my local address,

1521
01:09:21,640 --> 01:09:22,680
local memory for my worker,

1522
01:09:24,340 --> 01:09:25,850
how many pages have I updated,

1523
01:09:26,260 --> 01:09:27,410
and for each page I updated,

1524
01:09:27,790 --> 01:09:31,910
wait, maybe an extra, you know, hundred microseconds something like that,

1525
01:09:32,770 --> 01:09:33,525
simple heuristics,

1526
01:09:33,525 --> 01:09:35,300
I don't know whether it actually makes sense or not to do it,

1527
01:09:36,160 --> 01:09:37,740
it's a [] out for all case and databases,

1528
01:09:37,740 --> 01:09:38,580
it depends on the workload,

1529
01:09:38,580 --> 01:09:42,105
depends on, you know, if everybody's updating a bunch of stuff,

1530
01:09:42,105 --> 01:09:43,080
then maybe that's a bad idea,

1531
01:09:43,080 --> 01:09:44,970
but you have one thread, one worker,

1532
01:09:44,970 --> 01:09:46,190
that updates a little bit of things,

1533
01:09:46,390 --> 01:09:47,900
that maybe, yeah, that might make sense.

1534
01:09:48,710 --> 01:09:50,790
But once if I try to update the same key,

1535
01:09:50,870 --> 01:09:54,450
it gets, everything gets bogged, boggled down to a single threaded system,

1536
01:09:55,100 --> 01:09:56,250
that's the extreme case, though.

1537
01:09:56,720 --> 01:09:57,100
Yes.

1538
01:10:06,680 --> 01:10:07,530
How do you handle that,

1539
01:10:08,505 --> 01:10:10,340
they're dead, I mean, they restart.

1540
01:10:11,170 --> 01:10:11,570
Yeah.

1541
01:10:13,130 --> 01:10:15,660
Yeah, so, so very clear,

1542
01:10:16,130 --> 01:10:16,950
I say this in slide,

1543
01:10:16,970 --> 01:10:20,190
the restart mechanism is transparent to the user.

1544
01:10:22,510 --> 01:10:24,080
Yeah, I don't have a slides at this like.

1545
01:10:24,700 --> 01:10:25,620
Like I run a query

1546
01:10:26,300 --> 01:10:28,195
and I have to traverse a B+ tree

1547
01:10:28,195 --> 01:10:30,550
and I and, and to go look at the primary key

1548
01:10:30,550 --> 01:10:32,280
and I can't get a latch as I'm going down,

1549
01:10:32,420 --> 01:10:34,450
I don't want to abort the query and go back to the user,

1550
01:10:34,450 --> 01:10:35,760
hey, look, I couldn't get a latch,

1551
01:10:35,840 --> 01:10:37,705
because they don't know what a latch is, right,

1552
01:10:37,705 --> 01:10:40,630
and then tell to restart, we do this transparently for you,

1553
01:10:40,630 --> 01:10:42,690
so like, so like you submit one query,

1554
01:10:42,920 --> 01:10:47,100
it may restart the the traverse one of the B+ tree multiple times,

1555
01:10:47,840 --> 01:10:49,760
and, but you don't see that from the end user of the application,

1556
01:10:49,760 --> 01:10:50,735
we're doing it internally,

1557
01:10:50,735 --> 01:10:52,690
it's just the query got a little bit slower, because of that.

1558
01:10:56,700 --> 01:10:57,590
A lot of questions, sorry.

1559
01:11:00,490 --> 01:11:00,890
Yes.

1560
01:11:00,940 --> 01:11:08,730
Yeah, absolutely,

1561
01:11:08,730 --> 01:11:09,620
so the question is,

1562
01:11:09,700 --> 01:11:10,425
is there a scenario,

1563
01:11:10,425 --> 01:11:12,090
where someone has a write latch on the root

1564
01:11:12,090 --> 01:11:14,120
and if you restart, you're going to come back and abort,

1565
01:11:15,510 --> 01:11:16,060
absolutely, yes,

1566
01:11:16,875 --> 01:11:17,510
it's unavoidable.

1567
01:11:20,660 --> 01:11:24,280
I mean, the more keys you insert, the tree gets taller,

1568
01:11:26,360 --> 01:11:32,550
and therefore, the, the likelihood that someone's going to hold a write latch on the root goes down, right.

1569
01:11:38,410 --> 01:11:40,640
Going back to the stall stuff, too,

1570
01:11:42,030 --> 01:11:45,380
it's not just how much work the other thread doing,

1571
01:11:45,850 --> 01:11:50,610
like, like you have to sort of wait for,

1572
01:11:51,170 --> 01:11:57,180
remember these, these data structures are backed by pages in the buffer pool that are on a disk,

1573
01:11:57,650 --> 01:11:59,400
so even though I'm updating one key,

1574
01:11:59,750 --> 01:12:02,305
the key I need to update might be not in memory

1575
01:12:02,305 --> 01:12:03,840
and I gotta go out the disk and get it,

1576
01:12:05,130 --> 01:12:05,840
so that's why,

1577
01:12:05,840 --> 01:12:06,755
and you don't want to stall,

1578
01:12:06,755 --> 01:12:08,465
you don't want to spin forever for a long time,

1579
01:12:08,465 --> 01:12:09,275
because you don't know,

1580
01:12:09,275 --> 01:12:11,140
like, you know, it has to go get a disk,

1581
01:12:11,660 --> 01:12:12,785
it's just a really slow disk

1582
01:12:12,785 --> 01:12:14,170
and that's going to be a long time

1583
01:12:14,460 --> 01:12:19,470
and you can be waiting for 100 milliseconds, 500 milliseconds.

1584
01:12:20,320 --> 01:12:22,040
So he said, oh, yeah, do the average time,

1585
01:12:22,060 --> 01:12:23,415
I mean, it depends on so many factors,

1586
01:12:23,415 --> 01:12:24,830
that would be impossible to track these things.

1587
01:12:27,730 --> 01:12:28,860
Again, this is, again, this is why

1588
01:12:28,860 --> 01:12:31,545
this is different than taking a regular data structure algorithalms classes,

1589
01:12:31,545 --> 01:12:33,380
because these things are backed by disk,

1590
01:12:34,780 --> 01:12:36,280
and we're having multiple threads running at the same time,

1591
01:12:36,280 --> 01:12:40,740
and there's a bunch of things we need to do to hide that, those [],

1592
01:12:43,530 --> 01:12:44,840
SQL Server, a whole other [],

1593
01:12:44,840 --> 01:12:50,030
SQL Server, they have, they actually have their own user space [] routines,

1594
01:12:50,620 --> 01:12:52,940
so like if you're traversing the data structure,

1595
01:12:55,010 --> 01:12:57,060
and the thing I need, I can't get the latch,

1596
01:12:57,890 --> 01:13:01,270
instead of just spinning, they go back to their own user space schedule

1597
01:13:01,270 --> 01:13:02,875
and says, I can't, I can't run,

1598
01:13:02,875 --> 01:13:03,870
because I'm waiting for this latch,

1599
01:13:04,620 --> 01:13:06,600
and then they take your thread away

1600
01:13:06,600 --> 01:13:07,620
and have it do some other work,

1601
01:13:07,620 --> 01:13:09,495
and then they may know what latch you're waiting for,

1602
01:13:09,495 --> 01:13:10,790
they're actually doing some tracking,

1603
01:13:11,350 --> 01:13:13,400
who's waiting for what latches inside of it,

1604
01:13:14,180 --> 01:13:15,085
and they can do that,

1605
01:13:15,085 --> 01:13:16,770
because everything is [] routines in user space,

1606
01:13:18,750 --> 01:13:20,045
very few, nobody else does,

1607
01:13:20,045 --> 01:13:22,180
that SQL Server does some really cool things.

1608
01:13:24,130 --> 01:13:25,400
All right, cool. Any other questions?

1609
01:13:27,050 --> 01:13:27,450
Yes.

1610
01:13:47,320 --> 01:13:48,195
Yeah, so his question is,

1611
01:13:48,195 --> 01:13:48,720
let me go back here,

1612
01:13:48,720 --> 01:13:49,230
his question is,

1613
01:13:49,230 --> 01:13:52,300
if I'm traversing along with sibling nodes,

1614
01:13:56,690 --> 01:13:57,540
this one here, right,

1615
01:13:59,800 --> 01:14:00,630
if they're trying to get across,

1616
01:14:01,630 --> 01:14:04,010
why does, so T2 is that B,

1617
01:14:04,660 --> 01:14:05,660
T1 is that C,

1618
01:14:06,280 --> 01:14:10,940
why does T2 need to hold the latch on B in order to get to C,

1619
01:14:11,590 --> 01:14:12,735
because you need to know,

1620
01:14:12,735 --> 01:14:14,085
that the sibling pointer is still valid,

1621
01:14:14,085 --> 01:14:15,950
then this is the right, the right node,

1622
01:14:16,210 --> 01:14:18,590
that this is the right node you'd be looking to, right,

1623
01:14:18,760 --> 01:14:20,580
and you know that if there was an update,

1624
01:14:20,580 --> 01:14:21,930
because you hold this in read mode,

1625
01:14:21,930 --> 01:14:23,000
nobody can update it,

1626
01:14:23,050 --> 01:14:26,030
so you know that no one's gonna replace B with something

1627
01:14:26,560 --> 01:14:28,215
with some, you know, some other new version of it,

1628
01:14:28,215 --> 01:14:29,270
they now point to something else

1629
01:14:29,590 --> 01:14:31,380
and but you're still gonna follow the pointer

1630
01:14:31,380 --> 01:14:34,300
to whatever you thought was there before, right,

1631
01:14:34,470 --> 01:14:35,630
so you have to hold the latches

1632
01:14:35,630 --> 01:14:37,180
until you know you're safe on the other side,

1633
01:14:37,440 --> 01:14:38,590
then you can go ahead and release it.

1634
01:14:39,420 --> 01:14:41,420
Same thing, it's going from top down,

1635
01:14:41,420 --> 01:14:42,245
you need to know that,

1636
01:14:42,245 --> 01:14:44,800
like the thing I'm jumping to next is what I should be jumping into.

1637
01:14:48,000 --> 01:14:48,400
Yes.

1638
01:15:01,250 --> 01:15:01,650
Yes.

1639
01:15:24,300 --> 01:15:26,210
Yeah, so, so this question, same as,

1640
01:15:26,210 --> 01:15:28,180
it is a question that like,

1641
01:15:28,990 --> 01:15:34,220
last time, I talked about how systems like Postgres have sibling pointers at inner nodes,

1642
01:15:34,450 --> 01:15:36,800
even though I'm only showing leaf nodes here,

1643
01:15:37,120 --> 01:15:41,300
and if I use those inner node sibling pointers to jump, again, horizontally,

1644
01:15:42,280 --> 01:15:43,530
how do I take latches on those

1645
01:15:43,530 --> 01:15:44,870
and make sure things are still correct,

1646
01:15:45,250 --> 01:15:47,720
so the protocol, everything I'm describing here, would still work,

1647
01:15:49,480 --> 01:15:49,880
if,

1648
01:15:51,530 --> 01:15:52,555
for reads, it simple,

1649
01:15:52,555 --> 01:15:54,150
could you just take the read latch across,

1650
01:15:56,920 --> 01:15:58,635
because anybody else coming above you,

1651
01:15:58,635 --> 01:15:59,270
once you are write,

1652
01:15:59,470 --> 01:16:01,190
they'll see your read latch and they'll stop,

1653
01:16:01,630 --> 01:16:04,815
anything below, below that side of the tree that was doing an update,

1654
01:16:04,815 --> 01:16:06,830
you'll get [blocked], you take the take the read down,

1655
01:16:07,030 --> 01:16:07,760
so that's fine,

1656
01:16:08,080 --> 01:16:09,105
for doing updates,

1657
01:16:09,105 --> 01:16:11,450
I think it works the same way as you come across,

1658
01:16:13,340 --> 01:16:16,330
if what you're trying to do below is not safe,

1659
01:16:16,830 --> 01:16:18,490
then you still hold latches for those things,

1660
01:16:18,540 --> 01:16:19,595
the protocol still works,

1661
01:16:19,595 --> 01:16:21,850
even if you have to go across horizontally and go down.

1662
01:16:23,530 --> 01:16:24,740
You still have the deadlock,

1663
01:16:24,820 --> 01:16:27,830
if everyone's trying to go across vertically on you or horizontally on on you too,

1664
01:16:27,880 --> 01:16:29,480
and then you do the same thing I'm describing here.

1665
01:16:31,000 --> 01:16:31,970
Is there another question?

1666
01:16:34,780 --> 01:16:35,390
Okay, cool.

1667
01:16:38,410 --> 01:16:39,320
So, all right.

1668
01:16:40,380 --> 01:16:41,170
Just to finish up.

1669
01:16:42,980 --> 01:16:43,590
This is hard

1670
01:16:44,870 --> 01:16:47,260
and I'm showing you like the most simplest version to do,

1671
01:16:47,260 --> 01:16:49,830
latch crabbing and that [],

1672
01:16:53,300 --> 01:16:54,325
we're not going to cover this in this class,

1673
01:16:54,325 --> 01:16:56,245
but there's way more complicated schemes,

1674
01:16:56,245 --> 01:16:57,360
you can have [] latches,

1675
01:16:57,800 --> 01:17:00,900
you can have delayed updates,

1676
01:17:01,190 --> 01:17:02,650
you can do the B tree stuff,

1677
01:17:02,650 --> 01:17:03,330
where you delay things,

1678
01:17:03,650 --> 01:17:05,100
there's a bunch of other stuff you can do this,

1679
01:17:06,410 --> 01:17:09,210
the B tree is a lock-free B+ tree from Microsoft,

1680
01:17:09,770 --> 01:17:10,800
that's a whole other nightmare.

1681
01:17:13,040 --> 01:17:14,575
Again, this is hard, but this is good,

1682
01:17:14,575 --> 01:17:16,570
because this is like you take this class

1683
01:17:16,570 --> 01:17:17,550
and this is why,

1684
01:17:17,900 --> 01:17:20,370
you know, you don't want your, your random Javascript programmer

1685
01:17:20,600 --> 01:17:23,580
building your, your B+ tree, your data structures in your database systems,

1686
01:17:23,900 --> 01:17:26,880
you want CMU students like you guys that know what the hell they're doing

1687
01:17:26,930 --> 01:17:28,710
and make sure that they don't cause problems.

1688
01:17:29,900 --> 01:17:31,855
And so again we talk about hash table,

1689
01:17:31,855 --> 01:17:33,510
we talk about B B+ tree today,

1690
01:17:33,770 --> 01:17:35,350
but these techniques of this idea of

1691
01:17:35,350 --> 01:17:36,720
like everything's going the same direction

1692
01:17:36,740 --> 01:17:39,420
or I kill myself as soon as I can't get something and restart

1693
01:17:39,650 --> 01:17:45,750
like this is, this is relevant to, to a bunch of other data structures in systems as well.

1694
01:17:47,520 --> 01:17:50,260
I feel like we should just call this course, kill yourself,

1695
01:17:50,490 --> 01:17:54,260
I actually asking for CMU to get involved,

1696
01:17:54,260 --> 01:17:54,490
I don't need that trouble, sorry,

1697
01:17:55,920 --> 01:17:57,110
one year, somebody did complain,

1698
01:17:57,110 --> 01:18:00,250
that did say kill yourself a lot, sorry.

1699
01:18:00,390 --> 01:18:01,000
All right, so,

1700
01:18:01,680 --> 01:18:05,230
so next class we're talking about sorting or sort aggregations,

1701
01:18:05,280 --> 01:18:07,660
so this point we're moving up the stack,

1702
01:18:08,010 --> 01:18:09,730
now we can actually start executing queries,

1703
01:18:09,960 --> 01:18:10,810
fantastic, right,

1704
01:18:11,850 --> 01:18:15,005
so I won't be here on Monday or I'm not teaching,

1705
01:18:15,005 --> 01:18:17,255
Jignesh Patel be the other professor,

1706
01:18:17,255 --> 01:18:18,910
he's going to start teaching on Monday

1707
01:18:19,680 --> 01:18:21,130
and then wednesday, next week,

1708
01:18:21,390 --> 01:18:22,550
he and I are both gone,

1709
01:18:22,550 --> 01:18:24,230
I'm going to the Postgres conference in New York,

1710
01:18:24,230 --> 01:18:25,780
I'm giving a keynote there about databases,

1711
01:18:27,480 --> 01:18:28,720
might have to talk to [],

1712
01:18:31,120 --> 01:18:32,485
but like we'll have one of my PhD students,

1713
01:18:32,485 --> 01:18:33,925
my number one PhD student Matt Butrovich

1714
01:18:33,925 --> 01:18:36,600
will be teaching on Wednesday next week about Joins, okay?

1715
01:18:36,920 --> 01:18:40,120
And then Jignesh is awesome,

1716
01:18:40,120 --> 01:18:42,870
Jignesh, asked him about growing up in India,

1717
01:18:42,950 --> 01:18:45,400
because before he joined CMU,

1718
01:18:45,400 --> 01:18:46,165
he was telling me crazy stories,

1719
01:18:46,165 --> 01:18:48,600
he used to get in fights every morning on the bus going to school,

1720
01:18:49,345 --> 01:18:52,060
I think he carried knife, ask him about it.

1721
01:18:52,060 --> 01:18:57,400
Okay, and then we'll, we'll talk about the midterm on, on next week as well, okay.

